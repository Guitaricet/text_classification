{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train, test = torchtext.datasets.IMDB.splits(text, label)\n",
    "\n",
    "c = Counter(''.join([' '.join(t.text) for t in train]))\n",
    "\n",
    "ALPHABET = [char[0] for char in c.most_common(62)]  # all other chars used less ~ 100 times in a test\n",
    "ALPHABET.append('UNK')\n",
    "ALPHABET.append('PAD')\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}\n",
    "\n",
    "MAXLEN = 1024\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "TEST_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text(text, maxlen=MAXLEN, batch_size=BATCH_SIZE):\n",
    "    one_hotted_text = np.zeros((batch_size, maxlen, ALPHABET_LEN))\n",
    "    assert len(text) == batch_size\n",
    "    for bi, batch in enumerate(text):\n",
    "        for i, char in enumerate(batch):\n",
    "            if i >= MAXLEN:\n",
    "                break\n",
    "            one_hotted_text[bi, i, char2int.get(char, char2int['UNK'])] = 1.\n",
    "        if i < MAXLEN:\n",
    "            for j in range(i+1, MAXLEN):\n",
    "                one_hotted_text[bi, j, char2int['PAD']] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "all_texts = [t.text for t in train]\n",
    "all_labels = [int(t.label == 'pos') for t in train]\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(all_texts, all_labels)\n",
    "\n",
    "batch_idx = 0\n",
    "\n",
    "def next_batch():\n",
    "    # BATCH_SIZE(32), ALPHABET_LEN(128), MAXLEN(512)\n",
    "    global batch_idx\n",
    "    batch = X[batch_idx:batch_idx+BATCH_SIZE], y[batch_idx:batch_idx+BATCH_SIZE]\n",
    "    batch_idx += BATCH_SIZE\n",
    "    return batch\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None and param.requires_grad:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim=256):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.rnn = nn.LSTM(ALPHABET_LEN, hidden_dim, num_layers=1)\n",
    "        self.projector = nn.Linear(hidden_dim, 2)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = BATCH_SIZE\n",
    "        \n",
    "        # 1 is num_layers\n",
    "        if CUDA:\n",
    "            h0 = Variable(torch.randn([1, batch_size, self.hidden_dim]).cuda())\n",
    "            c0 = Variable(torch.randn([1, batch_size, self.hidden_dim]).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.randn([1, batch_size, self.hidden_dim]))\n",
    "            c0 = Variable(torch.randn([1, batch_size, self.hidden_dim]))\n",
    "\n",
    "        return h0, c0\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        self.hidden = self.init_hidden(inp.size()[1])\n",
    "        rnn_out, rnn_hidden = self.rnn(inp, self.hidden)\n",
    "        out = self.projector(rnn_out[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (rnn): LSTM(128, 256)\n",
       "  (projector): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CharRNN(256)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='_char_lstm_256_optimizer_5_maxlen_1024_batch_256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [t.text for t in test]\n",
    "test_labels = [int(t.label == 'pos') for t in test]\n",
    "\n",
    "test_texts, test_labels = shuffle(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_labels))\n",
    "sum(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(step, last_prediction, last_labels):\n",
    "\n",
    "    _, idx = torch.max(last_prediction, 1)\n",
    "    acc = accuracy_score(last_labels.data.tolist(), idx.data.tolist())\n",
    "    writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "    print('In-batch accuracy:', acc)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    test_texts, test_labels = shuffle(test_texts, test_labels)\n",
    "    \n",
    "    for t in test_texts[:TEST_SIZE]:\n",
    "\n",
    "        ptex = preprocess_text([t], batch_size=1)\n",
    "        ptex = Variable(ptex.cuda())\n",
    "        ptex = ptex.permute(1, 0, 2)\n",
    "        pred = model(ptex)\n",
    "        _, idx = torch.max(pred, 1)\n",
    "\n",
    "        predictions.append(idx.data[0])\n",
    "    \n",
    "    lables = test_labels[:TEST_SIZE]\n",
    "    \n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    print('Test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test', acc, global_step=global_step)\n",
    "\n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "0.6937292218208313\n",
      "In-batch accuracy: 0.48046875\n",
      "Test accuracy: 0.5\n",
      "Loss after epoch 1:\n",
      "0.6938817501068115\n",
      "In-batch accuracy: 0.48046875\n",
      "Test accuracy: 0.47\n",
      "Loss after epoch 2:\n",
      "0.6937626600265503\n",
      "In-batch accuracy: 0.50390625\n",
      "Test accuracy: 0.54\n",
      "Loss after epoch 3:\n",
      "0.6924145221710205\n",
      "In-batch accuracy: 0.54296875\n",
      "Test accuracy: 0.43\n",
      "Loss after epoch 4:\n",
      "0.6929919123649597\n",
      "In-batch accuracy: 0.484375\n",
      "Test accuracy: 0.48\n",
      "Loss after epoch 5:\n",
      "0.6946525573730469\n",
      "In-batch accuracy: 0.46484375\n",
      "Test accuracy: 0.56\n",
      "Loss after epoch 6:\n",
      "0.6942274570465088\n",
      "In-batch accuracy: 0.46875\n",
      "Test accuracy: 0.51\n",
      "Loss after epoch 7:\n",
      "0.6910460591316223\n",
      "In-batch accuracy: 0.546875\n",
      "Test accuracy: 0.57\n",
      "Loss after epoch 8:\n",
      "0.692038357257843\n",
      "In-batch accuracy: 0.52734375\n",
      "Test accuracy: 0.49\n",
      "Loss after epoch 9:\n",
      "0.691204309463501\n",
      "In-batch accuracy: 0.5546875\n",
      "Test accuracy: 0.55\n",
      "Loss after epoch 10:\n",
      "0.6895204186439514\n",
      "In-batch accuracy: 0.58984375\n",
      "Test accuracy: 0.51\n",
      "Loss after epoch 11:\n",
      "0.6919420957565308\n",
      "In-batch accuracy: 0.5546875\n",
      "Test accuracy: 0.49\n",
      "Loss after epoch 12:\n",
      "0.6913771033287048\n",
      "In-batch accuracy: 0.5234375\n",
      "Test accuracy: 0.51\n",
      "Loss after epoch 13:\n",
      "0.6889700889587402\n",
      "In-batch accuracy: 0.55078125\n",
      "Test accuracy: 0.5\n",
      "Loss after epoch 14:\n",
      "0.692321240901947\n",
      "In-batch accuracy: 0.51171875\n",
      "Test accuracy: 0.51\n",
      "Loss after epoch 15:\n",
      "0.6947385668754578\n",
      "In-batch accuracy: 0.48828125\n",
      "Test accuracy: 0.49\n",
      "Loss after epoch 16:\n",
      "0.6929243206977844\n",
      "In-batch accuracy: 0.5390625\n",
      "Test accuracy: 0.54\n",
      "Loss after epoch 17:\n",
      "0.6878046989440918\n",
      "In-batch accuracy: 0.54296875\n",
      "Test accuracy: 0.44\n",
      "Loss after epoch 18:\n",
      "0.689529299736023\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.47\n",
      "Loss after epoch 19:\n",
      "0.6966528296470642\n",
      "In-batch accuracy: 0.4453125\n",
      "Test accuracy: 0.52\n",
      "Loss after epoch 20:\n",
      "0.6916654706001282\n",
      "In-batch accuracy: 0.48828125\n",
      "Test accuracy: 0.57\n",
      "Loss after epoch 21:\n",
      "0.6865478157997131\n",
      "In-batch accuracy: 0.5390625\n",
      "Test accuracy: 0.53\n",
      "Loss after epoch 22:\n",
      "0.6986483931541443\n",
      "In-batch accuracy: 0.4609375\n",
      "Test accuracy: 0.55\n",
      "Loss after epoch 23:\n",
      "0.6868459582328796\n",
      "In-batch accuracy: 0.5625\n",
      "Test accuracy: 0.52\n",
      "Loss after epoch 24:\n",
      "0.6856573224067688\n",
      "In-batch accuracy: 0.53515625\n",
      "Test accuracy: 0.47\n",
      "Loss after epoch 25:\n",
      "0.6872400045394897\n",
      "In-batch accuracy: 0.55859375\n",
      "Test accuracy: 0.54\n",
      "Loss after epoch 26:\n",
      "0.6822831630706787\n",
      "In-batch accuracy: 0.54296875\n",
      "Test accuracy: 0.53\n",
      "Loss after epoch 27:\n",
      "0.6987432837486267\n",
      "In-batch accuracy: 0.49609375\n",
      "Test accuracy: 0.58\n",
      "Loss after epoch 28:\n",
      "0.6836926937103271\n",
      "In-batch accuracy: 0.5390625\n",
      "Test accuracy: 0.49\n",
      "Loss after epoch 29:\n",
      "0.6941189169883728\n",
      "In-batch accuracy: 0.515625\n",
      "Test accuracy: 0.47\n",
      "Loss after epoch 30:\n",
      "0.6962696313858032\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.49\n",
      "Loss after epoch 31:\n",
      "0.688937783241272\n",
      "In-batch accuracy: 0.5234375\n",
      "Test accuracy: 0.48\n",
      "Loss after epoch 32:\n",
      "0.6884768009185791\n",
      "In-batch accuracy: 0.55859375\n",
      "Test accuracy: 0.52\n",
      "Loss after epoch 33:\n",
      "0.6910006999969482\n",
      "In-batch accuracy: 0.53515625\n",
      "Test accuracy: 0.5\n",
      "Loss after epoch 34:\n",
      "0.6905500292778015\n",
      "In-batch accuracy: 0.53125\n",
      "Test accuracy: 0.41\n",
      "Loss after epoch 35:\n",
      "0.6890618205070496\n",
      "In-batch accuracy: 0.5390625\n",
      "Test accuracy: 0.53\n",
      "Loss after epoch 36:\n",
      "0.6882500648498535\n",
      "In-batch accuracy: 0.546875\n",
      "Test accuracy: 0.53\n",
      "Loss after epoch 37:\n",
      "0.6897085905075073\n",
      "In-batch accuracy: 0.53515625\n",
      "Test accuracy: 0.48\n",
      "Loss after epoch 38:\n",
      "0.6932424306869507\n",
      "In-batch accuracy: 0.4765625\n",
      "Test accuracy: 0.46\n",
      "Loss after epoch 39:\n",
      "0.691840410232544\n",
      "In-batch accuracy: 0.5390625\n",
      "Test accuracy: 0.42\n",
      "Loss after epoch 40:\n",
      "0.6910285353660583\n",
      "In-batch accuracy: 0.51953125\n",
      "Test accuracy: 0.55\n",
      "Loss after epoch 41:\n",
      "0.6886300444602966\n",
      "In-batch accuracy: 0.48828125\n",
      "Test accuracy: 0.5\n",
      "Loss after epoch 42:\n",
      "0.688485860824585\n",
      "In-batch accuracy: 0.4921875\n",
      "Test accuracy: 0.43\n",
      "Loss after epoch 43:\n",
      "0.6914753913879395\n",
      "In-batch accuracy: 0.54296875\n",
      "Test accuracy: 0.46\n",
      "Loss after epoch 44:\n",
      "0.6911207437515259\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.55\n",
      "Loss after epoch 45:\n",
      "0.6956138610839844\n",
      "In-batch accuracy: 0.51171875\n",
      "Test accuracy: 0.46\n",
      "Loss after epoch 46:\n",
      "0.6856604814529419\n",
      "In-batch accuracy: 0.55859375\n",
      "Test accuracy: 0.52\n",
      "Loss after epoch 47:\n",
      "0.684741735458374\n",
      "In-batch accuracy: 0.5859375\n",
      "Test accuracy: 0.48\n",
      "Loss after epoch 48:\n",
      "0.6914011836051941\n",
      "In-batch accuracy: 0.5234375\n",
      "Test accuracy: 0.5\n",
      "Loss after epoch 49:\n",
      "0.6844643950462341\n",
      "In-batch accuracy: 0.5703125\n",
      "Test accuracy: 0.45\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "loss_f = F.cross_entropy\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    global batch_idx\n",
    "    batch_idx = 0\n",
    "    X, y = shuffle(X, y)\n",
    "    while batch_idx < len(X) - BATCH_SIZE:\n",
    "        text, label = next_batch()\n",
    "\n",
    "        label = Variable(torch.LongTensor(label).cuda()) if CUDA else Variable(torch.LongTensor(label))\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        one_hotted_text = preprocess_text(text)\n",
    "        one_hotted_text = Variable(one_hotted_text.cuda()) if CUDA else Variable(one_hotted_text)\n",
    "        one_hotted_text = one_hotted_text.permute(1, 0, 2)\n",
    "        prediction = model(one_hotted_text)\n",
    "\n",
    "        loss = loss_f(prediction, label)\n",
    "\n",
    "        writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "        loss.backward()        \n",
    "        clip_gradient(optimizer, 1e-1)\n",
    "        optimizer.step()\n",
    "\n",
    "    # evaluation\n",
    "    print('Loss after epoch %s:' % epoch)\n",
    "    print(loss.data[0])\n",
    "        \n",
    "    _, idx = torch.max(prediction, 1)\n",
    "    acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "    writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "    print('In-batch accuracy:', acc)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    test_texts, test_labels = shuffle(test_texts, test_labels)\n",
    "    \n",
    "    for t in test_texts[:TEST_SIZE]:\n",
    "\n",
    "        ptex = preprocess_text([t], batch_size=1)\n",
    "        ptex = Variable(ptex.cuda())\n",
    "        ptex = ptex.permute(1, 0, 2)\n",
    "        pred = model(ptex)\n",
    "        _, idx = torch.max(pred, 1)\n",
    "\n",
    "        predictions.append(idx.data[0])\n",
    "    \n",
    "    lables = test_labels[:TEST_SIZE]\n",
    "    \n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    print('Test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test', acc, global_step=global_step)\n",
    "\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I am a Sociologist/Anthropologist specializing in the field of Symbolic Interactionism, and I must say that this film exhibits high quality in the symbolic context throughout the entire film. To anyone who has not yet seen this, I recommend that you also read \"Man\\'s Search For Ultimate Meaning\" by Victor E. Frankl. I think you will be able to draw some amazing correlations.<br /><br />That being said, I would like to say that despite the fact that the main characters are gay, this is not a story about being gay. This is a story about seeking out and finding meaning in life, despite the difficulties and challenges, the pain and terror that stand in your way. This is a story of seeking and finding balance and wholeness and happiness.',\n",
       " 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[1], test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 93.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharRNN(\n",
       "  (rnn): LSTM(128, 256)\n",
       "  (projector): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for t in tqdm(test_texts[:1000], total=1000):\n",
    "\n",
    "    ptex = preprocess_text([t], batch_size=1)\n",
    "    ptex = Variable(ptex.cuda())\n",
    "    ptex = ptex.permute(1, 0, 2)\n",
    "    pred = model(ptex)\n",
    "    _, idx = torch.max(pred, 1)\n",
    "\n",
    "    predictions.append(idx.data[0])\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables = test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.511"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lables, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptex = preprocess_text([test_texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 32, 128])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptex.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hotted_text = preprocess_text(text)\n",
    "one_hotted_text = Variable(one_hotted_text.cuda())\n",
    "one_hotted_text = one_hotted_text.permute(1, 0, 2)\n",
    "\n",
    "pred = model(one_hotted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
