{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yoon Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random, choice\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchtext\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet from the paper\n",
    "# https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf\n",
    "ALPHABET = ['<UNK>'] + ['\\n'] + [s for s in \"\"\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}\"\"\"]\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(len(ALPHABET)))}\n",
    "\n",
    "MAX_WORD_LEN = 16  # chars in word (try 32?)\n",
    "MAX_TEXT_LEN = 256  # words in text\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать CNN на слова, нужно фиксировать длину слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HieracialIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    \"\"\"\n",
    "    Zero vector used for padding\n",
    "    \"\"\"\n",
    "    noise_level = 0\n",
    "    alphabet = ALPHABET\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(HieracialIMDB, self).__getitem__(idx)\n",
    "        _text_tensor = self.preprocess(item.text)\n",
    "\n",
    "        label = int(item.label == 'pos')\n",
    "        return _text_tensor, label\n",
    "    \n",
    "    def preprocess(self, text, with_noise=True):\n",
    "        _text_tensor = torch.zeros([MAX_WORD_LEN * MAX_TEXT_LEN, len(self.alphabet)])\n",
    "\n",
    "        for i, token in enumerate(text):\n",
    "            if i >= MAX_TEXT_LEN:\n",
    "                break\n",
    "            if with_noise:\n",
    "                token = self.noise_generator(token)\n",
    "            for j, char in enumerate(token):\n",
    "                if j >= MAX_WORD_LEN:\n",
    "                    break\n",
    "                _text_tensor[i*MAX_WORD_LEN + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
    "        return _text_tensor\n",
    "    \n",
    "#     def _encode_word(self, word):\n",
    "#         word_tensor = torch.zeros([MAX_WORD_LEN, len(ALPHABET)])\n",
    "        \n",
    "#         for i, char in enumerate(word):\n",
    "#             word_tensor[i,char2int[char]] = 1.\n",
    "        \n",
    "#         return word_tensor\n",
    "\n",
    "    def noise_generator(self, string):\n",
    "        # removed '' symbol from alphabet for safety on word vectors\n",
    "        noised = \"\"\n",
    "        for c in string:\n",
    "            if random() > self.noise_level:\n",
    "                noised += c\n",
    "            if random() < self.noise_level:\n",
    "                noised += choice(self.alphabet)\n",
    "        return noised\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def get_accuracy(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "\n",
    "    for text, label in test_dataloader:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(1, 0, 2)\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    model.train()\n",
    "    return acc\n",
    "\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None, show_pad=False):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        max_values, idx = torch.max(one_hotted_text, 1)\n",
    "        for c, i in enumerate(idx):\n",
    "            if max_values[c] == 0:\n",
    "                if show_pad:\n",
    "                    symb = '<PAD>'\n",
    "                else:\n",
    "                    symb = ''\n",
    "            else:\n",
    "                symb = ALPHABET[i]\n",
    "            text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without spacy tokenizer it's commas all after the words =(\n",
    "\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=MAX_TEXT_LEN, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    use_vocab=False#, tokenize='spacy'\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.74 s, sys: 788 ms, total: 4.53 s\n",
      "Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test = HieracialIMDB.splits(text_field, label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"thismusicalisdecidedlymixed,andnoneoftheelementsreallyfittogether,butitsomehowmanagestobemostlyenjoyable.theplotcontainssomeoftheelementsofwodehouse'snovel,butnoneofitsvirtues,thoughheco-wrotethescript.thesongs,thoughcharming,havenothingtodowiththisparticularfilm,andareunusuallycrudelysqueezedintotheplot,evenbypre-oklahomastandards.burnsandallendotheirusualshtickquitecompetently,butitmissesthetoneoftherestofthefilmbyaboutfortyiqpoints.<br/><br/>thereareafewhighpoints.reginaldgardinerdoesgoodworkwhenheremembersthatthisisatalkie,andstopsmugginglikeasilentactor.andthereareafewbitsofwritingwhichcouldonlyhavebeenwrittenbywodehouse,thoughmostofthefilmfeelsliketheproductionofoneofthehollywoodmeetingshelaterparodied.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot2text(train[0][0])  # no spaces is onehot2text problem, not a data one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, val_dataloader = get_train_valid_loader(train, VALID_SIZE, BATCH_SIZE)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статья: https://arxiv.org/abs/1508.06615\n",
    "\n",
    "Модель принципиально работает так же, но есть некоторые сильные упрощения:\n",
    "  * нету highway-слоя\n",
    "  * тут используется фильтры только одного размера (а не трёх, как в оригинальной статье)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Для RNN: (word, batch, feature)\n",
    "    CNN: (batch, word, feature)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoonKimModel(nn.Module):\n",
    "    def __init__(self, n_filters, cnn_kernel_size, hidden_dim_out,\n",
    "                 dropout=0.5, init_function=None, embedding_dim=len(ALPHABET), pool_kernel_size=MAX_WORD_LEN):\n",
    "        \"\"\"\n",
    "        Default pooling is MaxOverTime pooling\n",
    "        \"\"\"\n",
    "        assert cnn_kernel_size % 2  # for 'same' padding\n",
    "\n",
    "        super(YoonKimModel, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.init_function = init_function\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_filters = n_filters\n",
    "        self.cnn_kernel_size = cnn_kernel_size\n",
    "        self.hidden_dim_out = hidden_dim_out\n",
    "\n",
    "        self.embedding = nn.Linear(len(ALPHABET), embedding_dim)\n",
    "        self.chars_cnn = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, n_filters, kernel_size=cnn_kernel_size, stride=1, padding=int(cnn_kernel_size - 1) // 2),  # 'same' padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=pool_kernel_size)\n",
    "        )\n",
    "        if init_function is not None:\n",
    "            self.conv[0].weight = init_function(self.conv[0].weight)\n",
    "\n",
    "        _conv_stride = 1  # by default\n",
    "        _pool_stride = pool_kernel_size  # by default\n",
    "        # I am not sure this formula is always correct:\n",
    "        self.conv_dim = n_filters * max(1, int(((MAX_WORD_LEN - cnn_kernel_size) / _conv_stride - pool_kernel_size) / _pool_stride + 1))\n",
    "\n",
    "        self.words_rnn = nn.GRU(self.conv_dim, hidden_dim_out, dropout=dropout)\n",
    "        self.projector = nn.Linear(hidden_dim_out, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(1)\n",
    "        words_tensor = Variable(torch.zeros(MAX_TEXT_LEN, batch_size, self.conv_dim)).cuda()\n",
    "        # TODO: external dependency\n",
    "        if CUDA:\n",
    "            words_tensor.cuda()\n",
    "\n",
    "        for i in range(MAX_TEXT_LEN):\n",
    "            word = x[i * MAX_WORD_LEN : (i + 1) * MAX_WORD_LEN, :]\n",
    "            word = self.embedding(word)\n",
    "            word = word.permute(1, 2, 0)\n",
    "            word = self.chars_cnn(word)\n",
    "            word = word.view(word.size(0), -1)\n",
    "            words_tensor[i, :] = word\n",
    "\n",
    "        x, _ = self.words_rnn(words_tensor)\n",
    "        x = self.projector(x[-1])\n",
    "        return x\n",
    "\n",
    "#     def describe(self):\n",
    "#         return 'YoonKimModel_filters_%s_cnn_%s_pool_%s_stride_%s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, n_filters, cnn_kernel_size, hidden_dim_out, dropout=0.5,\n",
    "                   lr=1e-4, epochs=30, _model=None):\n",
    "    HieracialIMDB.noise_level = noise_level\n",
    "\n",
    "    if _model is None:\n",
    "        model = YoonKimModel(\n",
    "            n_filters=n_filters, cnn_kernel_size=cnn_kernel_size, hidden_dim_out=hidden_dim_out, dropout=dropout\n",
    "        )\n",
    "        if CUDA:\n",
    "            model.cuda()\n",
    "        model.train()\n",
    "    \n",
    "    else:\n",
    "        model = _model\n",
    "\n",
    "    writer = SummaryWriter(comment='_YoonKim_lr%s_dropout%s_noise_level%s' %\n",
    "                           (int(-np.log10(lr)), dropout, noise_level))\n",
    "\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(1, 0, 2)\n",
    "            prediction = model(text)\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        print('Epoch %s. Global step %s' % (epoch, global_step))\n",
    "        print('Loss               : %s' % loss.data[0])\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        print('In-batch accuracy  :', acc)\n",
    "\n",
    "        acc = get_accuracy(model, val_dataloader)\n",
    "        print('Validation accuracy:', acc)\n",
    "        writer.add_scalar('accuracy_val', acc, global_step=global_step)\n",
    "        print()\n",
    "\n",
    "    # Test\n",
    "\n",
    "    acc = get_accuracy(model, test_dataloader)\n",
    "    print('Final test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test_final', acc, global_step=global_step)\n",
    "    print()\n",
    "    model.eval()\n",
    "    # model is in EVAL mode!\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n",
      "adding scalar\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(\n",
    "    noise_level=0, n_filters=256, cnn_kernel_size=5, hidden_dim_out=128, dropout=0.5,\n",
    "    lr=1e-4, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нужное ненужное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataloader:\n",
    "    item = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YoonKimModel(n_filters=256, cnn_kernel_size=5, hidden_dim_out=128, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoonKimModel(\n",
       "  (embedding): Linear(in_features=74, out_features=74, bias=True)\n",
       "  (chars_cnn): Sequential(\n",
       "    (0): Conv1d(74, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=16, stride=16, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (words_rnn): GRU(256, 128, dropout=0.5)\n",
       "  (projector): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Variable(item[0].cuda()).permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Variable(torch.LongTensor(item[1])).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6893\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(model(text), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "( 0  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 1  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 2  ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       " ... \n",
       "\n",
       "( 29 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 30 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "( 31 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 32x4096x74]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(1 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(2 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "...\n",
       "\n",
       "(29,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(30,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(31,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 32x16x74]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0][:,0:MAX_WORD_LEN,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(1 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(2 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "...\n",
       "\n",
       "(29,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(30,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(31,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 32x74x16]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(item[0][0:MAX_WORD_LEN,:]).permute(0, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(1 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(2 ,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "...\n",
       "\n",
       "(29,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(30,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "\n",
       "(31,.,.) = \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "     ...       ⋱       ...    \n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "   0   0   0  ...    0   0   0\n",
       "[torch.FloatTensor of size 32x74x16]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0].permute(1, 0, 2)[0:MAX_WORD_LEN,:].permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       "  0.1022 -0.0039 -0.0890  ...   0.0393  0.1056 -0.0511\n",
       "  0.0761 -0.0932  0.0260  ...  -0.0641  0.1511 -0.0113\n",
       "  0.0657 -0.0369  0.0588  ...   0.0276  0.1004  0.1344\n",
       "           ...             ⋱             ...          \n",
       "  0.1275 -0.0825  0.1114  ...   0.0630  0.0929  0.0624\n",
       " -0.0074 -0.0157 -0.0175  ...  -0.0782  0.0081  0.0615\n",
       " -0.0074 -0.0157 -0.0175  ...  -0.0782  0.0081  0.0615\n",
       "\n",
       "(1 ,.,.) = \n",
       "  0.0255 -0.0172  0.1354  ...  -0.0489 -0.0233  0.0601\n",
       "  0.1022 -0.0039 -0.0890  ...   0.0393  0.1056 -0.0511\n",
       "  0.0827 -0.0978  0.1132  ...  -0.0385  0.0374 -0.0501\n",
       "           ...             ⋱             ...          \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0761 -0.0932  0.0260  ...  -0.0641  0.1511 -0.0113\n",
       "  0.0761 -0.0932  0.0260  ...  -0.0641  0.1511 -0.0113\n",
       "\n",
       "(2 ,.,.) = \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0857  0.0450 -0.0070  ...  -0.0097 -0.0208  0.1098\n",
       "  0.1022 -0.0039 -0.0890  ...   0.0393  0.1056 -0.0511\n",
       "           ...             ⋱             ...          \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.1275 -0.0825  0.1114  ...   0.0630  0.0929  0.0624\n",
       "  0.1275 -0.0825  0.1114  ...   0.0630  0.0929  0.0624\n",
       "...\n",
       "\n",
       "(13,.,.) = \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "           ...             ⋱             ...          \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "\n",
       "(14,.,.) = \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "           ...             ⋱             ...          \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "\n",
       "(15,.,.) = \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "           ...             ⋱             ...          \n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "  0.0824 -0.0364  0.0261  ...  -0.0096  0.0528  0.0438\n",
       "[torch.FloatTensor of size 16x32x74]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chars_cnn(model.embedding(Variable(item[0].permute(1, 0, 2)[0:MAX_WORD_LEN,:])).permute(1, 2 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "( 0 ,.,.) = \n",
       "  0.1181\n",
       "  0.0433\n",
       "  0.0000\n",
       "   ⋮    \n",
       "  0.0908\n",
       "  0.0478\n",
       "  0.1122\n",
       "\n",
       "( 1 ,.,.) = \n",
       "  0.1486\n",
       "  0.0545\n",
       "  0.0115\n",
       "   ⋮    \n",
       "  0.1511\n",
       "  0.1207\n",
       "  0.0366\n",
       "\n",
       "( 2 ,.,.) = \n",
       "  0.1427\n",
       "  0.0846\n",
       "  0.0000\n",
       "   ⋮    \n",
       "  0.1290\n",
       "  0.1473\n",
       "  0.1483\n",
       "... \n",
       "\n",
       "(29 ,.,.) = \n",
       "  0.0911\n",
       "  0.0000\n",
       "  0.0000\n",
       "   ⋮    \n",
       "  0.0569\n",
       "  0.0477\n",
       "  0.0612\n",
       "\n",
       "(30 ,.,.) = \n",
       "  0.0919\n",
       "  0.0242\n",
       "  0.0022\n",
       "   ⋮    \n",
       "  0.1367\n",
       "  0.0610\n",
       "  0.0957\n",
       "\n",
       "(31 ,.,.) = \n",
       "  0.0919\n",
       "  0.0242\n",
       "  0.0022\n",
       "   ⋮    \n",
       "  0.1367\n",
       "  0.0610\n",
       "  0.0957\n",
       "[torch.FloatTensor of size 32x256x1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.chars_cnn(\n",
    "    Variable(item[0].permute(1, 0, 2)[0:MAX_WORD_LEN,:].permute(1, 2, 0))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
