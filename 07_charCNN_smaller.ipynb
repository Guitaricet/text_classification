{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from random import random, choice\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 512\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "NOISE_LEVEL = 0.1\n",
    "\n",
    "NOISE_LEVELS = [0, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use preprocessing for noise?\n",
    "\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# remove PAD for noise function\n",
    "# use more adequate alphabet\n",
    "ALPHABET = ['<UNK>'] + ['\\n'] + [s for s in \"\"\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}\"\"\"]\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['<UNK>'])] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None, show_pad=False):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        max_values, idx = torch.max(one_hotted_text, 1)\n",
    "        for c, i in enumerate(idx):\n",
    "            if max_values[c] == 0:\n",
    "                if show_pad:\n",
    "                    symb = '<PAD>'\n",
    "                else:\n",
    "                    symb = ''\n",
    "            else:\n",
    "                symb = ALPHABET[i]\n",
    "            text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)  # это плохо\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n",
    "\n",
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_metrics(model, test_data, noise_level=None):\n",
    "    \"\"\"\n",
    "    :param test_data: dataset or dataloader\n",
    "\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "    \n",
    "    if noise_level is not None:\n",
    "        assert isinstance(test_data, torch.utils.data.DataLoader)\n",
    "        test_data.noise_level = noise_level\n",
    "    \n",
    "    elif not isinstance(test_data, torch.utils.data.DataLoader):\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=BATCH_SIZE\n",
    "        )\n",
    "    else:\n",
    "        test_dataloader = test_data\n",
    "\n",
    "    for text, label in test_dataloader:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(1, 0, 2)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    f1 = f1_score(lables, predictions)\n",
    "    model.train()\n",
    "    return {'accuracy': acc, 'f1': f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharIMDB.noise_level = 0\n",
    "train, test = CharIMDB.splits(text_field, label_field)\n",
    "\n",
    "dataloader, val_dataloader = get_train_valid_loader(\n",
    "    train, valid_size=VALID_SIZE, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this musical is decidedly mixed, and none of the elements really fit together, but it somehow manages to be mostly enjoyable. the plot contains some of the elements of wodehouse's novel, but none of its virtues, though he co-wrote the script. the songs, though charming, have nothing to do with this particular film, and are unusually crudely squeezed into the plot, even by pre-oklahoma standards. burns and allen do their usual shtick quite competently, but it misses the tone of the rest of the film by about \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot2text(train[0][0])  # no spaces is onehot2text problem, not a data one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, init_function, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.init_function = init_function\n",
    "        self.dropout = dropout\n",
    "        self.n_filters = 256\n",
    "        self.cnn_kernel_size = 15\n",
    "        self.cnn_stride = 2\n",
    "        self.pool_kernel_size = 64\n",
    "        self.pool_stride = 32\n",
    "        \n",
    "        self.embedding = nn.Linear(ALPHABET_LEN, ALPHABET_LEN)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, self.n_filters, kernel_size=self.cnn_kernel_size, stride=self.cnn_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=self.pool_kernel_size, stride=self.pool_stride)\n",
    "        )\n",
    "        self.conv[0].weight = init_function(self.conv[0].weight)\n",
    "\n",
    "        conv_dim = self.n_filters * (int(((MAXLEN-self.cnn_kernel_size) / self.cnn_stride - self.pool_kernel_size) / self.pool_stride) + 1)\n",
    "#         self._conv_dim = conv_dim  # debug\n",
    "#         print(conv_dim)\n",
    "        self.fc = nn.Linear(conv_dim, 2)  # 30464 for MAXLEN=1024, 5888 for MAXLEN=256, 14080 for MAXLEN=512\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        (seq_len, batch_size, signal_dim)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)  # fix dim\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.conv(x)\n",
    "#         print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_params_num(model):\n",
    "    return sum(np.prod(list(p.size())) for p in model.parameters())\n",
    "\n",
    "def mk_dataline(model_type, epochs, lr, noise_level_train, noise_level_test, acc_train, acc_test,\n",
    "                f1_train, f1_test, dropout, model, init_function=None):\n",
    "    return {\n",
    "        'task': 'IMDB binary classification',\n",
    "        'model_type': model_type,\n",
    "        'trainable_params': model_params_num(model), 'dropout': dropout, 'init_function': init_function,\n",
    "        'epochs': epochs, 'lr': lr,\n",
    "        'noise_level_train': noise_level_train, 'noise_level_test': noise_level_test,\n",
    "        'acc_train': acc_train, 'acc_test': acc_test,\n",
    "        'f1_train': f1_train, 'f1_test': f1_test,\n",
    "        'model_desc': str(model),\n",
    "        'data_desc': 'Maxlen 512'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, init_function, lr=1e-4, dropout=0.5, epochs=30, _model=None):\n",
    "    start_time = time()\n",
    "    CharIMDB.noise_level = noise_level\n",
    "\n",
    "    if _model is None:\n",
    "        model = CharCNN(\n",
    "            init_function=init_function, dropout=dropout\n",
    "        )\n",
    "        if CUDA:\n",
    "            model.cuda()\n",
    "        model.train()\n",
    "    \n",
    "    else:\n",
    "        model = _model\n",
    "\n",
    "    model_name = '_charCNN_embed_smaller2_lr%s_noise%s_dropout%s' % (\n",
    "        int(-np.log10(lr)), noise_level, dropout\n",
    "    )\n",
    "\n",
    "    writer = SummaryWriter(comment=)\n",
    "    print('Writer: %s' % list(writer.all_writers.keys()))\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(1, 0, 2)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch %s. Global step %s. T=%s min' % (epoch, global_step, (time() - start_time) / 60.))\n",
    "            print('Loss               : %s' % loss.data[0])\n",
    "\n",
    "        # in-batch\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        _labels = label.data.tolist()\n",
    "        _predictions = idx.data.tolist()\n",
    "        acc = accuracy_score(_labels, _predictions)\n",
    "        f1 = f1_score(_labels, _predictions)\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        writer.add_scalar('f1_train', f1, global_step=global_step)\n",
    "        if epoch % 10 == 0:\n",
    "            print('In-batch accuracy  :', acc)\n",
    "\n",
    "        # validation\n",
    "        metrics = get_metrics(model, val_dataloader)\n",
    "        if epoch % 10 == 0:\n",
    "            print('Validation accuracy: %s, f1: %s' % (metrics['accuracy'], metrics['f1']))\n",
    "            print()\n",
    "\n",
    "        writer.add_scalar('accuracy_val', metrics['accuracy'], global_step=global_step)\n",
    "        writer.add_scalar('f1_val', metrics['f1'], global_step=global_step)\n",
    "\n",
    "    # Test\n",
    "    metrics_test = None\n",
    "\n",
    "    print('Calculating validation metrics... Time %s min' % ((time() - start_time) / 60.))\n",
    "    metrics_train = get_metrics_from_dataloader(model, dataloader)\n",
    "    acc_train = metrics_train['accuracy']\n",
    "    f1_train = metrics_train['f1']\n",
    "\n",
    "    for test_noise in NOISE_LEVELS:\n",
    "        metrics = get_metrics_from_dataset(model, test, test_noise)\n",
    "        if test_noise == noise_level:\n",
    "            metrics_test = metrics\n",
    "\n",
    "        acc_test = metrics['accuracy']\n",
    "        f1_test = metrics['f1']\n",
    "        results.append(mk_dataline(\n",
    "            model_type='charCNN', epochs=epochs, lr=lr,\n",
    "            noise_level_train=noise_level, acc_train=acc_train, f1_train=f1_train,\n",
    "            noise_level_test=test_noise, acc_test=acc_test, f1_test=f1_test,\n",
    "            dropout=dropout, model=model,\n",
    "            init_function=init_function\n",
    "        ))\n",
    "\n",
    "    print('Final test metrics: %s, Time %s min' % (metrics_test, ((time() - start_time) / 60.)))\n",
    "    if metrics_test is not None:\n",
    "        writer.add_scalar('accuracy_test_final', metrics_test['accuracy'], global_step=global_step)\n",
    "        writer.add_scalar('f1_test_final', metrics_test['f1'], global_step=global_step)\n",
    "    print()\n",
    "    model.eval()\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Global step 704. T=0.1436752398808797 min\n",
      "Loss               : 0.6803672313690186\n",
      "In-batch accuracy  : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.512, f1: 0.061538461538461535\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1542007724444072 min\n",
      "Loss               : 0.23422397673130035\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7436, f1: 0.75599543205177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20. Global step 14784. T=2.1592104117075603 min\n",
      "Loss               : 0.013622313737869263\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7332, f1: 0.7106290672451193\n",
      "\n",
      "Calculating validation metrics... Time 3.076084923744202 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [05:15<47:17, 315.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'f1': 0.7376722695769934, 'accuracy': 0.73656}, Time 5.255144357681274 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.14133394956588746 min\n",
      "Loss               : 0.7314321994781494\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.508, f1: 0.6693548387096774\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.3562750816345215 min\n",
      "Loss               : 0.22567851841449738\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7432, f1: 0.7092391304347827\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.437349478403727 min\n",
      "Loss               : 0.10743339359760284\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7676, f1: 0.762953896368829\n",
      "\n",
      "Calculating validation metrics... Time 3.448778168360392 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [10:48<43:12, 324.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.54760464032491 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.0907844622929891 min\n",
      "Loss               : 0.6932111978530884\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5532, f1: 0.6781907231345433\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1276414434115092 min\n",
      "Loss               : 0.4192439913749695\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7496, f1: 0.7517842981760507\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.176605765024821 min\n",
      "Loss               : 0.24921046197414398\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7652, f1: 0.7583367641004527\n",
      "\n",
      "Calculating validation metrics... Time 3.1391729354858398 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [16:01<37:22, 320.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.217387167612712 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09537695248921713 min\n",
      "Loss               : 0.6874804496765137\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.6132, f1: 0.5883354618986802\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1471372763315837 min\n",
      "Loss               : 0.3565017580986023\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7444, f1: 0.737792367665162\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.2060555458068847 min\n",
      "Loss               : 0.27578625082969666\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7548, f1: 0.7615713730066123\n",
      "\n",
      "Calculating validation metrics... Time 3.176018941402435 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [21:17<31:56, 319.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.27445619503657 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09673238595326741 min\n",
      "Loss               : 0.6823359131813049\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5204, f1: 0.12926652142338416\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1470781882603964 min\n",
      "Loss               : 0.06243807077407837\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7524, f1: 0.7618314736437091\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.2017578721046447 min\n",
      "Loss               : 0.2650335729122162\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7612, f1: 0.7534076827757126\n",
      "\n",
      "Calculating validation metrics... Time 3.1687230110168456 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [26:35<26:35, 319.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.289030599594116 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09391260147094727 min\n",
      "Loss               : 0.70283043384552\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5024, f1: 0.0048000000000000004\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1467703143755594 min\n",
      "Loss               : 0.4105784595012665\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.762, f1: 0.7637951568082572\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.194654281934102 min\n",
      "Loss               : 0.1121649369597435\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.752, f1: 0.7199638663053297\n",
      "\n",
      "Calculating validation metrics... Time 3.165289080142975 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [31:53<21:15, 318.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.302026172478993 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09194004535675049 min\n",
      "Loss               : 0.6559637188911438\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.5588, f1: 0.6731851851851852\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.147641658782959 min\n",
      "Loss               : 0.27374106645584106\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7448, f1: 0.763001485884101\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.209592616558075 min\n",
      "Loss               : 0.2525128126144409\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7668, f1: 0.7833519137866963\n",
      "\n",
      "Calculating validation metrics... Time 3.181969145933787 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [37:11<15:56, 318.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.302956835428874 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09604016939798991 min\n",
      "Loss               : 0.7281623482704163\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.6008, f1: 0.6815571155073389\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.156672199567159 min\n",
      "Loss               : 0.5288417339324951\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7516, f1: 0.7678504672897195\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.2299110293388367 min\n",
      "Loss               : 0.15664401650428772\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.766, f1: 0.7692307692307693\n",
      "\n",
      "Calculating validation metrics... Time 3.201933662096659 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [42:31<10:37, 318.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.331070137023926 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09274621407190958 min\n",
      "Loss               : 0.6521236300468445\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.518, f1: 0.11201179071481208\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1543944160143533 min\n",
      "Loss               : 0.9379855394363403\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.7452, f1: 0.7308829742289819\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.2232012271881105 min\n",
      "Loss               : 0.4122418761253357\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7528, f1: 0.7306015693112466\n",
      "\n",
      "Calculating validation metrics... Time 3.1914063771565755 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [47:48<05:18, 318.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.280966401100159 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09717000325520833 min\n",
      "Loss               : 0.7716481685638428\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.4988, f1: 0.6655991459834534\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.176574718952179 min\n",
      "Loss               : 0.2566969096660614\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7124, f1: 0.6463354648303001\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.2474002043406167 min\n",
      "Loss               : 0.19343164563179016\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.77, f1: 0.7689835275210929\n",
      "\n",
      "Calculating validation metrics... Time 3.21843079328537 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [53:06<00:00, 318.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: None, Time 5.309645819664001 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# searching for phase transition\n",
    "\n",
    "for noise_level in tqdm(np.arange(0, .01, 0.001)):\n",
    "    run_model_with(noise_level=noise_level, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Global step 704. T=0.09757444063822428 min\n",
      "Loss               : 0.6833441853523254\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.594, f1: 0.6644628099173554\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10. Global step 7744. T=1.0710898200670878 min\n",
      "Loss               : 0.3576161563396454\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7436, f1: 0.725010725010725\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.0572694261868794 min\n",
      "Loss               : 0.1215888112783432\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.74, f1: 0.7207903780068728\n",
      "\n",
      "Calculating validation metrics... Time 2.9548836310704547 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [05:02<45:25, 302.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.73676, 'f1': 0.7368547322963732}, Time 5.047053643067678 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.08685567378997802 min\n",
      "Loss               : 0.6945825815200806\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5936, f1: 0.6788874841972187\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.0606398701667785 min\n",
      "Loss               : 0.9090694189071655\n",
      "In-batch accuracy  : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7456, f1: 0.7170818505338079\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.0351781884829205 min\n",
      "Loss               : 0.9719800353050232\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7704, f1: 0.774548311076198\n",
      "\n",
      "Calculating validation metrics... Time 2.9230235616366067 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [10:04<40:17, 302.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.7544, 'f1': 0.7788343779266623}, Time 5.027114776770274 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.08835642337799073 min\n",
      "Loss               : 0.6829354763031006\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5132, f1: 0.6695628563670921\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.0660610636075338 min\n",
      "Loss               : 1.0264668464660645\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.7284, f1: 0.7064418504107219\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.046401325861613 min\n",
      "Loss               : 0.23428675532341003\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7544, f1: 0.7688253012048194\n",
      "\n",
      "Calculating validation metrics... Time 2.931548313299815 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [15:06<35:15, 302.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.75008, 'f1': 0.7710013194546254}, Time 5.033909809589386 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.08631937503814698 min\n",
      "Loss               : 0.6909242868423462\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5112, f1: 0.6693722943722944\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.083217167854309 min\n",
      "Loss               : 0.3939869999885559\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7104, f1: 0.7457865168539326\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.0790613214174907 min\n",
      "Loss               : 0.3692682981491089\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7464, f1: 0.7416462917685411\n",
      "\n",
      "Calculating validation metrics... Time 2.9949778079986573 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [20:12<30:18, 303.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.74996, 'f1': 0.7519739713526168}, Time 5.100250689188639 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09309595028559367 min\n",
      "Loss               : 0.7203581929206848\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.5096, f1: 0.6686486486486486\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1207369367281597 min\n",
      "Loss               : 0.7041387557983398\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6788, f1: 0.6100048567265663\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.13401597738266 min\n",
      "Loss               : 0.3560851514339447\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7144, f1: 0.677797833935018\n",
      "\n",
      "Calculating validation metrics... Time 3.0663119554519653 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [25:22<25:22, 304.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.73496, 'f1': 0.7482714079477243}, Time 5.170687929789225 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.0915231982866923 min\n",
      "Loss               : 0.7024847269058228\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5128, f1: 0.08558558558558559\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1404865423838297 min\n",
      "Loss               : 0.394155889749527\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6812, f1: 0.7227826086956521\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.1909544388453166 min\n",
      "Loss               : 0.8203105926513672\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.7056, f1: 0.6626947754353805\n",
      "\n",
      "Calculating validation metrics... Time 3.150494122505188 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [30:38<20:25, 306.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.7244, 'f1': 0.73599509540961}, Time 5.25678657690684 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.09529105424880982 min\n",
      "Loss               : 0.6908730268478394\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.4988, f1: 0.6655991459834534\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.1661256869633994 min\n",
      "Loss               : 0.6972641944885254\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6656, f1: 0.6620856911883589\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.235698322455088 min\n",
      "Loss               : 0.6497185826301575\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6992, f1: 0.6845637583892618\n",
      "\n",
      "Calculating validation metrics... Time 3.2094284256299335 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [35:57<15:24, 308.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.70756, 'f1': 0.729992244340215}, Time 5.3249284783999125 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.0985660990079244 min\n",
      "Loss               : 0.7428643107414246\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.5096, f1: 0.08370702541106129\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.2230181296666462 min\n",
      "Loss               : 0.7159014940261841\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.6468, f1: 0.5860290670417253\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.3315184394518536 min\n",
      "Loss               : 0.6266547441482544\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.696, f1: 0.6657871591908532\n",
      "\n",
      "Calculating validation metrics... Time 3.3505717277526856 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [41:25<10:21, 310.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.70232, 'f1': 0.703080114905841}, Time 5.46062300602595 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.1013597846031189 min\n",
      "Loss               : 0.6744129061698914\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.4988, f1: 0.6655991459834534\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.241614584128062 min\n",
      "Loss               : 0.5243411660194397\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6204, f1: 0.5044386422976501\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.3675535559654235 min\n",
      "Loss               : 0.31338781118392944\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6856, f1: 0.712719298245614\n",
      "\n",
      "Calculating validation metrics... Time 3.446236224969228 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [46:58<05:13, 313.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.6814, 'f1': 0.6337425851841634}, Time 5.556990742683411 min\n",
      "\n",
      "Epoch 0. Global step 704. T=0.10616544882456462 min\n",
      "Loss               : 0.7120844125747681\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.5092, f1: 0.09312638580931264\n",
      "\n",
      "Epoch 10. Global step 7744. T=1.304196302096049 min\n",
      "Loss               : 0.5625705718994141\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.6392, f1: 0.6015901060070671\n",
      "\n",
      "Epoch 20. Global step 14784. T=2.4941790223121645 min\n",
      "Loss               : 0.6240410208702087\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6772, f1: 0.6783579115185332\n",
      "\n",
      "Calculating validation metrics... Time 3.575537435213725 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [52:41<00:00, 316.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.68192, 'f1': 0.6674194897532414}, Time 5.715057114760081 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for noise_level in tqdm(NOISE_LEVELS):\n",
    "    run_model_with(noise_level=noise_level, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('results/CharCNN_embed2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6670222878456116\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5112\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6755492091178894\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5172\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.699364960193634\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5364\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.6891615390777588\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6676\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.5262390375137329\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7088\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.41326266527175903\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7372\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.5759977102279663\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7484\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.4313564896583557\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.746\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.5776655673980713\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7544\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.3323601484298706\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7712\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.3805471658706665\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.3446338176727295\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7784\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.15464019775390625\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7656\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1888725757598877\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7876\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.1652103066444397\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7864\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.2724268436431885\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7964\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.6561002731323242\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7836\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.19407756626605988\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7792\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.8851348161697388\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.6685544848442078\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7936\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.06143583357334137\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.78\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.3794499337673187\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7744\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.3443407416343689\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7984\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.2735293507575989\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7892\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.1365838497877121\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7888\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.6129616498947144\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7968\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.10170719027519226\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8036\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.22721727192401886\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7992\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.38628992438316345\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.555729329586029\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8004\n",
      "\n",
      "Final test accuracy: 0.79904\n",
      "\n",
      "CPU times: user 7min 50s, sys: 3min 13s, total: 11min 4s\n",
      "Wall time: 11min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=61184, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.1, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7154096364974976\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6276\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3147427439689636\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.43052104115486145\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7732\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.14214535057544708\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8052\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.16783644258975983\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8112\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.5878106951713562\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.82\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.1835513859987259\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.036214977502822876\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8056\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.036427706480026245\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.09720713645219803\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8232\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.027575135231018066\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.06920866668224335\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.015279620885848999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.032747477293014526\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8172\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.02133116126060486\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.0014932751655578613\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0026256442070007324\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.00022476911544799805\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "1.52587890625e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8168\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "3.4570693969726562e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.828\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "4.4465065002441406e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00014007091522216797\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.812\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "4.76837158203125e-07\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8216\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "2.7179718017578125e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8252\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.005523800849914551\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.792\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "1.800060272216797e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "3.933906555175781e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.818\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00014293193817138672\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.11518393456935883\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Final test accuracy: 0.77836\n",
      "\n",
      "CPU times: user 5min 50s, sys: 2min 26s, total: 8min 17s\n",
      "Wall time: 8min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=30464, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.785068154335022\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.6084\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3312198519706726\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7292\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.2843222916126251\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.1944502741098404\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7604\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.24288120865821838\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8008\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.36140114068984985\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8036\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.2669448256492615\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8048\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.18363156914710999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.48155519366264343\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.47901251912117004\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.802\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.03075912594795227\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.822\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.2517656683921814\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.08778958022594452\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1717863380908966\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8276\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.14468592405319214\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.013375252485275269\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8308\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.07788994908332825\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.005857408046722412\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8136\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.10116563737392426\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8044\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.01556655764579773\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.01607152819633484\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8204\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00832277536392212\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.826\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.036525875329971313\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8268\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.00587010383605957\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.0029016733169555664\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8284\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.012174874544143677\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8124\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.02179431915283203\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8156\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00522458553314209\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0005469918251037598\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8316\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0004094839096069336\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8324\n",
      "\n",
      "Final test accuracy: 0.82348\n",
      "\n",
      "CPU times: user 3min 42s, sys: 1min 33s, total: 5min 15s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=30464, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.8411439657211304\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.5809738636016846\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.66\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.4452686309814453\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6824\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.23656554520130157\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7136\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.5787070393562317\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.502457857131958\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.12519408762454987\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.731816291809082\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.736\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.12233468890190125\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.09430167078971863\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7312\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.09161564707756042\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.734\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.08762294054031372\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7312\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.105124831199646\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7328\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.0444985032081604\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7316\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.09123039245605469\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7304\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.06530529260635376\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.03109598159790039\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7328\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.004562437534332275\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.010403096675872803\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7324\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.006136536598205566\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.017438173294067383\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.004397451877593994\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.0013630986213684082\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.0010037422180175781\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.000855863094329834\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.0008487105369567871\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7264\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.0002518296241760254\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.0006242990493774414\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7264\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.00048047304153442383\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.000341951847076416\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Final test accuracy: 0.70608\n",
      "\n",
      "CPU times: user 1min 20s, sys: 32.3 s, total: 1min 53s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7073005437850952\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6404\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.5612970590591431\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7176\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.9215638637542725\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7228\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.3698350191116333\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.584014356136322\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7556\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.19489029049873352\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.758\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.41615644097328186\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7776\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.2622656226158142\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7752\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.16676472127437592\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7824\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.051940202713012695\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.75\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.11029338836669922\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7792\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.025028765201568604\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7872\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.028858810663223267\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.784\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.0239579975605011\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7716\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.029768288135528564\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7836\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.003383457660675049\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0065698325634002686\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7804\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.005014777183532715\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7788\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.0012508034706115723\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.018134474754333496\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.782\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.0017946362495422363\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7828\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.0020844340324401855\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7832\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.0012060999870300293\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.0019055008888244629\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7784\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "8.893013000488281e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7816\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.00021791458129882812\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7832\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "8.130073547363281e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00023221969604492188\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7828\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.00013083219528198242\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7816\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.00019437074661254883\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.78\n",
      "\n",
      "Final test accuracy: 0.77552\n",
      "\n",
      "CPU times: user 2min 4s, sys: 52.9 s, total: 2min 57s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    text = preprocess_text_nobatch(text)\n",
    "    text = text.unsqueeze(0).permute(0, 2, 1)\n",
    "    text = Variable(text.cuda())\n",
    "    prediction = model(text)\n",
    "    _, prediction = torch.max(prediction, 1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I hate it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I have seen this film as I was a child and it was awersome! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'Love it! Love it!  Love it! Love it! Love it! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"Maybe just long enough text if really suficcient so let's write something neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"We need more emotions! Like when film is cool you are so happy to rank it 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"So only long texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is not good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is very good for tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то такое себе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить на малой длине (140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.70023113489151\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5332\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.7055613398551941\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6228\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.46998968720436096\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6316\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.7275577783584595\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6564\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.33533045649528503\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6628\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.6466774940490723\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.3631550967693329\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6668\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.3672349154949188\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6776\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.18997327983379364\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6776\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.45411497354507446\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.682\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.12608222663402557\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.688\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.32205089926719666\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6888\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.3059559464454651\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6888\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1519184708595276\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6704\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.11397160589694977\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.676\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.22693216800689697\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6872\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.2246621549129486\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6816\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.046780407428741455\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.684\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.07688425481319427\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6784\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.0199909508228302\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.68\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.027406424283981323\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.68\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.038487911224365234\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6752\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.013645201921463013\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6736\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.04285439848899841\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6764\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.011004775762557983\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6756\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.004669070243835449\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.003603041172027588\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6744\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00252532958984375\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6788\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0018059015274047852\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0011753439903259277\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6724\n",
      "\n",
      "Final test accuracy: 0.65416\n",
      "\n",
      "CPU times: user 1min 1s, sys: 21.5 s, total: 1min 22s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I hate it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I have seen this film as I was a child and it was awersome! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'Love it! Love it!  Love it! Love it! Love it! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"Maybe just long enough text if really suficcient so let's write something neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"We need more emotions! Like when film is cool you are so happy to rank it 10\") # Изменилось с 1 на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"So only long texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is not good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is very good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, alphabet=None, noise_level=0, maxlen=512):\n",
    "        \"\"\"\n",
    "        :param dataframe: pandas dataframe with fields \"text\": str and \"label\": int\n",
    "        \"\"\"\n",
    "        if alphabet is None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            self.alphabet = alphabet\n",
    "        self.char2int = {s: i for s, i in zip(self.alphabet, range(len(self.alphabet)))}\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "        self.dataframe = dataframe\n",
    "        self.noise_level = noise_level\n",
    "        if self.noise_level > 0:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        line = self.dataframe.iloc[idx]\n",
    "        text = self._preprocess_text_nobatch(line.text)\n",
    "        label = line.label\n",
    "        return text, label\n",
    "\n",
    "    def _noise_generator(string):\n",
    "        noised = \"\"\n",
    "        for c in string:\n",
    "            if random() > self.noise_level:\n",
    "                noised += c\n",
    "            if random() < self.noise_level:\n",
    "                noised += choice(self.alphabet)\n",
    "        return noised\n",
    "\n",
    "    def _one_hot(self, char):\n",
    "        zeros = np.zeros(len(self.alphabet))\n",
    "        if char in self.char2int:\n",
    "            zeros[self.char2int[char]] = 1.\n",
    "        else:\n",
    "            zeros[self.char2int['UNK']] = 1.\n",
    "\n",
    "    def _preprocess_text_nobatch(self, text):\n",
    "        one_hotted_text = np.zeros((self.maxlen, len(self.alphabet)))\n",
    "        for i, char in enumerate(text):\n",
    "            if i >= self.maxlen:\n",
    "                break\n",
    "            one_hotted_text[i, self.char2int.get(char, self.char2int['UNK'])] = 1.\n",
    "        if i < self.maxlen:\n",
    "            for j in range(i+1, self.maxlen):\n",
    "                one_hotted_text[j, self.char2int['PAD']] = 1.\n",
    "\n",
    "        return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "    def onehot2text(self, one_hotted_text):\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = self.alphabet[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('/media/data/nlp/data/twitter_sentiment/twitter_sentiment_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282205</th>\n",
       "      <td>294537</td>\n",
       "      <td>294549</td>\n",
       "      <td>1</td>\n",
       "      <td>@julianna12369 Hon those two tweets together w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  ItemID  Sentiment  \\\n",
       "282205      294537  294549          1   \n",
       "\n",
       "                                            SentimentText  \n",
       "282205  @julianna12369 Hon those two tweets together w...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.columns = ['idxx', 'ItemID', 'label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_ds = OneHotDataset(twitter_df, alphabet=ALPHABET, maxlen=140)\n",
    "twitter_dl = torch.utils.data.DataLoader(twitter_ds, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 s, sys: 13.8 s, total: 46.8 s\n",
      "Wall time: 48.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5117747288379131"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# MAXLEN 512\n",
    "get_accuracy(model, twitter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 4.83 s, total: 19.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5006580369517948"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# MAXLEN 140\n",
    "get_accuracy(model, twitter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
