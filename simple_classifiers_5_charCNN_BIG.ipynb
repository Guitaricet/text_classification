{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from random import random, choice\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 1024\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 100\n",
    "\n",
    "NOISE_LEVEL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# train, test = torchtext.datasets.IMDB.splits(text_field, label_field)\n",
    "# c = Counter(''.join([' '.join(t.text_field) for t in train]))\n",
    "# ALPHABET = [char[0] for char in c.most_common(62)]  # all other chars used less ~ 100 times in a test\n",
    "# ALPHABET.append('UNK')\n",
    "# ALPHABET.append('PAD')\n",
    "ALPHABET = [' ', 'e', 't', 'a', 'i', 'o', 's', 'n', 'r', 'h', 'l', 'd', 'c', 'm', 'u', 'f', 'g', 'y', 'b', 'w', 'p',\\\n",
    "            '.', 'v', ',', 'k', \"'\", '/', '>', '<', '-', '\"', 'j', 'x', ')', '(', '!', 'z', 'q', '0', '1', '?', ':',\\\n",
    "            '9', '2', '*', ';', '3', '5', '8', '4', '7', '&', '6', 'Ã©', '\\x96', '`', '$', '\\x85', '_', '%', '=', '#',\\\n",
    "            'UNK', 'PAD']\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['UNK'])] = 1.\n",
    "    if i < MAXLEN:\n",
    "        for j in range(i+1, MAXLEN):\n",
    "            one_hotted_text[j, char2int['PAD']] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = ALPHABET[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n",
    "\n",
    "CharIMDB.noise_level = NOISE_LEVEL\n",
    "train, test = CharIMDB.splits(text_field, label_field)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        super(CharCNN, self).__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )               \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )   \n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8704, 1024),  # MAXLEN = 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(1024, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        # collapse\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # linear layer\n",
    "        x = self.fc1(x)\n",
    "        # linear layer\n",
    "        x = self.fc2(x)\n",
    "        # linear layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "#     def describe(self):\n",
    "#         return '_char_cnn_%s_%s' % (self.hidden_dim, self.kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOISE_LEVEL = 0\n",
    "CharIMDB.noise_level = NOISE_LEVEL\n",
    "\n",
    "model = CharCNN()\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='_charCNN_BIG_lr4_noise%s' % NOISE_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=10**-4)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "0.6992976665496826\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.45\n",
      "\n",
      "Loss after epoch 1:\n",
      "0.7079662084579468\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.68\n",
      "\n",
      "Loss after epoch 2:\n",
      "0.7390520572662354\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 3:\n",
      "0.20012804865837097\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.78\n",
      "\n",
      "Loss after epoch 4:\n",
      "0.228943333029747\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.87\n",
      "\n",
      "Loss after epoch 5:\n",
      "0.17180489003658295\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 6:\n",
      "0.20836986601352692\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.86\n",
      "\n",
      "Loss after epoch 7:\n",
      "0.2620856463909149\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.83\n",
      "\n",
      "Loss after epoch 8:\n",
      "0.09418275207281113\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 9:\n",
      "0.020548567175865173\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.86\n",
      "\n",
      "Loss after epoch 10:\n",
      "0.08662045001983643\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.76\n",
      "\n",
      "Loss after epoch 11:\n",
      "0.41919851303100586\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.86\n",
      "\n",
      "Loss after epoch 12:\n",
      "0.1615152209997177\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.81\n",
      "\n",
      "Loss after epoch 13:\n",
      "0.07587540149688721\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.75\n",
      "\n",
      "Loss after epoch 14:\n",
      "0.0017323791980743408\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Loss after epoch 15:\n",
      "0.505725622177124\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.68\n",
      "\n",
      "Loss after epoch 16:\n",
      "0.9245200157165527\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.81\n",
      "\n",
      "Loss after epoch 17:\n",
      "0.26276957988739014\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.81\n",
      "\n",
      "Loss after epoch 18:\n",
      "1.1920928955078125e-07\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Loss after epoch 19:\n",
      "0.001771688461303711\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 20:\n",
      "4.018335342407227\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.78\n",
      "\n",
      "Loss after epoch 21:\n",
      "4.297494888305664e-05\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 22:\n",
      "1.7285346984863281e-06\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.64\n",
      "\n",
      "Loss after epoch 23:\n",
      "7.033348083496094e-06\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 24:\n",
      "0.0001176595687866211\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.87\n",
      "\n",
      "Loss after epoch 25:\n",
      "0.015783414244651794\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.72\n",
      "\n",
      "Loss after epoch 26:\n",
      "0.0717228502035141\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.87\n",
      "\n",
      "Loss after epoch 27:\n",
      "2.562999725341797e-06\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.83\n",
      "\n",
      "Loss after epoch 28:\n",
      "1.2218952178955078e-05\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.78\n",
      "\n",
      "Loss after epoch 29:\n",
      "2.6941299438476562e-05\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.75\n",
      "\n",
      "CPU times: user 5min 21s, sys: 1min 56s, total: 7min 18s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_EPOCHS = 30\n",
    "\n",
    "loss_f = F.cross_entropy\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "#     if epoch == 10:\n",
    "#         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "    for batch_idx, (text, label) in enumerate(dataloader):\n",
    "\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "            label = Variable(torch.LongTensor(label).cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "            label = Variable(torch.LongTensor(label))\n",
    "\n",
    "        text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        loss = loss_f(prediction, label)\n",
    "\n",
    "        writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "        global_step += 1\n",
    "\n",
    "    # evaluation\n",
    "    print('Loss after epoch %s:' % epoch)\n",
    "    print(loss.data[0])\n",
    "        \n",
    "    _, idx = torch.max(prediction, 1)\n",
    "    acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "    writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "    print('In-batch accuracy:', acc)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "\n",
    "    for i in np.random.choice(range(25000), TEST_SIZE, replace=False):\n",
    "        _test = test[i]\n",
    "    #     test_texts.append(_test[0])\n",
    "    #     test_labels.append(_test[1])\n",
    "        _text = _test[0].unsqueeze(0).permute(0, 2, 1)\n",
    "        _text = Variable(_text.cuda()) if CUDA else Variable(_text)\n",
    "        lables.append(_test[1])\n",
    "        pred = model(_text)\n",
    "        _, idx = torch.max(pred, 1)\n",
    "        predictions.append(idx.data[0])\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    print('Test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test', acc, global_step=global_step)\n",
    "    print()\n",
    "    model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, lr=1e-4, dropout=0.5, epochs=30):\n",
    "    CharIMDB.noise_level = noise_level\n",
    "\n",
    "    model = CharCNN()\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    writer = SummaryWriter(comment='_charCNN_BIG_lr%s_noise%s_dropout%s' % (\n",
    "        int(-np.log10(lr)), noise_level, dropout\n",
    "    ))\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    #     if epoch == 10:\n",
    "    #         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        print('Loss after epoch %s:' % epoch)\n",
    "        print(loss.data[0])\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        print('In-batch accuracy:', acc)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        predictions = []\n",
    "        lables = []\n",
    "\n",
    "        for i in np.random.choice(range(25000), TEST_SIZE, replace=False):\n",
    "            _test = test[i]\n",
    "        #     test_texts.append(_test[0])\n",
    "        #     test_labels.append(_test[1])\n",
    "            _text = _test[0].unsqueeze(0).permute(0, 2, 1)\n",
    "            _text = Variable(_text.cuda()) if CUDA else Variable(_text)\n",
    "            lables.append(_test[1])\n",
    "            pred = model(_text)\n",
    "            _, idx = torch.max(pred, 1)\n",
    "            predictions.append(idx.data[0])\n",
    "\n",
    "        acc = accuracy_score(lables, predictions)\n",
    "        print('Test accuracy:', acc)\n",
    "        writer.add_scalar('accuracy_test', acc, global_step=global_step)\n",
    "        print()\n",
    "        model.train()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        _test = test[i]\n",
    "        _text = _test[0].unsqueeze(0).permute(0, 2, 1)\n",
    "        _text = Variable(_text.cuda()) if CUDA else Variable(_text)\n",
    "        lables.append(_test[1])\n",
    "        pred = model(_text)\n",
    "        _, idx = torch.max(pred, 1)\n",
    "        predictions.append(idx.data[0])\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    print('Final test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test', acc, global_step=global_step)\n",
    "    print()\n",
    "\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "0.693831205368042\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.45\n",
      "\n",
      "Loss after epoch 1:\n",
      "0.693220853805542\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.52\n",
      "\n",
      "Loss after epoch 2:\n",
      "0.694312334060669\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 3:\n",
      "0.6909643411636353\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.57\n",
      "\n",
      "Loss after epoch 4:\n",
      "0.6980196833610535\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.56\n",
      "\n",
      "Loss after epoch 5:\n",
      "0.6982015371322632\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.59\n",
      "\n",
      "Loss after epoch 6:\n",
      "0.6916560530662537\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.49\n",
      "\n",
      "Loss after epoch 7:\n",
      "0.6996750831604004\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.46\n",
      "\n",
      "Loss after epoch 8:\n",
      "0.6863850951194763\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.54\n",
      "\n",
      "Loss after epoch 9:\n",
      "0.6915104389190674\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 10:\n",
      "0.6835496425628662\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 11:\n",
      "0.6930607557296753\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.46\n",
      "\n",
      "Loss after epoch 12:\n",
      "0.6909423470497131\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.52\n",
      "\n",
      "Loss after epoch 13:\n",
      "0.6991958022117615\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Loss after epoch 14:\n",
      "0.7016175389289856\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.53\n",
      "\n",
      "Loss after epoch 15:\n",
      "0.6905828714370728\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.49\n",
      "\n",
      "Loss after epoch 16:\n",
      "0.7027257680892944\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.41\n",
      "\n",
      "Loss after epoch 17:\n",
      "0.6927698254585266\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.57\n",
      "\n",
      "Loss after epoch 18:\n",
      "0.7026633620262146\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.51\n",
      "\n",
      "Loss after epoch 19:\n",
      "0.6902344822883606\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.41\n",
      "\n",
      "Loss after epoch 20:\n",
      "0.6958439350128174\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.53\n",
      "\n",
      "Loss after epoch 21:\n",
      "0.693027913570404\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.61\n",
      "\n",
      "Loss after epoch 22:\n",
      "0.6982631683349609\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.52\n",
      "\n",
      "Loss after epoch 23:\n",
      "0.6969308853149414\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Loss after epoch 24:\n",
      "0.6928228735923767\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.51\n",
      "\n",
      "Loss after epoch 25:\n",
      "0.6945222616195679\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.57\n",
      "\n",
      "Loss after epoch 26:\n",
      "0.6930099129676819\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 27:\n",
      "0.6889662742614746\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 28:\n",
      "0.6913330554962158\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.59\n",
      "\n",
      "Loss after epoch 29:\n",
      "0.6887921094894409\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.54\n",
      "\n",
      "CPU times: user 5min 22s, sys: 1min 56s, total: 7min 19s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "0.6855185627937317\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 1:\n",
      "0.6913802623748779\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.49\n",
      "\n",
      "Loss after epoch 2:\n",
      "0.6922506093978882\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 3:\n",
      "0.6922696828842163\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 4:\n",
      "0.6893981695175171\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.51\n",
      "\n",
      "Loss after epoch 5:\n",
      "0.697161078453064\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 6:\n",
      "0.7012726068496704\n",
      "In-batch accuracy: 0.125\n",
      "Test accuracy: 0.53\n",
      "\n",
      "Loss after epoch 7:\n",
      "0.6930920481681824\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 8:\n",
      "0.6983960866928101\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 9:\n",
      "0.6918072700500488\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.48\n",
      "\n",
      "Loss after epoch 10:\n",
      "0.6950687170028687\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Loss after epoch 11:\n",
      "0.6959728002548218\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.54\n",
      "\n",
      "Loss after epoch 12:\n",
      "0.6826980113983154\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.55\n",
      "\n",
      "Loss after epoch 13:\n",
      "0.6958651542663574\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.46\n",
      "\n",
      "Loss after epoch 14:\n",
      "0.6924486756324768\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 15:\n",
      "0.6932474970817566\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.54\n",
      "\n",
      "Loss after epoch 16:\n",
      "0.6951637268066406\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.45\n",
      "\n",
      "Loss after epoch 17:\n",
      "0.6786683797836304\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.49\n",
      "\n",
      "Loss after epoch 18:\n",
      "0.6946345567703247\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.42\n",
      "\n",
      "Loss after epoch 19:\n",
      "0.6952676177024841\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 20:\n",
      "0.7035115361213684\n",
      "In-batch accuracy: 0.125\n",
      "Test accuracy: 0.52\n",
      "\n",
      "Loss after epoch 21:\n",
      "0.6989914774894714\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.46\n",
      "\n",
      "Loss after epoch 22:\n",
      "0.686728835105896\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 23:\n",
      "0.6970359683036804\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 24:\n",
      "0.697765588760376\n",
      "In-batch accuracy: 0.375\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 25:\n",
      "0.6912617683410645\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.62\n",
      "\n",
      "Loss after epoch 26:\n",
      "0.7038959264755249\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.43\n",
      "\n",
      "Loss after epoch 27:\n",
      "0.6951285004615784\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.52\n",
      "\n",
      "Loss after epoch 28:\n",
      "0.6927995681762695\n",
      "In-batch accuracy: 0.25\n",
      "Test accuracy: 0.47\n",
      "\n",
      "Loss after epoch 29:\n",
      "0.6860821843147278\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.53\n",
      "\n",
      "CPU times: user 5min 21s, sys: 2min, total: 7min 22s\n",
      "Wall time: 7min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "0.6988425254821777\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n",
      "Loss after epoch 1:\n",
      "0.7124646902084351\n",
      "In-batch accuracy: 0.5\n",
      "Test accuracy: 0.51\n",
      "\n",
      "Loss after epoch 2:\n",
      "0.5418098568916321\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Loss after epoch 3:\n",
      "0.4217878580093384\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 4:\n",
      "0.5336219668388367\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.7\n",
      "\n",
      "Loss after epoch 5:\n",
      "0.31769514083862305\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.73\n",
      "\n",
      "Loss after epoch 6:\n",
      "0.39250969886779785\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.83\n",
      "\n",
      "Loss after epoch 7:\n",
      "1.3161165714263916\n",
      "In-batch accuracy: 0.625\n",
      "Test accuracy: 0.76\n",
      "\n",
      "Loss after epoch 8:\n",
      "0.7381945848464966\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.83\n",
      "\n",
      "Loss after epoch 9:\n",
      "0.5788499116897583\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 10:\n",
      "0.08647662401199341\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 11:\n",
      "0.47070184350013733\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 12:\n",
      "0.11531414836645126\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Loss after epoch 13:\n",
      "0.4934667646884918\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.79\n",
      "\n",
      "Loss after epoch 14:\n",
      "0.43125736713409424\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Loss after epoch 15:\n",
      "0.3325360417366028\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Loss after epoch 16:\n",
      "0.09307573735713959\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 17:\n",
      "0.02536875009536743\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Loss after epoch 18:\n",
      "0.12328758090734482\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.86\n",
      "\n",
      "Loss after epoch 19:\n",
      "0.06742612272500992\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.77\n",
      "\n",
      "Loss after epoch 20:\n",
      "0.37218737602233887\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.87\n",
      "\n",
      "Loss after epoch 21:\n",
      "0.046948276460170746\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.87\n",
      "\n",
      "Loss after epoch 22:\n",
      "0.2966395318508148\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.78\n",
      "\n",
      "Loss after epoch 23:\n",
      "0.029672160744667053\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.83\n",
      "\n",
      "Loss after epoch 24:\n",
      "0.015298783779144287\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.85\n",
      "\n",
      "Loss after epoch 25:\n",
      "0.3507829010486603\n",
      "In-batch accuracy: 0.75\n",
      "Test accuracy: 0.82\n",
      "\n",
      "Loss after epoch 26:\n",
      "0.09255168586969376\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.84\n",
      "\n",
      "Loss after epoch 27:\n",
      "0.10408401489257812\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Loss after epoch 28:\n",
      "0.16074180603027344\n",
      "In-batch accuracy: 0.875\n",
      "Test accuracy: 0.86\n",
      "\n",
      "Loss after epoch 29:\n",
      "0.003489762544631958\n",
      "In-batch accuracy: 1.0\n",
      "Test accuracy: 0.82\n",
      "\n",
      "CPU times: user 5min 20s, sys: 2min, total: 7min 21s\n",
      "Wall time: 7min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
