{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from random import random, choice\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 1024\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "NOISE_LEVEL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# train, test = torchtext.datasets.IMDB.splits(text_field, label_field)\n",
    "# c = Counter(''.join([' '.join(t.text_field) for t in train]))\n",
    "# ALPHABET = [char[0] for char in c.most_common(62)]  # all other chars used less ~ 100 times in a test\n",
    "# ALPHABET.append('UNK')\n",
    "# ALPHABET.append('PAD')\n",
    "ALPHABET = [' ', 'e', 't', 'a', 'i', 'o', 's', 'n', 'r', 'h', 'l', 'd', 'c', 'm', 'u', 'f', 'g', 'y', 'b', 'w', 'p',\\\n",
    "            '.', 'v', ',', 'k', \"'\", '/', '>', '<', '-', '\"', 'j', 'x', ')', '(', '!', 'z', 'q', '0', '1', '?', ':',\\\n",
    "            '9', '2', '*', ';', '3', '5', '8', '4', '7', '&', '6', 'Ã©', '\\x96', '`', '$', '\\x85', '_', '%', '=', '#',\\\n",
    "            'UNK', 'PAD']\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['UNK'])] = 1.\n",
    "    if i < MAXLEN:\n",
    "        for j in range(i+1, MAXLEN):\n",
    "            one_hotted_text[j, char2int['PAD']] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = ALPHABET[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n",
    "\n",
    "CharIMDB.noise_level = NOISE_LEVEL\n",
    "train, test = CharIMDB.splits(text_field, label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader, val_dataloader = get_train_valid_loader(train, valid_size=VALID_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "\n",
    "    for text, label in test_dataset:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    model.train()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        super(CharCNN, self).__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )               \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )   \n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8704, 1024),  # MAXLEN = 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(1024, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        # collapse\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # linear layer\n",
    "        x = self.fc1(x)\n",
    "        # linear layer\n",
    "        x = self.fc2(x)\n",
    "        # linear layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "#     def describe(self):\n",
    "#         return '_char_cnn_%s_%s' % (self.hidden_dim, self.kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use run_model_with() instead this and training cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CharCNN()\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='_charCNN_BIG_lr4_noise%s_zero_grad' % NOISE_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(params=model.parameters(), lr=10**-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 7899\n",
      "0.05113282799720764\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 7978\n",
      "0.016985535621643066\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 8057\n",
      "0.42285072803497314\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 8136\n",
      "0.0152968168258667\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 8215\n",
      "0.006434261798858643\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 8294\n",
      "0.002848982810974121\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 8373\n",
      "0.04190392792224884\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 8452\n",
      "0.037236496806144714\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 8531\n",
      "0.09192997217178345\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 8610\n",
      "0.02971579134464264\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "CPU times: user 11.1 s, sys: 4.46 s, total: 15.6 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "loss_f = F.cross_entropy\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "#     if epoch == 10:\n",
    "#         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "    for batch_idx, (text, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "            label = Variable(torch.LongTensor(label).cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "            label = Variable(torch.LongTensor(label))\n",
    "\n",
    "        text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        loss = loss_f(prediction, label)\n",
    "\n",
    "        writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "        loss.backward()        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if CUDA:\n",
    "            torch.cuda.synchronize()\n",
    "        global_step += 1\n",
    "\n",
    "    # evaluation\n",
    "    print('Loss after epoch %s:' % epoch)\n",
    "    print('Global step: %s' % global_step)\n",
    "    print(loss.data[0])\n",
    "        \n",
    "    _, idx = torch.max(prediction, 1)\n",
    "    acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "    writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "    print('In-batch accuracy:', acc)\n",
    "\n",
    "    acc = get_accuracy(model, val_dataloader)\n",
    "    print('Validation accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_val', acc, global_step=global_step)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, lr=1e-4, dropout=0.5, epochs=30):\n",
    "    CharIMDB.noise_level = noise_level\n",
    "\n",
    "    model = CharCNN()\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    writer = SummaryWriter(comment='_charCNN_BIG_lr%s_noise%s_dropout%s_zero_grad' % (\n",
    "        int(-np.log10(lr)), noise_level, dropout\n",
    "    ))\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    #     if epoch == 10:\n",
    "    #         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        print('Loss after epoch %s:' % epoch)\n",
    "        print('Global step: %s' % global_step)\n",
    "        print(loss.data[0])\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        print('In-batch accuracy:', acc)\n",
    "\n",
    "        acc = get_accuracy(model, val_dataloader)\n",
    "        print('Validation accuracy:', acc)\n",
    "        writer.add_scalar('accuracy_val', acc, global_step=global_step)\n",
    "        print()\n",
    "\n",
    "    # Test\n",
    "\n",
    "    acc = get_accuracy(model, test_dataloader)\n",
    "    print('Final test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test_final', acc, global_step=global_step)\n",
    "    print()\n",
    "    model.eval()\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6904901266098022\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.7936182618141174\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.546\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.1952720582485199\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7572\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.5716578960418701\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7536\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.11316552758216858\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7936\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.2017299085855484\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.73\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.15417367219924927\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "1.2359867095947266\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7636\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.05472905933856964\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8068\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.032090961933135986\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8304\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.3187016546726227\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8256\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.07609929144382477\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.9025777578353882\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7448\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.14018456637859344\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8368\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.0032097697257995605\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8032\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.11359363794326782\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7896\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.17665620148181915\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.022224217653274536\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7428\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "1.4445987939834595\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6968\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.01966884732246399\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8108\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.044057637453079224\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8284\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.05015754699707031\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8256\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "3.9577484130859375e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8068\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "8.58306884765625e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8032\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "2.0265579223632812e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.824\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.022364050149917603\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8268\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "4.470348358154297e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8108\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "4.76837158203125e-07\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7672\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8196\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8316\n",
      "\n",
      "Final test accuracy: 0.81992\n",
      "\n",
      "CPU times: user 5min 33s, sys: 1min 57s, total: 7min 30s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6878147721290588\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.516\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.8137348294258118\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6368\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.4973318576812744\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7356\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.4195626676082611\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.754\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.6425861716270447\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.74\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.2816354036331177\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6772\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.20363134145736694\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.81\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.3277105391025543\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.762\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.2784428000450134\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6584\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.7423917055130005\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.3060608506202698\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.826\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.24945464730262756\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8324\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.05421966314315796\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8252\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.7132287621498108\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7492\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.17511194944381714\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8288\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.2466750144958496\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8292\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.04834270477294922\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8304\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.007305920124053955\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8332\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.9723018407821655\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8304\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.027651041746139526\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8256\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.1440512090921402\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8276\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.016360044479370117\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.774\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.5761013031005859\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8288\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.0018280744552612305\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8368\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.24785444140434265\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8408\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.2326948642730713\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7708\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.3225924074649811\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8192\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.004845023155212402\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.802\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.031513869762420654\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8356\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.04111725091934204\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Final test accuracy: 0.82636\n",
      "\n",
      "CPU times: user 5min 22s, sys: 1min 58s, total: 7min 20s\n",
      "Wall time: 7min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.690359354019165\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6226386427879333\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6264\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.30313509702682495\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.674\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.5101810693740845\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6656\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.8623838424682617\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7488\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "1.0181388854980469\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7688\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.13517919182777405\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7764\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.18683569133281708\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7752\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.44805753231048584\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8028\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.4592766761779785\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7052\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.2656686305999756\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7408\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.5802521109580994\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8108\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.2564764618873596\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.794\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.40323132276535034\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8144\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.4162025451660156\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.792\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.101860910654068\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8084\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0912260115146637\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8264\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.05840544402599335\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.806\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.13114947080612183\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8104\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.4556550979614258\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8256\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.037987276911735535\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8124\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.1401858627796173\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.832\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.07586954534053802\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8272\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.16867902874946594\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.09082506597042084\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.766\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.18219171464443207\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8264\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.4827604591846466\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8264\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.049702972173690796\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.826\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.04900871217250824\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8312\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.6591789722442627\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.8216\n",
      "\n",
      "Final test accuracy: 0.82828\n",
      "\n",
      "CPU times: user 5min 24s, sys: 1min 56s, total: 7min 21s\n",
      "Wall time: 7min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7387385964393616\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.5136\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6903369426727295\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5236\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.45277178287506104\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.602\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.8454218506813049\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5852\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.30889207124710083\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7324\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.578527569770813\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.738\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.28894734382629395\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7784\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.1560816615819931\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7648\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.27122265100479126\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7492\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.21013277769088745\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8008\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.18492548167705536\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7484\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.052552878856658936\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7244\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.0658174455165863\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.722\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.43509793281555176\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.798\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.07163600623607635\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7976\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.5195640325546265\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8144\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.5360977649688721\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.051629841327667236\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8272\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.7115954160690308\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.33579307794570923\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.7920107841491699\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.818\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.40126559138298035\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.828\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.04134446382522583\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.02883058786392212\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8108\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "1.1860005855560303\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8288\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.11563722789287567\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8216\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.7231330275535583\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.45991235971450806\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8292\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.6047413349151611\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8096\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.2541255056858063\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.832\n",
      "\n",
      "Final test accuracy: 0.83036\n",
      "\n",
      "CPU times: user 5min 24s, sys: 1min 56s, total: 7min 21s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6977649331092834\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6940438151359558\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.695360541343689\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.6921966671943665\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.6927817463874817\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.6933063268661499\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.6916301250457764\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.6964783072471619\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.6885600090026855\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.6984038352966309\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.690052330493927\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.6919317841529846\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.6923553943634033\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.6949230432510376\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.6834208965301514\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.6872274279594421\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.6901277303695679\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.6924545168876648\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.6887795925140381\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.6941399574279785\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.6890177726745605\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.6906525492668152\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.6889071464538574\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.6938627362251282\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.6900492906570435\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.6886663436889648\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.6879659295082092\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.6884937286376953\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.6937386393547058\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.6953108310699463\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Final test accuracy: 0.5\n",
      "\n",
      "CPU times: user 5min 26s, sys: 1min 56s, total: 7min 23s\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6951391100883484\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6784296631813049\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5004\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.7228308320045471\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5044\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.7211583256721497\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5988\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.5820444226264954\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6224\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.6386209726333618\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7028\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.8176125288009644\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7052\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.6912543773651123\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7224\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.49356338381767273\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7244\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.5802894830703735\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7652\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.3906420171260834\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.75\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.18091297149658203\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7628\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "1.0413846969604492\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7348\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.11860665678977966\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.794\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.19768913090229034\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.788\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.37259092926979065\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7872\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.12854774296283722\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7764\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.8373459577560425\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7856\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.238074392080307\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7944\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.057415157556533813\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.786\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.4103859066963196\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8032\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.7683334946632385\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7356\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.1189490258693695\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8048\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.6829365491867065\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7668\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.17398445308208466\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8084\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.2563667893409729\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.792\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.3589767813682556\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.722\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.9169814586639404\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8044\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.4723195433616638\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8108\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.33775919675827026\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8176\n",
      "\n",
      "Final test accuracy: 0.81656\n",
      "\n",
      "CPU times: user 5min 26s, sys: 1min 57s, total: 7min 24s\n",
      "Wall time: 7min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6949774622917175\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.516\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6756817102432251\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.4976\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.6862725019454956\n",
      "In-batch accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = run_model_with(noise_level=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__int__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_advanced_index_add',\n",
       " '_backward_hooks',\n",
       " '_execution_engine',\n",
       " '_fallthrough_methods',\n",
       " '_get_type',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_torch',\n",
       " '_unnarrow',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'all',\n",
       " 'any',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bmm',\n",
       " 'btrifact',\n",
       " 'btrisolve',\n",
       " 'byte',\n",
       " 'cat',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clone',\n",
       " 'contiguous',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'diag',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'eig',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'fill_',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'gels',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'gesv',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'histc',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_select',\n",
       " 'int',\n",
       " 'inverse',\n",
       " 'is_contiguous',\n",
       " 'is_leaf',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'kthvalue',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'long',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'masked_copy',\n",
       " 'masked_copy_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'narrow',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'numel',\n",
       " 'ones_like',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'potrf',\n",
       " 'potri',\n",
       " 'potrs',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prod',\n",
       " 'pstrf',\n",
       " 'put_',\n",
       " 'qr',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'renorm',\n",
       " 'repeat',\n",
       " 'requires_grad',\n",
       " 'resize',\n",
       " 'resize_as',\n",
       " 'retain_grad',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'std',\n",
       " 'storage_offset',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trtrs',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unfold',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'volatile',\n",
       " 'zero_',\n",
       " 'zeros_like']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.conv1[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.xavier_normal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
