{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18 15:32 summarizer.preprocessing.cleaner INFO     'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cfg\n",
    "\n",
    "from text_classification import trainutils\n",
    "from text_classification.layers import *\n",
    "from text_classification.logger import logger\n",
    "from text_classification.datautils import *\n",
    "from text_classification.trainutils import get_metrics\n",
    "\n",
    "from train import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '../data/mokoron/' # '../data/airline_tweets_binary/' # \n",
    "text_filed = 'text_spellchecked'\n",
    "text_original_field = 'text_original'\n",
    "label_field = 'sentiment' # 'airline_sentiment'\n",
    "\n",
    "alphabet = cfg.alphabet + cfg.russian_chars\n",
    "alphabet = [c for c in alphabet if c not in ('(', ')')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoonKim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = HierarchicalMokoron(\n",
    "    basepath + 'train.csv', text_filed, label_field, alphabet=alphabet, max_text_len=128)\n",
    "valid_data = HierarchicalMokoron(\n",
    "    basepath + 'validation.csv', text_filed, label_field, alphabet=alphabet, max_text_len=128)\n",
    "test_data = HierarchicalMokoron(\n",
    "    basepath + 'test.csv', text_filed, label_field, alphabet=alphabet, max_text_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data = train_data.data.sample(1024)\n",
    "valid_data.data = valid_data.data.sample(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(\n",
    "        train_data, test_data, validset=valid_data, batch_size=cfg.train.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18 15:32 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 35, 'dropout': 0, 'alphabet_len': 104, 'lr': 0.0001}\n",
      "07-18 15:32 root         INFO     Writer: runs/Jul18_15-32-53_lyalin_YoonKimModel_lr4_dropout0_noise_level0.0000hyperparameters_search_manual\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fa0c7bb6f4d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_manual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0msave_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           use_annealing=False)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# TODO: use embedding lookup instead of one-hot vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "n_filters = 32\n",
    "cnn_kernel_size = 5\n",
    "dropout = 0#.5\n",
    "hidden_dim_out = 64\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "    'alphabet_len': len(alphabet)\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=50,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None,\n",
    "          use_annealing=False)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, acc: %s, parameters: %s' % (\n",
    "        metrics['f1'], metrics['acc'], str(params)\n",
    "    ))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18 11:46 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 11:46 root         INFO     Set the model into eval mode\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics = get_metrics(trained_model, test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8123543123543123, 'f1': 0.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 32\n",
    "cnn_kernel_size = 5\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 64\n",
    "embedding_dim = 64\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "    'alphabet_len': len(alphabet)\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=10,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, acc: %s, parameters: %s' % (\n",
    "        metrics['f1'], metrics['acc'], str(params)\n",
    "    ))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-17 17:19 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.6548361219888224, 'alphabet_len': 104, 'lr': 0.00023854348792259845}\n",
      "07-17 17:19 root         INFO     Writer: runs/Jul17_17-19-16_lyalin_YoonKimModel_lr3_dropout0.6548361219888224_noise_level0.0000hyperparameters_search_random\n",
      "07-17 17:25 root         INFO     Epoch 0. Global step 4757. T=6.04min\n",
      "07-17 17:25 root         INFO     In-batch loss      : 0.6973\n",
      "07-17 17:25 root         INFO     Training accuracy  : 0.5084, f1: 0.6741\n",
      "07-17 17:25 root         INFO     Validation accuracy: 0.5070, f1: 0.6728\n",
      "07-17 17:37 root         INFO     Epoch 2. Global step 14271. T=17.77min\n",
      "07-17 17:37 root         INFO     In-batch loss      : 0.6951\n",
      "07-17 17:37 root         INFO     Training accuracy  : 0.5100, f1: 0.6755\n",
      "07-17 17:37 root         INFO     Validation accuracy: 0.5080, f1: 0.6737\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f1aa4665f28>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError: \n",
      "07-17 17:48 root         INFO     Epoch 4. Global step 23785. T=29.50min\n",
      "07-17 17:48 root         INFO     In-batch loss      : 0.7020\n",
      "07-17 17:48 root         INFO     Training accuracy  : 0.5026, f1: 0.6690\n",
      "07-17 17:48 root         INFO     Validation accuracy: 0.5062, f1: 0.6722\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f1aa4665f28>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 732, in answer_challenge\n",
      "    message = connection.recv_bytes(256)         # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 383, in _recv\n",
      "    raise EOFError\n",
      "EOFError: \n",
      "07-17 18:00 root         INFO     Epoch 6. Global step 33299. T=41.25min\n",
      "07-17 18:00 root         INFO     In-batch loss      : 0.6948\n",
      "07-17 18:00 root         INFO     Training accuracy  : 0.5013, f1: 0.6678\n",
      "07-17 18:00 root         INFO     Validation accuracy: 0.4996, f1: 0.6663\n",
      "07-17 18:12 root         INFO     Epoch 8. Global step 42813. T=52.87min\n",
      "07-17 18:12 root         INFO     In-batch loss      : 0.6956\n",
      "07-17 18:12 root         INFO     Training accuracy  : 0.5071, f1: 0.6729\n",
      "07-17 18:12 root         INFO     Validation accuracy: 0.5168, f1: 0.6814\n",
      "07-17 18:17 root         INFO     Epoch 9. Global step 47570. T=58.57min\n",
      "07-17 18:17 root         INFO     In-batch loss      : 0.6963\n",
      "07-17 18:17 root         INFO     Training accuracy  : 0.5025, f1: 0.6689\n",
      "07-17 18:17 root         INFO     Validation accuracy: 0.5115, f1: 0.6768\n",
      "07-17 18:17 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 18:17 root         INFO     Set the model into eval mode\n",
      "07-17 18:18 root         INFO     YES!, f1: 0.6736610955227522, parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.6548361219888224, 'alphabet_len': 104, 'lr': 0.00023854348792259845}\n",
      "07-17 18:18 root         INFO     {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.6548361219888224, 'alphabet_len': 104, 'lr': 0.00023854348792259845}\n",
      "07-17 18:18 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 64, 'embedding_dim': 64, 'dropout': 0.9664404360558677, 'alphabet_len': 104, 'lr': 0.00011891438531047106}\n",
      "07-17 18:18 root         INFO     Writer: runs/Jul17_18-18-24_lyalin_YoonKimModel_lr3_dropout0.9664404360558677_noise_level0.0000hyperparameters_search_random\n",
      "07-17 18:24 root         INFO     Epoch 0. Global step 4757. T=6.10min\n",
      "07-17 18:24 root         INFO     In-batch loss      : 0.6989\n",
      "07-17 18:24 root         INFO     Training accuracy  : 0.5049, f1: 0.6710\n",
      "07-17 18:24 root         INFO     Validation accuracy: 0.5108, f1: 0.6762\n",
      "07-17 18:36 root         INFO     Epoch 2. Global step 14271. T=18.27min\n",
      "07-17 18:36 root         INFO     In-batch loss      : 0.6930\n",
      "07-17 18:36 root         INFO     Training accuracy  : 0.5106, f1: 0.6761\n",
      "07-17 18:36 root         INFO     Validation accuracy: 0.5109, f1: 0.6763\n",
      "07-17 18:48 root         INFO     Epoch 4. Global step 23785. T=30.39min\n",
      "07-17 18:48 root         INFO     In-batch loss      : 0.6884\n",
      "07-17 18:48 root         INFO     Training accuracy  : 0.5123, f1: 0.6775\n",
      "07-17 18:48 root         INFO     Validation accuracy: 0.4868, f1: 0.6548\n",
      "07-17 19:00 root         INFO     Epoch 6. Global step 33299. T=42.53min\n",
      "07-17 19:00 root         INFO     In-batch loss      : 0.6958\n",
      "07-17 19:00 root         INFO     Training accuracy  : 0.5173, f1: 0.6819\n",
      "07-17 19:00 root         INFO     Validation accuracy: 0.5140, f1: 0.6790\n",
      "07-17 19:13 root         INFO     Epoch 8. Global step 42813. T=54.67min\n",
      "07-17 19:13 root         INFO     In-batch loss      : 0.6898\n",
      "07-17 19:13 root         INFO     Training accuracy  : 0.5041, f1: 0.6703\n",
      "07-17 19:13 root         INFO     Validation accuracy: 0.5088, f1: 0.6745\n",
      "07-17 19:19 root         INFO     Epoch 9. Global step 47570. T=60.74min\n",
      "07-17 19:19 root         INFO     In-batch loss      : 0.6846\n",
      "07-17 19:19 root         INFO     Training accuracy  : 0.5018, f1: 0.6683\n",
      "07-17 19:19 root         INFO     Validation accuracy: 0.5029, f1: 0.6693\n",
      "07-17 19:19 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 19:19 root         INFO     Set the model into eval mode\n",
      "07-17 19:19 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 128, 'embedding_dim': 64, 'dropout': 0.20502518380196375, 'alphabet_len': 104, 'lr': 0.0004521995755792399}\n",
      "07-17 19:19 root         INFO     Writer: runs/Jul17_19-19-43_lyalin_YoonKimModel_lr3_dropout0.20502518380196375_noise_level0.0000hyperparameters_search_random\n",
      "07-17 19:25 root         INFO     Epoch 0. Global step 4757. T=5.67min\n",
      "07-17 19:25 root         INFO     In-batch loss      : 0.6938\n",
      "07-17 19:25 root         INFO     Training accuracy  : 0.5018, f1: 0.6683\n",
      "07-17 19:25 root         INFO     Validation accuracy: 0.5150, f1: 0.6798\n",
      "07-17 19:36 root         INFO     Epoch 2. Global step 14271. T=17.01min\n",
      "07-17 19:36 root         INFO     In-batch loss      : 0.6963\n",
      "07-17 19:36 root         INFO     Training accuracy  : 0.5077, f1: 0.6735\n",
      "07-17 19:36 root         INFO     Validation accuracy: 0.5069, f1: 0.6727\n",
      "07-17 19:48 root         INFO     Epoch 4. Global step 23785. T=28.36min\n",
      "07-17 19:48 root         INFO     In-batch loss      : 0.6929\n",
      "07-17 19:48 root         INFO     Training accuracy  : 0.5020, f1: 0.6684\n",
      "07-17 19:48 root         INFO     Validation accuracy: 0.5067, f1: 0.6726\n",
      "07-17 19:59 root         INFO     Epoch 6. Global step 33299. T=39.71min\n",
      "07-17 19:59 root         INFO     In-batch loss      : 0.6949\n",
      "07-17 19:59 root         INFO     Training accuracy  : 0.5035, f1: 0.6698\n",
      "07-17 19:59 root         INFO     Validation accuracy: 0.5113, f1: 0.6766\n",
      "07-17 20:10 root         INFO     Epoch 8. Global step 42813. T=51.05min\n",
      "07-17 20:10 root         INFO     In-batch loss      : 0.6927\n",
      "07-17 20:10 root         INFO     Training accuracy  : 0.5053, f1: 0.6713\n",
      "07-17 20:10 root         INFO     Validation accuracy: 0.5201, f1: 0.6843\n",
      "07-17 20:16 root         INFO     Epoch 9. Global step 47570. T=56.71min\n",
      "07-17 20:16 root         INFO     In-batch loss      : 0.6888\n",
      "07-17 20:16 root         INFO     Training accuracy  : 0.5126, f1: 0.6778\n",
      "07-17 20:16 root         INFO     Validation accuracy: 0.5098, f1: 0.6753\n",
      "07-17 20:16 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 20:16 root         INFO     Set the model into eval mode\n",
      "07-17 20:17 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 128, 'embedding_dim': 32, 'dropout': 0.23587890031251094, 'alphabet_len': 104, 'lr': 0.0005261899283538675}\n",
      "07-17 20:17 root         INFO     Writer: runs/Jul17_20-17-00_lyalin_YoonKimModel_lr3_dropout0.23587890031251094_noise_level0.0000hyperparameters_search_random\n",
      "07-17 20:22 root         INFO     Epoch 0. Global step 4757. T=5.71min\n",
      "07-17 20:22 root         INFO     In-batch loss      : 0.6927\n",
      "07-17 20:22 root         INFO     Training accuracy  : 0.4991, f1: 0.6658\n",
      "07-17 20:22 root         INFO     Validation accuracy: 0.5150, f1: 0.6798\n",
      "07-17 20:34 root         INFO     Epoch 2. Global step 14271. T=17.11min\n",
      "07-17 20:34 root         INFO     In-batch loss      : 0.7004\n",
      "07-17 20:34 root         INFO     Training accuracy  : 0.4986, f1: 0.6654\n",
      "07-17 20:34 root         INFO     Validation accuracy: 0.5020, f1: 0.6684\n",
      "07-17 20:45 root         INFO     Epoch 4. Global step 23785. T=28.50min\n",
      "07-17 20:45 root         INFO     In-batch loss      : 0.6982\n",
      "07-17 20:45 root         INFO     Training accuracy  : 0.5007, f1: 0.6672\n",
      "07-17 20:45 root         INFO     Validation accuracy: 0.4966, f1: 0.6636\n",
      "07-17 20:56 root         INFO     Epoch 6. Global step 33299. T=39.90min\n",
      "07-17 20:56 root         INFO     In-batch loss      : 0.6893\n",
      "07-17 20:56 root         INFO     Training accuracy  : 0.5076, f1: 0.6734\n",
      "07-17 20:56 root         INFO     Validation accuracy: 0.5105, f1: 0.6760\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f1a11433898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/reduction.py\", line 153, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "07-17 21:08 root         INFO     Epoch 8. Global step 42813. T=51.34min\n",
      "07-17 21:08 root         INFO     In-batch loss      : 0.6942\n",
      "07-17 21:08 root         INFO     Training accuracy  : 0.5122, f1: 0.6774\n",
      "07-17 21:08 root         INFO     Validation accuracy: 0.5102, f1: 0.6756\n",
      "07-17 21:14 root         INFO     Epoch 9. Global step 47570. T=57.05min\n",
      "07-17 21:14 root         INFO     In-batch loss      : 0.6905\n",
      "07-17 21:14 root         INFO     Training accuracy  : 0.5093, f1: 0.6749\n",
      "07-17 21:14 root         INFO     Validation accuracy: 0.5039, f1: 0.6701\n",
      "07-17 21:14 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 21:14 root         INFO     Set the model into eval mode\n",
      "07-17 21:14 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.8447996379645887, 'alphabet_len': 104, 'lr': 0.0007275374021455765}\n",
      "07-17 21:14 root         INFO     Writer: runs/Jul17_21-14-37_lyalin_YoonKimModel_lr3_dropout0.8447996379645887_noise_level0.0000hyperparameters_search_random\n",
      "07-17 21:20 root         INFO     Epoch 0. Global step 4757. T=6.03min\n",
      "07-17 21:20 root         INFO     In-batch loss      : 0.6790\n",
      "07-17 21:20 root         INFO     Training accuracy  : 0.5047, f1: 0.6709\n",
      "07-17 21:20 root         INFO     Validation accuracy: 0.4958, f1: 0.6630\n",
      "07-17 21:32 root         INFO     Epoch 2. Global step 14271. T=18.11min\n",
      "07-17 21:32 root         INFO     In-batch loss      : 0.6957\n",
      "07-17 21:32 root         INFO     Training accuracy  : 0.5177, f1: 0.6822\n",
      "07-17 21:32 root         INFO     Validation accuracy: 0.5065, f1: 0.6724\n",
      "07-17 21:44 root         INFO     Epoch 4. Global step 23785. T=30.20min\n",
      "07-17 21:44 root         INFO     In-batch loss      : 0.6975\n",
      "07-17 21:44 root         INFO     Training accuracy  : 0.5106, f1: 0.6761\n",
      "07-17 21:44 root         INFO     Validation accuracy: 0.5127, f1: 0.6779\n",
      "07-17 21:56 root         INFO     Epoch 6. Global step 33299. T=42.30min\n",
      "07-17 21:56 root         INFO     In-batch loss      : 0.6877\n",
      "07-17 21:56 root         INFO     Training accuracy  : 0.5092, f1: 0.6748\n",
      "07-17 21:56 root         INFO     Validation accuracy: 0.5121, f1: 0.6774\n",
      "07-17 22:09 root         INFO     Epoch 8. Global step 42813. T=54.38min\n",
      "07-17 22:09 root         INFO     In-batch loss      : 0.6929\n",
      "07-17 22:09 root         INFO     Training accuracy  : 0.5104, f1: 0.6758\n",
      "07-17 22:09 root         INFO     Validation accuracy: 0.5078, f1: 0.6736\n",
      "07-17 22:15 root         INFO     Epoch 9. Global step 47570. T=60.41min\n",
      "07-17 22:15 root         INFO     In-batch loss      : 0.3477\n",
      "07-17 22:15 root         INFO     Training accuracy  : 0.7818, f1: 0.7809\n",
      "07-17 22:15 root         INFO     Validation accuracy: 0.7722, f1: 0.7733\n",
      "07-17 22:15 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 22:15 root         INFO     Set the model into eval mode\n",
      "07-17 22:15 root         INFO     YES!, f1: 0.7762320781711363, parameters: {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.8447996379645887, 'alphabet_len': 104, 'lr': 0.0007275374021455765}\n",
      "07-17 22:15 root         INFO     {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.8447996379645887, 'alphabet_len': 104, 'lr': 0.0007275374021455765}\n",
      "07-17 22:15 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.9974407124103818, 'alphabet_len': 104, 'lr': 0.0001433808074444301}\n",
      "07-17 22:15 root         INFO     Writer: runs/Jul17_22-15-37_lyalin_YoonKimModel_lr3_dropout0.9974407124103818_noise_level0.0000hyperparameters_search_random\n",
      "07-17 22:21 root         INFO     Epoch 0. Global step 4757. T=5.60min\n",
      "07-17 22:21 root         INFO     In-batch loss      : 0.6672\n",
      "07-17 22:21 root         INFO     Training accuracy  : 0.5095, f1: 0.6750\n",
      "07-17 22:21 root         INFO     Validation accuracy: 0.5075, f1: 0.6733\n",
      "07-17 22:32 root         INFO     Epoch 2. Global step 14271. T=16.83min\n",
      "07-17 22:32 root         INFO     In-batch loss      : 0.6911\n",
      "07-17 22:32 root         INFO     Training accuracy  : 0.5084, f1: 0.6741\n",
      "07-17 22:32 root         INFO     Validation accuracy: 0.5102, f1: 0.6756\n",
      "07-17 22:43 root         INFO     Epoch 4. Global step 23785. T=28.05min\n",
      "07-17 22:43 root         INFO     In-batch loss      : 0.6984\n",
      "07-17 22:43 root         INFO     Training accuracy  : 0.5142, f1: 0.6792\n",
      "07-17 22:43 root         INFO     Validation accuracy: 0.5119, f1: 0.6772\n",
      "07-17 22:54 root         INFO     Epoch 6. Global step 33299. T=39.27min\n",
      "07-17 22:54 root         INFO     In-batch loss      : 0.7025\n",
      "07-17 22:54 root         INFO     Training accuracy  : 0.5076, f1: 0.6734\n",
      "07-17 22:54 root         INFO     Validation accuracy: 0.5038, f1: 0.6700\n",
      "07-17 23:06 root         INFO     Epoch 8. Global step 42813. T=50.49min\n",
      "07-17 23:06 root         INFO     In-batch loss      : 0.6814\n",
      "07-17 23:06 root         INFO     Training accuracy  : 0.5156, f1: 0.6804\n",
      "07-17 23:06 root         INFO     Validation accuracy: 0.5119, f1: 0.6772\n",
      "07-17 23:11 root         INFO     Epoch 9. Global step 47570. T=56.09min\n",
      "07-17 23:11 root         INFO     In-batch loss      : 0.6929\n",
      "07-17 23:11 root         INFO     Training accuracy  : 0.5055, f1: 0.6716\n",
      "07-17 23:11 root         INFO     Validation accuracy: 0.5061, f1: 0.6721\n",
      "07-17 23:11 root         WARNING  Model is evaluating in training mode!\n",
      "07-17 23:11 root         INFO     Set the model into eval mode\n",
      "07-17 23:12 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 5, 'hidden_dim_out': 256, 'embedding_dim': 64, 'dropout': 0.8231300367687396, 'alphabet_len': 104, 'lr': 0.0005888677094828468}\n",
      "07-17 23:12 root         INFO     Writer: runs/Jul17_23-12-16_lyalin_YoonKimModel_lr3_dropout0.8231300367687396_noise_level0.0000hyperparameters_search_random\n",
      "07-17 23:18 root         INFO     Epoch 0. Global step 4757. T=6.29min\n",
      "07-17 23:18 root         INFO     In-batch loss      : 0.6862\n",
      "07-17 23:18 root         INFO     Training accuracy  : 0.5016, f1: 0.6681\n",
      "07-17 23:18 root         INFO     Validation accuracy: 0.5097, f1: 0.6752\n",
      "07-17 23:31 root         INFO     Epoch 2. Global step 14271. T=18.86min\n",
      "07-17 23:31 root         INFO     In-batch loss      : 0.6819\n",
      "07-17 23:31 root         INFO     Training accuracy  : 0.5066, f1: 0.6725\n",
      "07-17 23:31 root         INFO     Validation accuracy: 0.5097, f1: 0.6752\n",
      "07-17 23:43 root         INFO     Epoch 4. Global step 23785. T=31.44min\n",
      "07-17 23:43 root         INFO     In-batch loss      : 0.6848\n",
      "07-17 23:43 root         INFO     Training accuracy  : 0.5049, f1: 0.6710\n",
      "07-17 23:43 root         INFO     Validation accuracy: 0.5069, f1: 0.6727\n",
      "07-17 23:56 root         INFO     Epoch 6. Global step 33299. T=44.03min\n",
      "07-17 23:56 root         INFO     In-batch loss      : 0.6935\n",
      "07-17 23:56 root         INFO     Training accuracy  : 0.5003, f1: 0.6669\n",
      "07-17 23:56 root         INFO     Validation accuracy: 0.5062, f1: 0.6722\n",
      "07-18 00:08 root         INFO     Epoch 8. Global step 42813. T=56.60min\n",
      "07-18 00:08 root         INFO     In-batch loss      : 0.6882\n",
      "07-18 00:08 root         INFO     Training accuracy  : 0.5028, f1: 0.6691\n",
      "07-18 00:08 root         INFO     Validation accuracy: 0.5191, f1: 0.6834\n",
      "07-18 00:15 root         INFO     Epoch 9. Global step 47570. T=62.89min\n",
      "07-18 00:15 root         INFO     In-batch loss      : 0.6490\n",
      "07-18 00:15 root         INFO     Training accuracy  : 0.5607, f1: 0.5787\n",
      "07-18 00:15 root         INFO     Validation accuracy: 0.5534, f1: 0.5771\n",
      "07-18 00:15 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 00:15 root         INFO     Set the model into eval mode\n",
      "07-18 00:15 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 7, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.6377266923295836, 'alphabet_len': 104, 'lr': 0.00011752244362134444}\n",
      "07-18 00:15 root         INFO     Writer: runs/Jul18_00-15-44_lyalin_YoonKimModel_lr3_dropout0.6377266923295836_noise_level0.0000hyperparameters_search_random\n",
      "07-18 00:22 root         INFO     Epoch 0. Global step 4757. T=6.69min\n",
      "07-18 00:22 root         INFO     In-batch loss      : 0.6804\n",
      "07-18 00:22 root         INFO     Training accuracy  : 0.5127, f1: 0.6779\n",
      "07-18 00:22 root         INFO     Validation accuracy: 0.5119, f1: 0.6772\n",
      "07-18 00:35 root         INFO     Epoch 2. Global step 14271. T=20.06min\n",
      "07-18 00:35 root         INFO     In-batch loss      : 0.6922\n",
      "07-18 00:35 root         INFO     Training accuracy  : 0.5049, f1: 0.6710\n",
      "07-18 00:35 root         INFO     Validation accuracy: 0.5074, f1: 0.6732\n",
      "07-18 00:49 root         INFO     Epoch 4. Global step 23785. T=33.43min\n",
      "07-18 00:49 root         INFO     In-batch loss      : 0.7001\n",
      "07-18 00:49 root         INFO     Training accuracy  : 0.5063, f1: 0.6722\n",
      "07-18 00:49 root         INFO     Validation accuracy: 0.5115, f1: 0.6768\n",
      "07-18 01:02 root         INFO     Epoch 6. Global step 33299. T=46.81min\n",
      "07-18 01:02 root         INFO     In-batch loss      : 0.6821\n",
      "07-18 01:02 root         INFO     Training accuracy  : 0.5201, f1: 0.6843\n",
      "07-18 01:02 root         INFO     Validation accuracy: 0.5097, f1: 0.6752\n",
      "07-18 01:15 root         INFO     Epoch 8. Global step 42813. T=60.18min\n",
      "07-18 01:15 root         INFO     In-batch loss      : 0.6975\n",
      "07-18 01:15 root         INFO     Training accuracy  : 0.5004, f1: 0.6670\n",
      "07-18 01:15 root         INFO     Validation accuracy: 0.5163, f1: 0.6810\n",
      "07-18 01:22 root         INFO     Epoch 9. Global step 47570. T=66.88min\n",
      "07-18 01:22 root         INFO     In-batch loss      : 0.7040\n",
      "07-18 01:22 root         INFO     Training accuracy  : 0.5066, f1: 0.6725\n",
      "07-18 01:22 root         INFO     Validation accuracy: 0.5045, f1: 0.6707\n",
      "07-18 01:22 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 01:22 root         INFO     Set the model into eval mode\n",
      "07-18 01:23 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 7, 'hidden_dim_out': 256, 'embedding_dim': 32, 'dropout': 0.38884727149039633, 'alphabet_len': 104, 'lr': 0.0004355825679299327}\n",
      "07-18 01:23 root         INFO     Writer: runs/Jul18_01-23-11_lyalin_YoonKimModel_lr3_dropout0.38884727149039633_noise_level0.0000hyperparameters_search_random\n",
      "07-18 01:28 root         INFO     Epoch 0. Global step 4757. T=5.66min\n",
      "07-18 01:28 root         INFO     In-batch loss      : 0.6875\n",
      "07-18 01:28 root         INFO     Training accuracy  : 0.5053, f1: 0.6713\n",
      "07-18 01:28 root         INFO     Validation accuracy: 0.5108, f1: 0.6762\n",
      "07-18 01:40 root         INFO     Epoch 2. Global step 14271. T=17.02min\n",
      "07-18 01:40 root         INFO     In-batch loss      : 0.7004\n",
      "07-18 01:40 root         INFO     Training accuracy  : 0.5058, f1: 0.6718\n",
      "07-18 01:40 root         INFO     Validation accuracy: 0.5147, f1: 0.6796\n",
      "07-18 01:51 root         INFO     Epoch 4. Global step 23785. T=28.39min\n",
      "07-18 01:51 root         INFO     In-batch loss      : 0.6983\n",
      "07-18 01:51 root         INFO     Training accuracy  : 0.4976, f1: 0.6646\n",
      "07-18 01:51 root         INFO     Validation accuracy: 0.5061, f1: 0.6721\n",
      "07-18 02:02 root         INFO     Epoch 6. Global step 33299. T=39.74min\n",
      "07-18 02:02 root         INFO     In-batch loss      : 0.6924\n",
      "07-18 02:02 root         INFO     Training accuracy  : 0.5026, f1: 0.6690\n",
      "07-18 02:02 root         INFO     Validation accuracy: 0.5023, f1: 0.6687\n",
      "07-18 02:14 root         INFO     Epoch 8. Global step 42813. T=51.11min\n",
      "07-18 02:14 root         INFO     In-batch loss      : 0.7076\n",
      "07-18 02:14 root         INFO     Training accuracy  : 0.5847, f1: 0.6633\n",
      "07-18 02:14 root         INFO     Validation accuracy: 0.5844, f1: 0.6603\n",
      "07-18 02:19 root         INFO     Epoch 9. Global step 47570. T=56.79min\n",
      "07-18 02:19 root         INFO     In-batch loss      : 0.6901\n",
      "07-18 02:19 root         INFO     Training accuracy  : 0.5004, f1: 0.6670\n",
      "07-18 02:19 root         INFO     Validation accuracy: 0.5038, f1: 0.6700\n",
      "07-18 02:19 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 02:19 root         INFO     Set the model into eval mode\n",
      "07-18 02:20 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 3, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.7685017258402894, 'alphabet_len': 104, 'lr': 0.0004058328157266604}\n",
      "07-18 02:20 root         INFO     Writer: runs/Jul18_02-20-33_lyalin_YoonKimModel_lr3_dropout0.7685017258402894_noise_level0.0000hyperparameters_search_random\n",
      "07-18 02:26 root         INFO     Epoch 0. Global step 4757. T=5.61min\n",
      "07-18 02:26 root         INFO     In-batch loss      : 0.7011\n",
      "07-18 02:26 root         INFO     Training accuracy  : 0.5071, f1: 0.6729\n",
      "07-18 02:26 root         INFO     Validation accuracy: 0.5060, f1: 0.6720\n",
      "07-18 02:37 root         INFO     Epoch 2. Global step 14271. T=16.85min\n",
      "07-18 02:37 root         INFO     In-batch loss      : 0.6889\n",
      "07-18 02:37 root         INFO     Training accuracy  : 0.5012, f1: 0.6677\n",
      "07-18 02:37 root         INFO     Validation accuracy: 0.4993, f1: 0.6660\n",
      "07-18 02:48 root         INFO     Epoch 4. Global step 23785. T=28.10min\n",
      "07-18 02:48 root         INFO     In-batch loss      : 0.6896\n",
      "07-18 02:48 root         INFO     Training accuracy  : 0.5064, f1: 0.6724\n",
      "07-18 02:48 root         INFO     Validation accuracy: 0.5061, f1: 0.6721\n",
      "07-18 02:59 root         INFO     Epoch 6. Global step 33299. T=39.36min\n",
      "07-18 02:59 root         INFO     In-batch loss      : 0.6881\n",
      "07-18 02:59 root         INFO     Training accuracy  : 0.5035, f1: 0.6698\n",
      "07-18 02:59 root         INFO     Validation accuracy: 0.5108, f1: 0.6762\n",
      "07-18 03:11 root         INFO     Epoch 8. Global step 42813. T=50.59min\n",
      "07-18 03:11 root         INFO     In-batch loss      : 0.6907\n",
      "07-18 03:11 root         INFO     Training accuracy  : 0.5127, f1: 0.6779\n",
      "07-18 03:11 root         INFO     Validation accuracy: 0.5136, f1: 0.6786\n",
      "07-18 03:16 root         INFO     Epoch 9. Global step 47570. T=56.21min\n",
      "07-18 03:16 root         INFO     In-batch loss      : 0.6954\n",
      "07-18 03:16 root         INFO     Training accuracy  : 0.5088, f1: 0.6744\n",
      "07-18 03:16 root         INFO     Validation accuracy: 0.5043, f1: 0.6705\n",
      "07-18 03:16 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 03:16 root         INFO     Set the model into eval mode\n",
      "07-18 03:17 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 7, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.8578143245766716, 'alphabet_len': 104, 'lr': 0.0006726233644343961}\n",
      "07-18 03:17 root         INFO     Writer: runs/Jul18_03-17-20_lyalin_YoonKimModel_lr3_dropout0.8578143245766716_noise_level0.0000hyperparameters_search_random\n",
      "07-18 03:23 root         INFO     Epoch 0. Global step 4757. T=5.70min\n",
      "07-18 03:23 root         INFO     In-batch loss      : 0.6888\n",
      "07-18 03:23 root         INFO     Training accuracy  : 0.5076, f1: 0.6734\n",
      "07-18 03:23 root         INFO     Validation accuracy: 0.5062, f1: 0.6722\n",
      "07-18 03:34 root         INFO     Epoch 2. Global step 14271. T=17.09min\n",
      "07-18 03:34 root         INFO     In-batch loss      : 0.7052\n",
      "07-18 03:34 root         INFO     Training accuracy  : 0.5085, f1: 0.6742\n",
      "07-18 03:34 root         INFO     Validation accuracy: 0.5103, f1: 0.6758\n",
      "07-18 03:45 root         INFO     Epoch 4. Global step 23785. T=28.48min\n",
      "07-18 03:45 root         INFO     In-batch loss      : 0.6952\n",
      "07-18 03:45 root         INFO     Training accuracy  : 0.5088, f1: 0.6744\n",
      "07-18 03:45 root         INFO     Validation accuracy: 0.5092, f1: 0.6748\n",
      "07-18 03:57 root         INFO     Epoch 6. Global step 33299. T=39.88min\n",
      "07-18 03:57 root         INFO     In-batch loss      : 0.6975\n",
      "07-18 03:57 root         INFO     Training accuracy  : 0.5059, f1: 0.6719\n",
      "07-18 03:57 root         INFO     Validation accuracy: 0.5092, f1: 0.6748\n",
      "07-18 04:08 root         INFO     Epoch 8. Global step 42813. T=51.37min\n",
      "07-18 04:08 root         INFO     In-batch loss      : 0.7005\n",
      "07-18 04:08 root         INFO     Training accuracy  : 0.5053, f1: 0.6713\n",
      "07-18 04:08 root         INFO     Validation accuracy: 0.5078, f1: 0.6736\n",
      "07-18 04:14 root         INFO     Epoch 9. Global step 47570. T=57.10min\n",
      "07-18 04:14 root         INFO     In-batch loss      : 0.6872\n",
      "07-18 04:14 root         INFO     Training accuracy  : 0.5095, f1: 0.6750\n",
      "07-18 04:14 root         INFO     Validation accuracy: 0.5060, f1: 0.6720\n",
      "07-18 04:14 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 04:14 root         INFO     Set the model into eval mode\n",
      "07-18 04:15 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 7, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.9611162835139782, 'alphabet_len': 104, 'lr': 0.00010753160323954229}\n",
      "07-18 04:15 root         INFO     Writer: runs/Jul18_04-15-01_lyalin_YoonKimModel_lr3_dropout0.9611162835139782_noise_level0.0000hyperparameters_search_random\n",
      "07-18 04:20 root         INFO     Epoch 0. Global step 4757. T=5.73min\n",
      "07-18 04:20 root         INFO     In-batch loss      : 0.7014\n",
      "07-18 04:20 root         INFO     Training accuracy  : 0.5064, f1: 0.6724\n",
      "07-18 04:20 root         INFO     Validation accuracy: 0.5056, f1: 0.6717\n",
      "07-18 04:32 root         INFO     Epoch 2. Global step 14271. T=17.14min\n",
      "07-18 04:32 root         INFO     In-batch loss      : 0.6962\n",
      "07-18 04:32 root         INFO     Training accuracy  : 0.5109, f1: 0.6763\n",
      "07-18 04:32 root         INFO     Validation accuracy: 0.5081, f1: 0.6738\n",
      "07-18 04:43 root         INFO     Epoch 4. Global step 23785. T=28.55min\n",
      "07-18 04:43 root         INFO     In-batch loss      : 0.6892\n",
      "07-18 04:43 root         INFO     Training accuracy  : 0.5093, f1: 0.6749\n",
      "07-18 04:43 root         INFO     Validation accuracy: 0.5129, f1: 0.6780\n",
      "07-18 04:54 root         INFO     Epoch 6. Global step 33299. T=39.94min\n",
      "07-18 04:54 root         INFO     In-batch loss      : 0.7025\n",
      "07-18 04:54 root         INFO     Training accuracy  : 0.5105, f1: 0.6759\n",
      "07-18 04:54 root         INFO     Validation accuracy: 0.5033, f1: 0.6696\n",
      "07-18 05:06 root         INFO     Epoch 8. Global step 42813. T=51.40min\n",
      "07-18 05:06 root         INFO     In-batch loss      : 0.6867\n",
      "07-18 05:06 root         INFO     Training accuracy  : 0.5050, f1: 0.6711\n",
      "07-18 05:06 root         INFO     Validation accuracy: 0.5037, f1: 0.6699\n",
      "07-18 05:12 root         INFO     Epoch 9. Global step 47570. T=57.15min\n",
      "07-18 05:12 root         INFO     In-batch loss      : 0.6999\n",
      "07-18 05:12 root         INFO     Training accuracy  : 0.4979, f1: 0.6648\n",
      "07-18 05:12 root         INFO     Validation accuracy: 0.5099, f1: 0.6754\n",
      "07-18 05:12 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 05:12 root         INFO     Set the model into eval mode\n",
      "07-18 05:12 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 7, 'hidden_dim_out': 256, 'embedding_dim': 128, 'dropout': 0.5230480722218602, 'alphabet_len': 104, 'lr': 0.0009734501456260838}\n",
      "07-18 05:12 root         INFO     Writer: runs/Jul18_05-12-44_lyalin_YoonKimModel_lr3_dropout0.5230480722218602_noise_level0.0000hyperparameters_search_random\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7f1a95955e10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 493, in Client\n",
      "    answer_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 737, in answer_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "07-18 05:18 root         INFO     Epoch 0. Global step 4757. T=5.62min\n",
      "07-18 05:18 root         INFO     In-batch loss      : 0.6810\n",
      "07-18 05:18 root         INFO     Training accuracy  : 0.5072, f1: 0.6731\n",
      "07-18 05:18 root         INFO     Validation accuracy: 0.5158, f1: 0.6806\n",
      "07-18 05:29 root         INFO     Epoch 2. Global step 14271. T=16.87min\n",
      "07-18 05:29 root         INFO     In-batch loss      : 0.6921\n",
      "07-18 05:29 root         INFO     Training accuracy  : 0.5046, f1: 0.6558\n",
      "07-18 05:29 root         INFO     Validation accuracy: 0.5069, f1: 0.6568\n",
      "07-18 05:40 root         INFO     Epoch 4. Global step 23785. T=28.09min\n",
      "07-18 05:40 root         INFO     In-batch loss      : 0.6905\n",
      "07-18 05:40 root         INFO     Training accuracy  : 0.5146, f1: 0.6095\n",
      "07-18 05:40 root         INFO     Validation accuracy: 0.5159, f1: 0.6056\n",
      "07-18 05:52 root         INFO     Epoch 6. Global step 33299. T=39.31min\n",
      "07-18 05:52 root         INFO     In-batch loss      : 0.6863\n",
      "07-18 05:52 root         INFO     Training accuracy  : 0.5004, f1: 0.6670\n",
      "07-18 05:52 root         INFO     Validation accuracy: 0.5032, f1: 0.6695\n",
      "07-18 06:03 root         INFO     Epoch 8. Global step 42813. T=50.55min\n",
      "07-18 06:03 root         INFO     In-batch loss      : 0.6914\n",
      "07-18 06:03 root         INFO     Training accuracy  : 0.5194, f1: 0.6837\n",
      "07-18 06:03 root         INFO     Validation accuracy: 0.5016, f1: 0.6681\n",
      "07-18 06:08 root         INFO     Epoch 9. Global step 47570. T=56.17min\n",
      "07-18 06:08 root         INFO     In-batch loss      : 0.3524\n",
      "07-18 06:08 root         INFO     Training accuracy  : 0.7706, f1: 0.7737\n",
      "07-18 06:08 root         INFO     Validation accuracy: 0.7740, f1: 0.7748\n",
      "07-18 06:08 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 06:08 root         INFO     Set the model into eval mode\n",
      "07-18 06:09 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 7, 'hidden_dim_out': 128, 'embedding_dim': 64, 'dropout': 0.5067441998248025, 'alphabet_len': 104, 'lr': 0.00010662308152627062}\n",
      "07-18 06:09 root         INFO     Writer: runs/Jul18_06-09-29_lyalin_YoonKimModel_lr3_dropout0.5067441998248025_noise_level0.0000hyperparameters_search_random\n",
      "07-18 06:15 root         INFO     Epoch 0. Global step 4757. T=5.69min\n",
      "07-18 06:15 root         INFO     In-batch loss      : 0.6853\n",
      "07-18 06:15 root         INFO     Training accuracy  : 0.5054, f1: 0.6714\n",
      "07-18 06:15 root         INFO     Validation accuracy: 0.5002, f1: 0.6669\n",
      "07-18 06:26 root         INFO     Epoch 2. Global step 14271. T=17.09min\n",
      "07-18 06:26 root         INFO     In-batch loss      : 0.7015\n",
      "07-18 06:26 root         INFO     Training accuracy  : 0.4993, f1: 0.6661\n",
      "07-18 06:26 root         INFO     Validation accuracy: 0.5135, f1: 0.6785\n",
      "07-18 06:37 root         INFO     Epoch 4. Global step 23785. T=28.47min\n",
      "07-18 06:37 root         INFO     In-batch loss      : 0.7038\n",
      "07-18 06:37 root         INFO     Training accuracy  : 0.5089, f1: 0.6746\n",
      "07-18 06:37 root         INFO     Validation accuracy: 0.5099, f1: 0.6754\n",
      "07-18 06:49 root         INFO     Epoch 6. Global step 33299. T=39.86min\n",
      "07-18 06:49 root         INFO     In-batch loss      : 0.6933\n",
      "07-18 06:49 root         INFO     Training accuracy  : 0.5112, f1: 0.6765\n",
      "07-18 06:49 root         INFO     Validation accuracy: 0.5120, f1: 0.6773\n",
      "07-18 07:00 root         INFO     Epoch 8. Global step 42813. T=51.24min\n",
      "07-18 07:00 root         INFO     In-batch loss      : 0.6823\n",
      "07-18 07:00 root         INFO     Training accuracy  : 0.4949, f1: 0.6621\n",
      "07-18 07:00 root         INFO     Validation accuracy: 0.5099, f1: 0.6754\n",
      "07-18 07:06 root         INFO     Epoch 9. Global step 47570. T=56.94min\n",
      "07-18 07:06 root         INFO     In-batch loss      : 0.6953\n",
      "07-18 07:06 root         INFO     Training accuracy  : 0.5020, f1: 0.6684\n",
      "07-18 07:06 root         INFO     Validation accuracy: 0.5115, f1: 0.6768\n",
      "07-18 07:06 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 07:06 root         INFO     Set the model into eval mode\n",
      "07-18 07:07 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 32, 'dropout': 0.7030584162055805, 'alphabet_len': 104, 'lr': 0.00034121906128044174}\n",
      "07-18 07:07 root         INFO     Writer: runs/Jul18_07-07-00_lyalin_YoonKimModel_lr3_dropout0.7030584162055805_noise_level0.0000hyperparameters_search_random\n",
      "07-18 07:12 root         INFO     Epoch 0. Global step 4757. T=5.73min\n",
      "07-18 07:12 root         INFO     In-batch loss      : 0.7002\n",
      "07-18 07:12 root         INFO     Training accuracy  : 0.5029, f1: 0.6692\n",
      "07-18 07:12 root         INFO     Validation accuracy: 0.4990, f1: 0.6658\n",
      "07-18 07:24 root         INFO     Epoch 2. Global step 14271. T=17.19min\n",
      "07-18 07:24 root         INFO     In-batch loss      : 0.6952\n",
      "07-18 07:24 root         INFO     Training accuracy  : 0.5123, f1: 0.6775\n",
      "07-18 07:24 root         INFO     Validation accuracy: 0.5124, f1: 0.6776\n",
      "07-18 07:35 root         INFO     Epoch 4. Global step 23785. T=28.68min\n",
      "07-18 07:35 root         INFO     In-batch loss      : 0.6900\n",
      "07-18 07:35 root         INFO     Training accuracy  : 0.5113, f1: 0.6766\n",
      "07-18 07:35 root         INFO     Validation accuracy: 0.5129, f1: 0.6780\n",
      "07-18 07:47 root         INFO     Epoch 6. Global step 33299. T=40.16min\n",
      "07-18 07:47 root         INFO     In-batch loss      : 0.6978\n",
      "07-18 07:47 root         INFO     Training accuracy  : 0.5110, f1: 0.6764\n",
      "07-18 07:47 root         INFO     Validation accuracy: 0.5112, f1: 0.6765\n",
      "07-18 07:58 root         INFO     Epoch 8. Global step 42813. T=51.62min\n",
      "07-18 07:58 root         INFO     In-batch loss      : 0.6871\n",
      "07-18 07:58 root         INFO     Training accuracy  : 0.5130, f1: 0.6781\n",
      "07-18 07:58 root         INFO     Validation accuracy: 0.5049, f1: 0.6710\n",
      "07-18 08:04 root         INFO     Epoch 9. Global step 47570. T=57.35min\n",
      "07-18 08:04 root         INFO     In-batch loss      : 0.6955\n",
      "07-18 08:04 root         INFO     Training accuracy  : 0.5083, f1: 0.6740\n",
      "07-18 08:04 root         INFO     Validation accuracy: 0.5026, f1: 0.6690\n",
      "07-18 08:04 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 08:04 root         INFO     Set the model into eval mode\n",
      "07-18 08:04 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 128, 'embedding_dim': 32, 'dropout': 0.44895581099067805, 'alphabet_len': 104, 'lr': 0.00011019608208442927}\n",
      "07-18 08:04 root         INFO     Writer: runs/Jul18_08-04-55_lyalin_YoonKimModel_lr3_dropout0.44895581099067805_noise_level0.0000hyperparameters_search_random\n",
      "07-18 08:10 root         INFO     Epoch 0. Global step 4757. T=5.94min\n",
      "07-18 08:10 root         INFO     In-batch loss      : 0.7063\n",
      "07-18 08:10 root         INFO     Training accuracy  : 0.5038, f1: 0.6700\n",
      "07-18 08:10 root         INFO     Validation accuracy: 0.5110, f1: 0.6764\n",
      "07-18 08:22 root         INFO     Epoch 2. Global step 14271. T=17.85min\n",
      "07-18 08:22 root         INFO     In-batch loss      : 0.6873\n",
      "07-18 08:22 root         INFO     Training accuracy  : 0.5085, f1: 0.6742\n",
      "07-18 08:22 root         INFO     Validation accuracy: 0.5069, f1: 0.6727\n",
      "07-18 08:34 root         INFO     Epoch 4. Global step 23785. T=29.76min\n",
      "07-18 08:34 root         INFO     In-batch loss      : 0.6903\n",
      "07-18 08:34 root         INFO     Training accuracy  : 0.5021, f1: 0.6685\n",
      "07-18 08:34 root         INFO     Validation accuracy: 0.5059, f1: 0.6719\n",
      "07-18 08:46 root         INFO     Epoch 6. Global step 33299. T=41.72min\n",
      "07-18 08:46 root         INFO     In-batch loss      : 0.6897\n",
      "07-18 08:46 root         INFO     Training accuracy  : 0.5004, f1: 0.6670\n",
      "07-18 08:46 root         INFO     Validation accuracy: 0.5072, f1: 0.6731\n",
      "07-18 08:58 root         INFO     Epoch 8. Global step 42813. T=53.60min\n",
      "07-18 08:58 root         INFO     In-batch loss      : 0.6960\n",
      "07-18 08:58 root         INFO     Training accuracy  : 0.4997, f1: 0.6664\n",
      "07-18 08:58 root         INFO     Validation accuracy: 0.5081, f1: 0.6738\n",
      "07-18 09:04 root         INFO     Epoch 9. Global step 47570. T=59.55min\n",
      "07-18 09:04 root         INFO     In-batch loss      : 0.6990\n",
      "07-18 09:04 root         INFO     Training accuracy  : 0.5029, f1: 0.6692\n",
      "07-18 09:04 root         INFO     Validation accuracy: 0.5060, f1: 0.6720\n",
      "07-18 09:04 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 09:04 root         INFO     Set the model into eval mode\n",
      "07-18 09:05 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 7, 'hidden_dim_out': 128, 'embedding_dim': 128, 'dropout': 0.5429691646521396, 'alphabet_len': 104, 'lr': 0.0005391013231116506}\n",
      "07-18 09:05 root         INFO     Writer: runs/Jul18_09-05-04_lyalin_YoonKimModel_lr3_dropout0.5429691646521396_noise_level0.0000hyperparameters_search_random\n",
      "07-18 09:11 root         INFO     Epoch 0. Global step 4757. T=6.67min\n",
      "07-18 09:11 root         INFO     In-batch loss      : 0.6866\n",
      "07-18 09:11 root         INFO     Training accuracy  : 0.5081, f1: 0.6739\n",
      "07-18 09:11 root         INFO     Validation accuracy: 0.5125, f1: 0.6777\n",
      "07-18 09:25 root         INFO     Epoch 2. Global step 14271. T=20.01min\n",
      "07-18 09:25 root         INFO     In-batch loss      : 0.6940\n",
      "07-18 09:25 root         INFO     Training accuracy  : 0.4968, f1: 0.6639\n",
      "07-18 09:25 root         INFO     Validation accuracy: 0.5055, f1: 0.6716\n",
      "07-18 09:38 root         INFO     Epoch 4. Global step 23785. T=33.22min\n",
      "07-18 09:38 root         INFO     In-batch loss      : 0.6892\n",
      "07-18 09:38 root         INFO     Training accuracy  : 0.5041, f1: 0.6703\n",
      "07-18 09:38 root         INFO     Validation accuracy: 0.5121, f1: 0.6774\n",
      "07-18 09:51 root         INFO     Epoch 6. Global step 33299. T=46.45min\n",
      "07-18 09:51 root         INFO     In-batch loss      : 0.6884\n",
      "07-18 09:51 root         INFO     Training accuracy  : 0.5098, f1: 0.6754\n",
      "07-18 09:51 root         INFO     Validation accuracy: 0.5018, f1: 0.6683\n",
      "07-18 10:04 root         INFO     Epoch 8. Global step 42813. T=59.68min\n",
      "07-18 10:04 root         INFO     In-batch loss      : 0.6914\n",
      "07-18 10:04 root         INFO     Training accuracy  : 0.5144, f1: 0.6794\n",
      "07-18 10:04 root         INFO     Validation accuracy: 0.5044, f1: 0.6706\n",
      "07-18 10:11 root         INFO     Epoch 9. Global step 47570. T=66.30min\n",
      "07-18 10:11 root         INFO     In-batch loss      : 0.6917\n",
      "07-18 10:11 root         INFO     Training accuracy  : 0.5098, f1: 0.6754\n",
      "07-18 10:11 root         INFO     Validation accuracy: 0.5100, f1: 0.6755\n",
      "07-18 10:11 root         WARNING  Model is evaluating in training mode!\n",
      "07-18 10:11 root         INFO     Set the model into eval mode\n",
      "07-18 10:11 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 5, 'hidden_dim_out': 128, 'embedding_dim': 128, 'dropout': 0.7947560757358095, 'alphabet_len': 104, 'lr': 0.0002252672530009273}\n",
      "07-18 10:11 root         INFO     Writer: runs/Jul18_10-11-56_lyalin_YoonKimModel_lr3_dropout0.7947560757358095_noise_level0.0000hyperparameters_search_random\n",
      "07-18 10:17 root         INFO     Epoch 0. Global step 4757. T=5.61min\n",
      "07-18 10:17 root         INFO     In-batch loss      : 0.6915\n",
      "07-18 10:17 root         INFO     Training accuracy  : 0.5098, f1: 0.6754\n",
      "07-18 10:17 root         INFO     Validation accuracy: 0.5108, f1: 0.6762\n",
      "07-18 10:28 root         INFO     Epoch 2. Global step 14271. T=16.89min\n",
      "07-18 10:28 root         INFO     In-batch loss      : 0.6897\n",
      "07-18 10:28 root         INFO     Training accuracy  : 0.5092, f1: 0.6748\n",
      "07-18 10:28 root         INFO     Validation accuracy: 0.5100, f1: 0.6755\n",
      "Process Process-2324:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-2322:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7db9eb2153ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m               save_model_path=None)\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 115, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-2321:\n",
      "Traceback (most recent call last):\n",
      "Process Process-2323:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    n_filters = int(np.random.choice([32, 64, 128, 256]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "    hidden_dim_out = int(np.random.choice([64, 128, 256]))\n",
    "    embedding_dim = int(np.random.choice([32, 64, 128]))\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'hidden_dim_out': hidden_dim_out,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "        'alphabet_len': len(alphabet)\n",
    "    }\n",
    "\n",
    "    model = YoonKimModel(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=10,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
