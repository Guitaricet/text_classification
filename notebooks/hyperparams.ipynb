{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-10 11:16 summarizer.preprocessing.cleaner INFO     'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cfg\n",
    "\n",
    "from text_classification import trainutils\n",
    "from text_classification.layers import *\n",
    "from text_classification.logger import logger\n",
    "from text_classification.datautils import *\n",
    "from text_classification.trainutils import get_metrics\n",
    "\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "CharIMDB.maxlen = 512\n",
    "train_data, test_data = CharIMDB.splits(text_field, label_field, root='../.data')\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-04 18:06 root         INFO     Writer: runs/Jul04_18-06-09_lyalin_CharCNN_lr0_dropout0.5_noise_level0.0000\n",
      "07-04 18:06 root         INFO     Epoch 0. Global step 665. T=0.17min\n",
      "07-04 18:06 root         INFO     In-batch loss      : 0.6937\n",
      "07-04 18:06 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:06 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "07-04 18:07 root         INFO     Epoch 9. Global step 6650. T=1.65min\n",
      "07-04 18:07 root         INFO     In-batch loss      : 0.6934\n",
      "07-04 18:07 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Calculating test metrics... Time T=1.65min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n",
      "07-04 18:07 root         INFO     Original dataset accuracy: 0.5000, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Final test accuracy:0.5000, f1: 0.0000. Time 1.8032399932543437 min\n",
      "07-04 18:07 root         INFO     Writer: runs/Jul04_18-07-57_lyalin_CharCNN_lr1_dropout0.5_noise_level0.0000\n",
      "07-04 18:08 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-04 18:08 root         INFO     In-batch loss      : 0.6641\n",
      "07-04 18:08 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:08 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:09 root         INFO     Epoch 9. Global step 6650. T=1.68min\n",
      "07-04 18:09 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:09 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:09 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:09 root         INFO     Calculating test metrics... Time T=1.68min\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.00s/it]\n",
      "07-04 18:09 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:09 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.8411134799321494 min\n",
      "07-04 18:09 root         INFO     Writer: runs/Jul04_18-09-47_lyalin_CharCNN_lr2_dropout0.5_noise_level0.0000\n",
      "07-04 18:09 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-04 18:09 root         INFO     In-batch loss      : 0.6981\n",
      "07-04 18:09 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:09 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:11 root         INFO     Epoch 9. Global step 6650. T=1.72min\n",
      "07-04 18:11 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:11 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:11 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:11 root         INFO     Calculating test metrics... Time T=1.72min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
      "07-04 18:11 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:11 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.9072402000427247 min\n",
      "07-04 18:11 root         INFO     Writer: runs/Jul04_18-11-42_lyalin_CharCNN_lr3_dropout0.5_noise_level0.0000\n",
      "07-04 18:11 root         INFO     Epoch 0. Global step 665. T=0.22min\n",
      "07-04 18:11 root         INFO     In-batch loss      : 0.6919\n",
      "07-04 18:11 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:11 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Epoch 9. Global step 6650. T=1.85min\n",
      "07-04 18:13 root         INFO     In-batch loss      : 0.6910\n",
      "07-04 18:13 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Calculating test metrics... Time T=1.85min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n",
      "07-04 18:13 root         INFO     Original dataset accuracy: 0.5000, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Final test accuracy:0.5000, f1: 0.0000. Time 2.0057247122128805 min\n",
      "07-04 18:13 root         INFO     Writer: runs/Jul04_18-13-42_lyalin_CharCNN_lr4_dropout0.5_noise_level0.0000\n",
      "07-04 18:13 root         INFO     Epoch 0. Global step 665. T=0.19min\n",
      "07-04 18:13 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:13 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:15 root         INFO     Epoch 9. Global step 6650. T=1.71min\n",
      "07-04 18:15 root         INFO     In-batch loss      : 0.6915\n",
      "07-04 18:15 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:15 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:15 root         INFO     Calculating test metrics... Time T=1.71min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "07-04 18:15 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:15 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.870841427644094 min\n"
     ]
    }
   ],
   "source": [
    "model = CharCNN(128, 5, 512, len(cfg.alphabet))\n",
    "\n",
    "for lr in [1e0, 1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "    trained_model, results = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              test_dataloader,\n",
    "              test_dataloader,\n",
    "              lr=lr,\n",
    "              noise_level=0,\n",
    "              comment='',\n",
    "              save_model_path=None,\n",
    "              save_results_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(150)):\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand()\n",
    "    \n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7391752577319587,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 5,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.09851507346853383,\n",
       "  'accuracy': 0.7301333333333333,\n",
       "  'f1': 0.7391752577319587})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/150 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A07-05 18:09 root         INFO     {'n_filters': 16, 'cnn_kernel_size': 3, 'maxlen': 512, 'dropout': 0.7587327768268632}\n",
      "07-05 18:09 root         INFO     Writer: runs/Jul05_18-09-08_lyalin_CharCNN_lr4_dropout0.7587327768268632_noise_level0.0000hyperparameters_search\n",
      "07-05 18:09 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-05 18:09 root         INFO     In-batch loss      : 0.7718\n",
      "07-05 18:09 root         INFO     Training accuracy  : 0.5236, f1: 0.6120\n",
      "07-05 18:09 root         INFO     Validation accuracy: 0.5096, f1: 0.5986\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(150)):\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand() * 0.5 + 0.5\n",
    "    \n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7124064998710343,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 7,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.6716150874837757,\n",
       "  'accuracy': 0.7026666666666667,\n",
       "  'f1': 0.7124064998710343})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(150)):\n",
    "    lr = np.random.uniform()\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand() * 0.5 + 0.5\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7124064998710343,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 7,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.6716150874837757,\n",
       "  'accuracy': 0.7026666666666667,\n",
       "  'f1': 0.7124064998710343})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10**np.random.uniform(-4, 0)\n",
    "n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "maxlen = 512\n",
    "dropout = np.random.rand() * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0.7124064998710343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 14:12 root         INFO     Writer: runs/Jul09_14-12-47_lyalin_CharCNN_lr3_dropout0.5_noise_level0.0000hyperparameters_search\n",
      "07-09 14:12 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-09 14:12 root         INFO     In-batch loss      : 0.7336\n",
      "07-09 14:12 root         INFO     Training accuracy  : 0.6725, f1: 0.6801\n",
      "07-09 14:12 root         INFO     Validation accuracy: 0.6603, f1: 0.6687\n",
      "07-09 14:13 root         INFO     Epoch 2. Global step 1995. T=0.50min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.2334\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7330, f1: 0.7254\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7120, f1: 0.7005\n",
      "07-09 14:13 root         INFO     Epoch 4. Global step 3325. T=0.82min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.5750\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7641, f1: 0.7677\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7368, f1: 0.7380\n",
      "07-09 14:13 root         INFO     Epoch 6. Global step 4655. T=1.16min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.3988\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7850, f1: 0.7847\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7464, f1: 0.7416\n",
      "07-09 14:14 root         INFO     Epoch 8. Global step 5985. T=1.50min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.1454\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8040, f1: 0.8059\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7549, f1: 0.7555\n",
      "07-09 14:14 root         INFO     Epoch 10. Global step 7315. T=1.83min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.6503\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8136, f1: 0.8139\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7587, f1: 0.7574\n",
      "07-09 14:14 root         INFO     Epoch 12. Global step 8645. T=2.17min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.4744\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8253, f1: 0.8244\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7632, f1: 0.7609\n",
      "07-09 14:15 root         INFO     Epoch 14. Global step 9975. T=2.49min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.1294\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8327, f1: 0.8377\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7672, f1: 0.7732\n",
      "07-09 14:15 root         INFO     Epoch 16. Global step 11305. T=2.82min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.6567\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8418, f1: 0.8459\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7725, f1: 0.7778\n",
      "07-09 14:15 root         INFO     Epoch 18. Global step 12635. T=3.16min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.4790\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8482, f1: 0.8505\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7672, f1: 0.7683\n",
      "07-09 14:16 root         INFO     Epoch 20. Global step 13965. T=3.49min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 1.2805\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8539, f1: 0.8556\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7664, f1: 0.7683\n",
      "07-09 14:16 root         INFO     Epoch 22. Global step 15295. T=3.82min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 0.2380\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8596, f1: 0.8633\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7688, f1: 0.7743\n",
      "07-09 14:16 root         INFO     Epoch 24. Global step 16625. T=4.14min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 0.1049\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8688, f1: 0.8707\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7664, f1: 0.7686\n",
      "07-09 14:17 root         INFO     Epoch 26. Global step 17955. T=4.47min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.0648\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8731, f1: 0.8733\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7691, f1: 0.7675\n",
      "07-09 14:17 root         INFO     Epoch 28. Global step 19285. T=4.80min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.5017\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8797, f1: 0.8794\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7616, f1: 0.7595\n",
      "07-09 14:17 root         INFO     Epoch 29. Global step 19950. T=4.96min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.0165\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8805, f1: 0.8822\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7680, f1: 0.7712\n",
      "07-09 14:17 root         WARNING  Model is evaluating in training mode!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES!\n",
      "{'n_filters': 128, 'cnn_kernel_size': 5, 'maxlen': 512, 'dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "lr = 0.001\n",
    "n_filters = 128\n",
    "cnn_kernel_size = 5\n",
    "maxlen = 512\n",
    "dropout = 0.5\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'maxlen': maxlen,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    print('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttentionedYoonKim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize='spacy', use_vocab=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train_data, test_data = HierarchicalIMDB.splits(text_field, label_field, root='../.data')\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 15:21 root         INFO     Writer: runs/Jul09_15-21-51_lyalin_AttentionedYoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search\n",
      "07-09 15:23 root         INFO     Epoch 0. Global step 665. T=2.03min\n",
      "07-09 15:23 root         INFO     In-batch loss      : 0.7096\n",
      "07-09 15:23 root         INFO     Training accuracy  : 0.5078, f1: 0.4185\n",
      "07-09 15:23 root         INFO     Validation accuracy: 0.5064, f1: 0.4210\n",
      "07-09 15:28 root         INFO     Epoch 2. Global step 1995. T=6.32min\n",
      "07-09 15:28 root         INFO     In-batch loss      : 0.7181\n",
      "07-09 15:28 root         INFO     Training accuracy  : 0.6406, f1: 0.6223\n",
      "07-09 15:28 root         INFO     Validation accuracy: 0.6248, f1: 0.6051\n",
      "07-09 15:32 root         INFO     Epoch 4. Global step 3325. T=10.43min\n",
      "07-09 15:32 root         INFO     In-batch loss      : 0.6390\n",
      "07-09 15:32 root         INFO     Training accuracy  : 0.7547, f1: 0.7503\n",
      "07-09 15:32 root         INFO     Validation accuracy: 0.7453, f1: 0.7410\n",
      "07-09 15:36 root         INFO     Epoch 6. Global step 4655. T=14.53min\n",
      "07-09 15:36 root         INFO     In-batch loss      : 0.3805\n",
      "07-09 15:36 root         INFO     Training accuracy  : 0.8479, f1: 0.8495\n",
      "07-09 15:36 root         INFO     Validation accuracy: 0.8285, f1: 0.8291\n",
      "07-09 15:40 root         INFO     Epoch 8. Global step 5985. T=18.64min\n",
      "07-09 15:40 root         INFO     In-batch loss      : 0.1037\n",
      "07-09 15:40 root         INFO     Training accuracy  : 0.8748, f1: 0.8753\n",
      "07-09 15:40 root         INFO     Validation accuracy: 0.8501, f1: 0.8503\n",
      "07-09 15:44 root         INFO     Epoch 10. Global step 7315. T=22.72min\n",
      "07-09 15:44 root         INFO     In-batch loss      : 0.0217\n",
      "07-09 15:44 root         INFO     Training accuracy  : 0.8937, f1: 0.8951\n",
      "07-09 15:44 root         INFO     Validation accuracy: 0.8680, f1: 0.8689\n",
      "07-09 15:48 root         INFO     Epoch 12. Global step 8645. T=26.81min\n",
      "07-09 15:48 root         INFO     In-batch loss      : 0.7714\n",
      "07-09 15:48 root         INFO     Training accuracy  : 0.9061, f1: 0.9049\n",
      "07-09 15:48 root         INFO     Validation accuracy: 0.8685, f1: 0.8657\n",
      "07-09 15:52 root         INFO     Epoch 14. Global step 9975. T=30.90min\n",
      "07-09 15:52 root         INFO     In-batch loss      : 1.0344\n",
      "07-09 15:52 root         INFO     Training accuracy  : 0.9181, f1: 0.9182\n",
      "07-09 15:52 root         INFO     Validation accuracy: 0.8757, f1: 0.8757\n",
      "07-09 15:56 root         INFO     Epoch 16. Global step 11305. T=34.98min\n",
      "07-09 15:56 root         INFO     In-batch loss      : 0.0940\n",
      "07-09 15:56 root         INFO     Training accuracy  : 0.9275, f1: 0.9276\n",
      "07-09 15:56 root         INFO     Validation accuracy: 0.8757, f1: 0.8757\n",
      "Process Process-206:\n",
      "Process Process-208:\n",
      "Process Process-205:\n",
      "Process Process-207:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-064b96edd3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           save_model_path=None)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# TODO: change dataloaders and remove premute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mwords_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_modules'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "lr = 0.001\n",
    "n_filters = 128  # int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "cnn_kernel_size = 5\n",
    "maxlen = 512\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 128\n",
    "embedding_dim = 74\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'heads': 1,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "#     'pool_kernel_size': 4\n",
    "}\n",
    "\n",
    "model = AttentionedYoonKimModel(**params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    print('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 118)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 19:44 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 5, 'hidden_dim_out': 256, 'heads': 1, 'embedding_dim': 51, 'dropout': 0.49569537913353157}\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49569537913353157 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 19:44 root         INFO     Writer: runs/Jul09_19-44-56_lyalin_AttentionedYoonKimModel_lr3_dropout0.49569537913353157_noise_level0.0000hyperparameters_search_manual\n",
      "07-09 19:47 root         INFO     Epoch 0. Global step 665. T=2.07min\n",
      "07-09 19:47 root         INFO     In-batch loss      : 0.6998\n",
      "07-09 19:47 root         INFO     Training accuracy  : 0.5013, f1: 0.6622\n",
      "07-09 19:47 root         INFO     Validation accuracy: 0.5016, f1: 0.6605\n",
      "07-09 19:51 root         INFO     Epoch 2. Global step 1995. T=6.23min\n",
      "07-09 19:51 root         INFO     In-batch loss      : 0.6561\n",
      "07-09 19:51 root         INFO     Training accuracy  : 0.6108, f1: 0.6203\n",
      "07-09 19:51 root         INFO     Validation accuracy: 0.6021, f1: 0.6084\n",
      "07-09 19:55 root         INFO     Epoch 4. Global step 3325. T=10.39min\n",
      "07-09 19:55 root         INFO     In-batch loss      : 0.6962\n",
      "07-09 19:55 root         INFO     Training accuracy  : 0.7150, f1: 0.7130\n",
      "07-09 19:55 root         INFO     Validation accuracy: 0.7024, f1: 0.7003\n",
      "07-09 19:59 root         INFO     Epoch 6. Global step 4655. T=14.56min\n",
      "07-09 19:59 root         INFO     In-batch loss      : 0.6482\n",
      "07-09 19:59 root         INFO     Training accuracy  : 0.8055, f1: 0.8024\n",
      "07-09 19:59 root         INFO     Validation accuracy: 0.7981, f1: 0.7961\n",
      "07-09 20:03 root         INFO     Epoch 8. Global step 5985. T=18.72min\n",
      "07-09 20:03 root         INFO     In-batch loss      : 0.0697\n",
      "07-09 20:03 root         INFO     Training accuracy  : 0.8556, f1: 0.8558\n",
      "07-09 20:03 root         INFO     Validation accuracy: 0.8349, f1: 0.8348\n",
      "07-09 20:07 root         INFO     Epoch 10. Global step 7315. T=22.90min\n",
      "07-09 20:07 root         INFO     In-batch loss      : 0.1638\n",
      "07-09 20:07 root         INFO     Training accuracy  : 0.8720, f1: 0.8735\n",
      "07-09 20:07 root         INFO     Validation accuracy: 0.8485, f1: 0.8500\n",
      "07-09 20:11 root         INFO     Epoch 12. Global step 8645. T=27.06min\n",
      "07-09 20:11 root         INFO     In-batch loss      : 0.0301\n",
      "07-09 20:11 root         INFO     Training accuracy  : 0.8877, f1: 0.8879\n",
      "07-09 20:11 root         INFO     Validation accuracy: 0.8571, f1: 0.8571\n",
      "07-09 20:16 root         INFO     Epoch 14. Global step 9975. T=31.23min\n",
      "07-09 20:16 root         INFO     In-batch loss      : 0.8798\n",
      "07-09 20:16 root         INFO     Training accuracy  : 0.8951, f1: 0.8953\n",
      "07-09 20:16 root         INFO     Validation accuracy: 0.8507, f1: 0.8508\n",
      "07-09 20:20 root         INFO     Epoch 16. Global step 11305. T=35.39min\n",
      "07-09 20:20 root         INFO     In-batch loss      : 0.0013\n",
      "07-09 20:20 root         INFO     Training accuracy  : 0.9068, f1: 0.9062\n",
      "07-09 20:20 root         INFO     Validation accuracy: 0.8603, f1: 0.8596\n",
      "Process Process-1741:\n",
      "Process Process-1744:\n",
      "Process Process-1743:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-825e30ffd436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_manual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           save_model_path=None)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/trainutils.py\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, test_data, noise_level, frac)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-1742:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 64\n",
    "cnn_kernel_size = 5\n",
    "dropout = np.random.rand() * 0.9 + 0.1\n",
    "hidden_dim_out = 256\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'heads': 1,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "#     'pool_kernel_size': 4\n",
    "}\n",
    "\n",
    "logger.info('Parameters: %s' % params)\n",
    "model = AttentionedYoonKimModel(**params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 20:22 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 7, 'hidden_dim_out': 64, 'heads': 1, 'embedding_dim': 67, 'dropout': 0.363531569594306}\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.363531569594306 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 20:22 root         INFO     Writer: runs/Jul09_20-22-54_lyalin_AttentionedYoonKimModel_lr3_dropout0.363531569594306_noise_level0.0000hyperparameters_search_random\n",
      "07-09 20:24 root         INFO     Epoch 0. Global step 665. T=2.03min\n",
      "07-09 20:24 root         INFO     In-batch loss      : 0.7092\n",
      "07-09 20:24 root         INFO     Training accuracy  : 0.5140, f1: 0.3765\n",
      "07-09 20:24 root         INFO     Validation accuracy: 0.5061, f1: 0.3743\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    n_filters = int(np.random.choice([32, 64, 128, 256]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "    hidden_dim_out = int(np.random.choice([64, 128, 256]))\n",
    "    embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'hidden_dim_out': hidden_dim_out,\n",
    "        'heads': 1,\n",
    "    #     'maxlen': maxlen,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "    #     'pool_kernel_size': 4\n",
    "    }\n",
    "\n",
    "    model = AttentionedYoonKimModel(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=20,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667728237791931"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoonKimModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 6s, sys: 627 ms, total: 3min 7s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize='spacy', use_vocab=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train_data, test_data = HierarchicalIMDB.splits(text_field, label_field, root='../.data')\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-10 11:53 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 90, 'dropout': 0.5, 'lr': 0.001}\n",
      "07-10 11:53 root         INFO     Writer: runs/Jul10_11-53-58_lyalin_YoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search_manual\n",
      "07-10 11:56 root         INFO     Epoch 0. Global step 665. T=2.09min\n",
      "07-10 11:56 root         INFO     In-batch loss      : 0.6743\n",
      "07-10 11:56 root         INFO     Training accuracy  : 0.5113, f1: 0.3792\n",
      "07-10 11:56 root         INFO     Validation accuracy: 0.5152, f1: 0.3871\n",
      "07-10 12:00 root         INFO     Epoch 2. Global step 1995. T=6.20min\n",
      "07-10 12:00 root         INFO     In-batch loss      : 0.6813\n",
      "07-10 12:00 root         INFO     Training accuracy  : 0.5140, f1: 0.4029\n",
      "07-10 12:00 root         INFO     Validation accuracy: 0.5019, f1: 0.3923\n",
      "07-10 12:04 root         INFO     Epoch 4. Global step 3325. T=10.36min\n",
      "07-10 12:04 root         INFO     In-batch loss      : 0.7592\n",
      "07-10 12:04 root         INFO     Training accuracy  : 0.5319, f1: 0.3472\n",
      "07-10 12:04 root         INFO     Validation accuracy: 0.5189, f1: 0.3304\n",
      "07-10 12:08 root         INFO     Epoch 6. Global step 4655. T=14.51min\n",
      "07-10 12:08 root         INFO     In-batch loss      : 0.4164\n",
      "07-10 12:08 root         INFO     Training accuracy  : 0.6739, f1: 0.6646\n",
      "07-10 12:08 root         INFO     Validation accuracy: 0.6637, f1: 0.6554\n",
      "07-10 12:12 root         INFO     Epoch 8. Global step 5985. T=18.79min\n",
      "07-10 12:12 root         INFO     In-batch loss      : 0.4408\n",
      "07-10 12:12 root         INFO     Training accuracy  : 0.7242, f1: 0.6967\n",
      "07-10 12:12 root         INFO     Validation accuracy: 0.7152, f1: 0.6897\n",
      "07-10 12:17 root         INFO     Epoch 10. Global step 7315. T=23.03min\n",
      "07-10 12:17 root         INFO     In-batch loss      : 0.6099\n",
      "07-10 12:17 root         INFO     Training accuracy  : 0.7878, f1: 0.7804\n",
      "07-10 12:17 root         INFO     Validation accuracy: 0.7712, f1: 0.7635\n",
      "07-10 12:21 root         INFO     Epoch 12. Global step 8645. T=27.27min\n",
      "07-10 12:21 root         INFO     In-batch loss      : 0.2722\n",
      "07-10 12:21 root         INFO     Training accuracy  : 0.8266, f1: 0.8271\n",
      "07-10 12:21 root         INFO     Validation accuracy: 0.8131, f1: 0.8126\n",
      "07-10 12:25 root         INFO     Epoch 14. Global step 9975. T=31.58min\n",
      "07-10 12:25 root         INFO     In-batch loss      : 0.8232\n",
      "07-10 12:25 root         INFO     Training accuracy  : 0.8480, f1: 0.8519\n",
      "07-10 12:25 root         INFO     Validation accuracy: 0.8307, f1: 0.8349\n",
      "07-10 12:29 root         INFO     Epoch 16. Global step 11305. T=35.87min\n",
      "07-10 12:29 root         INFO     In-batch loss      : 0.1489\n",
      "07-10 12:29 root         INFO     Training accuracy  : 0.8646, f1: 0.8647\n",
      "07-10 12:29 root         INFO     Validation accuracy: 0.8397, f1: 0.8393\n",
      "07-10 12:34 root         INFO     Epoch 18. Global step 12635. T=40.14min\n",
      "07-10 12:34 root         INFO     In-batch loss      : 1.0206\n",
      "07-10 12:34 root         INFO     Training accuracy  : 0.8756, f1: 0.8763\n",
      "07-10 12:34 root         INFO     Validation accuracy: 0.8453, f1: 0.8459\n",
      "07-10 12:36 root         INFO     Epoch 19. Global step 13300. T=42.26min\n",
      "07-10 12:36 root         INFO     In-batch loss      : 0.0198\n",
      "07-10 12:36 root         INFO     Training accuracy  : 0.8789, f1: 0.8791\n",
      "07-10 12:36 root         INFO     Validation accuracy: 0.8475, f1: 0.8474\n",
      "07-10 12:36 root         WARNING  Model is evaluating in training mode!\n",
      "07-10 12:36 root         INFO     YES!, f1: 0.848694725625999, parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 90, 'dropout': 0.5, 'lr': 0.001}\n",
      "07-10 12:36 root         INFO     {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 90, 'dropout': 0.5, 'lr': 0.001}\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 32\n",
    "cnn_kernel_size = 5\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 64\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=20,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, acc: %s, parameters: %s' % (\n",
    "        metrics['f1'], metrics['acc'], str(params)\n",
    "    ))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-10 12:36 root         INFO     Parameters: {'n_filters': 512, 'cnn_kernel_size': 7, 'hidden_dim_out': 512, 'embedding_dim': 37, 'dropout': 0.5, 'lr': 0.001}\n",
      "07-10 12:36 root         INFO     Writer: runs/Jul10_12-36-20_lyalin_YoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search_manual\n",
      "07-10 12:39 root         INFO     Epoch 0. Global step 665. T=2.85min\n",
      "07-10 12:39 root         INFO     In-batch loss      : 0.6960\n",
      "07-10 12:39 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-10 12:39 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-10 12:44 root         INFO     Epoch 2. Global step 1995. T=8.49min\n",
      "07-10 12:44 root         INFO     In-batch loss      : 0.7064\n",
      "07-10 12:44 root         INFO     Training accuracy  : 0.5242, f1: 0.3710\n",
      "07-10 12:44 root         INFO     Validation accuracy: 0.5139, f1: 0.3588\n",
      "07-10 12:50 root         INFO     Epoch 4. Global step 3325. T=14.10min\n",
      "07-10 12:50 root         INFO     In-batch loss      : 0.6994\n",
      "07-10 12:50 root         INFO     Training accuracy  : 0.5361, f1: 0.6585\n",
      "07-10 12:50 root         INFO     Validation accuracy: 0.5064, f1: 0.6347\n",
      "07-10 12:56 root         INFO     Epoch 6. Global step 4655. T=19.69min\n",
      "07-10 12:56 root         INFO     In-batch loss      : 0.6396\n",
      "07-10 12:56 root         INFO     Training accuracy  : 0.5636, f1: 0.4160\n",
      "07-10 12:56 root         INFO     Validation accuracy: 0.5216, f1: 0.3652\n",
      "07-10 13:01 root         INFO     Epoch 8. Global step 5985. T=25.29min\n",
      "07-10 13:01 root         INFO     In-batch loss      : 0.4394\n",
      "07-10 13:01 root         INFO     Training accuracy  : 0.6848, f1: 0.6667\n",
      "07-10 13:01 root         INFO     Validation accuracy: 0.6488, f1: 0.6361\n",
      "07-10 13:07 root         INFO     Epoch 10. Global step 7315. T=30.89min\n",
      "07-10 13:07 root         INFO     In-batch loss      : 0.6907\n",
      "07-10 13:07 root         INFO     Training accuracy  : 0.8023, f1: 0.7902\n",
      "07-10 13:07 root         INFO     Validation accuracy: 0.7595, f1: 0.7436\n",
      "07-10 13:12 root         INFO     Epoch 12. Global step 8645. T=36.47min\n",
      "07-10 13:12 root         INFO     In-batch loss      : 1.6833\n",
      "07-10 13:12 root         INFO     Training accuracy  : 0.8899, f1: 0.8899\n",
      "07-10 13:12 root         INFO     Validation accuracy: 0.8320, f1: 0.8320\n",
      "07-10 13:18 root         INFO     Epoch 14. Global step 9975. T=42.13min\n",
      "07-10 13:18 root         INFO     In-batch loss      : 0.0568\n",
      "07-10 13:18 root         INFO     Training accuracy  : 0.9243, f1: 0.9250\n",
      "07-10 13:18 root         INFO     Validation accuracy: 0.8469, f1: 0.8481\n",
      "07-10 13:24 root         INFO     Epoch 16. Global step 11305. T=47.85min\n",
      "07-10 13:24 root         INFO     In-batch loss      : 0.4473\n",
      "07-10 13:24 root         INFO     Training accuracy  : 0.9481, f1: 0.9485\n",
      "07-10 13:24 root         INFO     Validation accuracy: 0.8501, f1: 0.8506\n",
      "07-10 13:29 root         INFO     Epoch 18. Global step 12635. T=53.63min\n",
      "07-10 13:29 root         INFO     In-batch loss      : 0.0022\n",
      "07-10 13:29 root         INFO     Training accuracy  : 0.9687, f1: 0.9686\n",
      "07-10 13:29 root         INFO     Validation accuracy: 0.8467, f1: 0.8459\n",
      "07-10 13:32 root         INFO     Epoch 19. Global step 13300. T=56.49min\n",
      "07-10 13:32 root         INFO     In-batch loss      : 0.0540\n",
      "07-10 13:32 root         INFO     Training accuracy  : 0.9762, f1: 0.9762\n",
      "07-10 13:32 root         INFO     Validation accuracy: 0.8443, f1: 0.8429\n",
      "07-10 13:32 root         WARNING  Model is evaluating in training mode!\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 512\n",
    "cnn_kernel_size = 7\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 512\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=20,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-10 14:54 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 72, 'dropout': 0.6243415666771305, 'lr': 0.000667854542403568}\n",
      "07-10 14:54 root         INFO     Writer: runs/Jul10_14-54-03_lyalin_YoonKimModel_lr3_dropout0.6243415666771305_noise_level0.0000hyperparameters_search_random\n",
      "07-10 14:56 root         INFO     Epoch 0. Global step 665. T=2.27min\n",
      "07-10 14:56 root         INFO     In-batch loss      : 0.6882\n",
      "07-10 14:56 root         INFO     Training accuracy  : 0.4993, f1: 0.0006\n",
      "07-10 14:56 root         INFO     Validation accuracy: 0.5043, f1: 0.0000\n",
      "07-10 15:00 root         INFO     Epoch 2. Global step 1995. T=6.86min\n",
      "07-10 15:00 root         INFO     In-batch loss      : 0.7192\n",
      "07-10 15:00 root         INFO     Training accuracy  : 0.5180, f1: 0.3858\n",
      "07-10 15:00 root         INFO     Validation accuracy: 0.5125, f1: 0.3824\n",
      "07-10 15:05 root         INFO     Epoch 4. Global step 3325. T=11.43min\n",
      "07-10 15:05 root         INFO     In-batch loss      : 0.6095\n",
      "07-10 15:05 root         INFO     Training accuracy  : 0.5284, f1: 0.6534\n",
      "07-10 15:05 root         INFO     Validation accuracy: 0.5040, f1: 0.6321\n",
      "07-10 15:10 root         INFO     Epoch 6. Global step 4655. T=16.10min\n",
      "07-10 15:10 root         INFO     In-batch loss      : 0.3505\n",
      "07-10 15:10 root         INFO     Training accuracy  : 0.6880, f1: 0.6945\n",
      "07-10 15:10 root         INFO     Validation accuracy: 0.6821, f1: 0.6884\n",
      "07-10 15:14 root         INFO     Epoch 8. Global step 5985. T=20.85min\n",
      "07-10 15:14 root         INFO     In-batch loss      : 0.2982\n",
      "07-10 15:14 root         INFO     Training accuracy  : 0.7322, f1: 0.7144\n",
      "07-10 15:14 root         INFO     Validation accuracy: 0.7176, f1: 0.6972\n",
      "07-10 15:19 root         INFO     Epoch 10. Global step 7315. T=25.46min\n",
      "07-10 15:19 root         INFO     In-batch loss      : 0.9133\n",
      "07-10 15:19 root         INFO     Training accuracy  : 0.7827, f1: 0.7901\n",
      "07-10 15:19 root         INFO     Validation accuracy: 0.7669, f1: 0.7747\n",
      "07-10 15:24 root         INFO     Epoch 12. Global step 8645. T=30.06min\n",
      "07-10 15:24 root         INFO     In-batch loss      : 0.1917\n",
      "07-10 15:24 root         INFO     Training accuracy  : 0.8364, f1: 0.8385\n",
      "07-10 15:24 root         INFO     Validation accuracy: 0.8232, f1: 0.8250\n",
      "07-10 15:28 root         INFO     Epoch 14. Global step 9975. T=34.62min\n",
      "07-10 15:28 root         INFO     In-batch loss      : 0.1848\n",
      "07-10 15:28 root         INFO     Training accuracy  : 0.8698, f1: 0.8690\n",
      "07-10 15:28 root         INFO     Validation accuracy: 0.8445, f1: 0.8438\n",
      "07-10 15:33 root         INFO     Epoch 16. Global step 11305. T=39.19min\n",
      "07-10 15:33 root         INFO     In-batch loss      : 0.0154\n",
      "07-10 15:33 root         INFO     Training accuracy  : 0.8824, f1: 0.8793\n",
      "07-10 15:33 root         INFO     Validation accuracy: 0.8536, f1: 0.8500\n",
      "07-10 15:37 root         INFO     Epoch 18. Global step 12635. T=43.78min\n",
      "07-10 15:37 root         INFO     In-batch loss      : 0.0192\n",
      "07-10 15:37 root         INFO     Training accuracy  : 0.8961, f1: 0.8983\n",
      "07-10 15:37 root         INFO     Validation accuracy: 0.8616, f1: 0.8649\n",
      "07-10 15:40 root         INFO     Epoch 19. Global step 13300. T=46.11min\n",
      "07-10 15:40 root         INFO     In-batch loss      : 0.1481\n",
      "07-10 15:40 root         INFO     Training accuracy  : 0.9024, f1: 0.9027\n",
      "07-10 15:40 root         INFO     Validation accuracy: 0.8651, f1: 0.8653\n",
      "07-10 15:40 root         WARNING  Model is evaluating in training mode!\n",
      "07-10 15:40 root         INFO     YES!, f1: 0.8641318798191969, parameters: {'n_filters': 256, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 72, 'dropout': 0.6243415666771305, 'lr': 0.000667854542403568}\n",
      "07-10 15:40 root         INFO     {'n_filters': 256, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 72, 'dropout': 0.6243415666771305, 'lr': 0.000667854542403568}\n",
      "07-10 15:40 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 38, 'dropout': 0.4659108174106398, 'lr': 0.00010019759343495729}\n",
      "07-10 15:40 root         INFO     Writer: runs/Jul10_15-40-16_lyalin_YoonKimModel_lr3_dropout0.4659108174106398_noise_level0.0000hyperparameters_search_random\n",
      "07-10 15:42 root         INFO     Epoch 0. Global step 665. T=2.08min\n",
      "07-10 15:42 root         INFO     In-batch loss      : 0.6960\n",
      "07-10 15:42 root         INFO     Training accuracy  : 0.5019, f1: 0.6670\n",
      "07-10 15:42 root         INFO     Validation accuracy: 0.4960, f1: 0.6617\n",
      "07-10 15:46 root         INFO     Epoch 2. Global step 1995. T=6.28min\n",
      "07-10 15:46 root         INFO     In-batch loss      : 0.6691\n",
      "07-10 15:46 root         INFO     Training accuracy  : 0.5054, f1: 0.4333\n",
      "07-10 15:46 root         INFO     Validation accuracy: 0.5072, f1: 0.4410\n",
      "07-10 15:50 root         INFO     Epoch 4. Global step 3325. T=10.40min\n",
      "07-10 15:50 root         INFO     In-batch loss      : 0.7133\n",
      "07-10 15:50 root         INFO     Training accuracy  : 0.5048, f1: 0.4393\n",
      "07-10 15:50 root         INFO     Validation accuracy: 0.5040, f1: 0.4428\n",
      "07-10 15:54 root         INFO     Epoch 6. Global step 4655. T=14.59min\n",
      "07-10 15:54 root         INFO     In-batch loss      : 0.7029\n",
      "07-10 15:54 root         INFO     Training accuracy  : 0.5143, f1: 0.4115\n",
      "07-10 15:54 root         INFO     Validation accuracy: 0.5136, f1: 0.4165\n",
      "07-10 15:59 root         INFO     Epoch 8. Global step 5985. T=18.81min\n",
      "07-10 15:59 root         INFO     In-batch loss      : 0.7061\n",
      "07-10 15:59 root         INFO     Training accuracy  : 0.5008, f1: 0.6672\n",
      "07-10 15:59 root         INFO     Validation accuracy: 0.4957, f1: 0.6626\n",
      "07-10 16:03 root         INFO     Epoch 10. Global step 7315. T=23.10min\n",
      "07-10 16:03 root         INFO     In-batch loss      : 0.6763\n",
      "07-10 16:03 root         INFO     Training accuracy  : 0.5217, f1: 0.3411\n",
      "07-10 16:03 root         INFO     Validation accuracy: 0.5181, f1: 0.3374\n",
      "07-10 16:07 root         INFO     Epoch 12. Global step 8645. T=27.33min\n",
      "07-10 16:07 root         INFO     In-batch loss      : 0.7141\n",
      "07-10 16:07 root         INFO     Training accuracy  : 0.5203, f1: 0.3940\n",
      "07-10 16:07 root         INFO     Validation accuracy: 0.5155, f1: 0.3945\n",
      "07-10 16:11 root         INFO     Epoch 14. Global step 9975. T=31.53min\n",
      "07-10 16:11 root         INFO     In-batch loss      : 0.7713\n",
      "07-10 16:11 root         INFO     Training accuracy  : 0.5241, f1: 0.3790\n",
      "07-10 16:11 root         INFO     Validation accuracy: 0.5184, f1: 0.3747\n",
      "07-10 16:16 root         INFO     Epoch 16. Global step 11305. T=35.79min\n",
      "07-10 16:16 root         INFO     In-batch loss      : 0.6752\n",
      "07-10 16:16 root         INFO     Training accuracy  : 0.5288, f1: 0.3264\n",
      "07-10 16:16 root         INFO     Validation accuracy: 0.5155, f1: 0.3099\n",
      "07-10 16:20 root         INFO     Epoch 18. Global step 12635. T=39.99min\n",
      "07-10 16:20 root         INFO     In-batch loss      : 0.7169\n",
      "07-10 16:20 root         INFO     Training accuracy  : 0.5365, f1: 0.3996\n",
      "07-10 16:20 root         INFO     Validation accuracy: 0.5272, f1: 0.3938\n",
      "07-10 16:22 root         INFO     Epoch 19. Global step 13300. T=42.09min\n",
      "07-10 16:22 root         INFO     In-batch loss      : 0.7220\n",
      "07-10 16:22 root         INFO     Training accuracy  : 0.5974, f1: 0.5115\n",
      "07-10 16:22 root         INFO     Validation accuracy: 0.5920, f1: 0.5118\n",
      "07-10 16:22 root         WARNING  Model is evaluating in training mode!\n",
      "07-10 16:22 root         INFO     Parameters: {'n_filters': 256, 'cnn_kernel_size': 3, 'hidden_dim_out': 64, 'embedding_dim': 110, 'dropout': 0.7513114312835268, 'lr': 0.000988439258241246}\n",
      "07-10 16:22 root         INFO     Writer: runs/Jul10_16-22-29_lyalin_YoonKimModel_lr3_dropout0.7513114312835268_noise_level0.0000hyperparameters_search_random\n",
      "07-10 16:24 root         INFO     Epoch 0. Global step 665. T=2.18min\n",
      "07-10 16:24 root         INFO     In-batch loss      : 0.7208\n",
      "07-10 16:24 root         INFO     Training accuracy  : 0.5151, f1: 0.3949\n",
      "07-10 16:24 root         INFO     Validation accuracy: 0.5147, f1: 0.4005\n",
      "07-10 16:29 root         INFO     Epoch 2. Global step 1995. T=6.63min\n",
      "07-10 16:29 root         INFO     In-batch loss      : 0.7147\n",
      "07-10 16:29 root         INFO     Training accuracy  : 0.5184, f1: 0.3928\n",
      "07-10 16:29 root         INFO     Validation accuracy: 0.5149, f1: 0.3963\n",
      "07-10 16:33 root         INFO     Epoch 4. Global step 3325. T=11.00min\n",
      "07-10 16:33 root         INFO     In-batch loss      : 0.7549\n",
      "07-10 16:33 root         INFO     Training accuracy  : 0.5290, f1: 0.3322\n",
      "07-10 16:33 root         INFO     Validation accuracy: 0.5149, f1: 0.3133\n",
      "07-10 16:37 root         INFO     Epoch 6. Global step 4655. T=15.42min\n",
      "07-10 16:37 root         INFO     In-batch loss      : 0.6134\n",
      "07-10 16:37 root         INFO     Training accuracy  : 0.6579, f1: 0.6650\n",
      "07-10 16:37 root         INFO     Validation accuracy: 0.6443, f1: 0.6522\n",
      "07-10 16:42 root         INFO     Epoch 8. Global step 5985. T=19.88min\n",
      "07-10 16:42 root         INFO     In-batch loss      : 0.6563\n",
      "07-10 16:42 root         INFO     Training accuracy  : 0.7178, f1: 0.7269\n",
      "07-10 16:42 root         INFO     Validation accuracy: 0.6955, f1: 0.7069\n",
      "07-10 16:46 root         INFO     Epoch 10. Global step 7315. T=24.40min\n",
      "07-10 16:46 root         INFO     In-batch loss      : 0.6244\n",
      "07-10 16:46 root         INFO     Training accuracy  : 0.7681, f1: 0.7762\n",
      "07-10 16:46 root         INFO     Validation accuracy: 0.7696, f1: 0.7773\n",
      "07-10 16:51 root         INFO     Epoch 12. Global step 8645. T=28.85min\n",
      "07-10 16:51 root         INFO     In-batch loss      : 1.1233\n",
      "07-10 16:51 root         INFO     Training accuracy  : 0.8176, f1: 0.8187\n",
      "07-10 16:51 root         INFO     Validation accuracy: 0.8099, f1: 0.8094\n",
      "07-10 16:55 root         INFO     Epoch 14. Global step 9975. T=33.42min\n",
      "07-10 16:55 root         INFO     In-batch loss      : 0.3433\n",
      "07-10 16:55 root         INFO     Training accuracy  : 0.8549, f1: 0.8582\n",
      "07-10 16:55 root         INFO     Validation accuracy: 0.8445, f1: 0.8484\n",
      "07-10 17:00 root         INFO     Epoch 16. Global step 11305. T=38.51min\n",
      "07-10 17:00 root         INFO     In-batch loss      : 0.0850\n",
      "07-10 17:00 root         INFO     Training accuracy  : 0.8692, f1: 0.8699\n",
      "07-10 17:00 root         INFO     Validation accuracy: 0.8488, f1: 0.8498\n",
      "07-10 17:06 root         INFO     Epoch 18. Global step 12635. T=43.61min\n",
      "07-10 17:06 root         INFO     In-batch loss      : 0.9459\n",
      "07-10 17:06 root         INFO     Training accuracy  : 0.8837, f1: 0.8862\n",
      "07-10 17:06 root         INFO     Validation accuracy: 0.8555, f1: 0.8583\n",
      "07-10 17:08 root         INFO     Epoch 19. Global step 13300. T=46.13min\n",
      "07-10 17:08 root         INFO     In-batch loss      : 0.4638\n",
      "07-10 17:08 root         INFO     Training accuracy  : 0.8916, f1: 0.8933\n",
      "07-10 17:08 root         INFO     Validation accuracy: 0.8568, f1: 0.8596\n",
      "07-10 17:08 root         WARNING  Model is evaluating in training mode!\n",
      "07-10 17:08 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 3, 'hidden_dim_out': 256, 'embedding_dim': 72, 'dropout': 0.49223155699823873, 'lr': 0.0005384036069563902}\n",
      "07-10 17:08 root         INFO     Writer: runs/Jul10_17-08-44_lyalin_YoonKimModel_lr3_dropout0.49223155699823873_noise_level0.0000hyperparameters_search_random\n",
      "07-10 17:11 root         INFO     Epoch 0. Global step 665. T=2.31min\n",
      "07-10 17:11 root         INFO     In-batch loss      : 0.7465\n",
      "07-10 17:11 root         INFO     Training accuracy  : 0.5112, f1: 0.4110\n",
      "07-10 17:11 root         INFO     Validation accuracy: 0.5085, f1: 0.4129\n",
      "Process Process-1349:\n",
      "Process Process-1350:\n",
      "Process Process-1352:\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Process Process-1351:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d51800f37c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m               \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m               save_model_path=None)\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/trainutils.py\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, test_data, noise_level, frac)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    n_filters = int(np.random.choice([32, 64, 128, 256]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "    hidden_dim_out = int(np.random.choice([64, 128, 256]))\n",
    "    embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'hidden_dim_out': hidden_dim_out,\n",
    "    #     'maxlen': maxlen,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "    }\n",
    "\n",
    "    model = YoonKimModel(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=20,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
