{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "from collections import Counter\n",
    "from random import random, choice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torchtext\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "NOISE_LEVEL = 0.1  # possibly not used\n",
    "\n",
    "NOISE_LEVELS = [0, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.125, 0.15, 0.175, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAXLEN = 512\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "# use preprocessing for noise?\n",
    "\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "ALPHABET = ['<UNK>'] + ['\\n'] + [s for s in \"\"\" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}\"\"\"]\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)  # это плохо\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot dataset (Mokoron, SST, IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB\n"
     ]
    }
   ],
   "source": [
    "# MAXLEN = 170  # for makaron\n",
    "# MAXLEN = 200  # for SST\n",
    "MAXLEN = 512  # for IMDB\n",
    "\n",
    "russian = False\n",
    "no_emoji = False\n",
    "if MAXLEN == 170:\n",
    "    print('MOKORON!')\n",
    "    russian = True\n",
    "    no_emoji = True\n",
    "elif MAXLEN == 512:\n",
    "    print('IMDB')\n",
    "elif MAXLEN == 200:\n",
    "    print('SST!')\n",
    "else:\n",
    "    print(\"I don't know which dataset is used =(\")\n",
    "\n",
    "ALPHABET = ['<UNK>'] + ['\\n'] + [s for s in \"\"\" 0123456789-,;.!?:'’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}\"\"\"]\n",
    "if russian:\n",
    "    ALPHABET += [s for s in 'абвгдеёжзийклмнопрстуфхцчщъыьэюя']\n",
    "\n",
    "ALPHABET += [s for s in 'abcdefghijklmnopqrstuvwxyz']\n",
    "\n",
    "if no_emoji:\n",
    "    ALPHABET = [s for s in ALPHABET if s not in ('(', ')')]\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}\n",
    "\n",
    "class MokoronDatasetOneHot(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Zero vector for padding.\n",
    "    \"\"\"\n",
    "    noise_level = 0\n",
    "\n",
    "    def __init__(self, filepath, text_field, maxlen=MAXLEN):\n",
    "        self.alphabet = ALPHABET\n",
    "\n",
    "        self.data = pd.read_csv(filepath)\n",
    "        self.text_field = text_field\n",
    "        self.maxlen = maxlen\n",
    "        self.char2int = {s: i for s, i in zip(self.alphabet, range(len(self.alphabet)))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.data.iloc[idx]\n",
    "        text = line[self.text_field]\n",
    "        label = int(line.sentiment == 1.)\n",
    "\n",
    "        if self.noise_level > 0:\n",
    "            text = self._noise_generator(text)\n",
    "        text = self._preprocess(text)\n",
    "        return text, label\n",
    "\n",
    "    def _noise_generator(self, string):\n",
    "        noised = \"\"\n",
    "        for c in string:\n",
    "            if random() > self.noise_level:\n",
    "                noised += c\n",
    "            if random() < self.noise_level:\n",
    "                noised += choice(self.alphabet)\n",
    "        return noised\n",
    "\n",
    "    def _one_hot(self, char):\n",
    "        zeros = np.zeros(len(self.alphabet))\n",
    "        if char in self.char2int:\n",
    "            zeros[self.char2int[char]] = 1.\n",
    "        else:\n",
    "            zeros[self.char2int['<UNK>']] = 1.\n",
    "\n",
    "    def _preprocess(self, text):\n",
    "        text = text.lower()\n",
    "        one_hotted_text = np.zeros((self.maxlen, len(self.alphabet)))\n",
    "        for i, char in enumerate(text):\n",
    "            if i >= self.maxlen:\n",
    "                break\n",
    "            one_hotted_text[i, self.char2int.get(char, self.char2int['<UNK>'])] = 1.\n",
    "\n",
    "        return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "    def onehot2text(self, one_hotted_text, show_pad=False):\n",
    "        text = ''\n",
    "        max_values, idx = torch.max(one_hotted_text, 1)\n",
    "        for c, i in enumerate(idx):\n",
    "            if max_values[c] == 0:\n",
    "                if show_pad:\n",
    "                    symb = '<PAD>'\n",
    "                else:\n",
    "                    symb = ''\n",
    "            else:\n",
    "                symb = ALPHABET[i]\n",
    "            text += symb\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['<UNK>'])] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None, show_pad=False):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        max_values, idx = torch.max(one_hotted_text, 1)\n",
    "        for c, i in enumerate(idx):\n",
    "            if max_values[c] == 0:\n",
    "                if show_pad:\n",
    "                    symb = '<PAD>'\n",
    "                else:\n",
    "                    symb = ''\n",
    "            else:\n",
    "                symb = ALPHABET[i]\n",
    "            text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "\n",
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_metrics(model, test_data, noise_level=None):\n",
    "    \"\"\"\n",
    "    :param test_data: dataset or dataloader\n",
    "\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "    \n",
    "    if isinstance(test_data, torch.utils.data.Dataset):\n",
    "        if noise_level is not None:\n",
    "            test_data.noise_level = noise_level\n",
    "\n",
    "        test_dataloader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=BATCH_SIZE\n",
    "        )\n",
    "    else:\n",
    "        assert isinstance(test_data, torch.utils.data.DataLoader)\n",
    "        test_dataloader = test_data\n",
    "\n",
    "    for text, label in test_dataloader:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(1, 0, 2)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    f1 = f1_score(lables, predictions)\n",
    "    model.train()\n",
    "    return {'accuracy': acc, 'f1': f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "CharIMDB.noise_level = 0\n",
    "train, test = CharIMDB.splits(text_field, label_field)\n",
    "\n",
    "dataloader, val_dataloader = get_train_valid_loader(\n",
    "    train, valid_size=VALID_SIZE, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this musical is decidedly mixed, and none of the elements really fit together, but it somehow manages to be mostly enjoyable. the plot contains some of the elements of wodehouse's novel, but none of its virtues, though he co-wrote the script. the songs, though charming, have nothing to do with this particular film, and are unusually crudely squeezed into the plot, even by pre-oklahoma standards. burns and allen do their usual shtick quite competently, but it misses the tone of the rest of the film by about \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot2text(train[0][0])  # no spaces is onehot2text problem, not a data one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mokoron or SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/media/data/nlp/sentiment/IMDB/splits/'  # makaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/media/data/nlp/sentiment/ru-mokoron/splits/'  # makaron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/media/data/nlp/sentiment/stanfordSentimentTreebank/splits/'  # SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = MokoronDatasetOneHot(basepath + 'train.csv', 'text_original')\n",
    "valid = MokoronDatasetOneHot(basepath + 'validation.csv', 'text_original')\n",
    "test = MokoronDatasetOneHot(basepath + 'test.csv', 'text_original')\n",
    "\n",
    "test_original = MokoronDatasetOneHot(basepath + 'test.csv', 'text_original')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train, BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(valid, BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21250"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, init_function, n_filters, cnn_kernel_size, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        \"\"\"\n",
    "        :param init_funciton: torch.nn.init\n",
    "        :param dropout: dropout zero probability (1 - keep probability)\n",
    "        \"\"\"\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.init_function = init_function\n",
    "        self.dropout_prob = dropout\n",
    "        self.n_filters = n_filters\n",
    "        self.cnn_kernel_size = cnn_kernel_size  # 15\n",
    "        self.cnn_stride = 2\n",
    "        self.pool_kernel_size = 64  # MAXLEN  # 64\n",
    "        self.pool_stride = 32  # self.pool_kernel_size  # 32\n",
    "\n",
    "        self.embedding = nn.Linear(ALPHABET_LEN, ALPHABET_LEN)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, self.n_filters, kernel_size=self.cnn_kernel_size, stride=self.cnn_stride),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=self.pool_kernel_size, stride=self.pool_stride)\n",
    "        )\n",
    "        self.conv[0].weight = init_function(self.conv[0].weight)\n",
    "\n",
    "        conv_dim = self.n_filters * (int(((MAXLEN-self.cnn_kernel_size) / self.cnn_stride - self.pool_kernel_size) / self.pool_stride) + 1)\n",
    "        self.dropout = nn.Dropout(self.dropout_prob)\n",
    "        self.fc = nn.Linear(conv_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        (seq_len, batch_size, signal_dim)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_params_num(model):\n",
    "    return sum(np.prod(list(p.size())) for p in model.parameters())\n",
    "\n",
    "def mk_dataline(model_type, epochs, lr, noise_level_train, noise_level_test, acc_train, acc_test,\n",
    "                f1_train, f1_test, dropout, model, run_name, task, init_function=None):\n",
    "    return {\n",
    "        'task': task,\n",
    "        'model_type': model_type,\n",
    "        'trainable_params': model_params_num(model), 'dropout': dropout, 'init_function': init_function,\n",
    "        'epochs': epochs, 'lr': lr,\n",
    "        'noise_level_train': noise_level_train, 'noise_level_test': noise_level_test,\n",
    "        'acc_train': acc_train, 'acc_test': acc_test,\n",
    "        'f1_train': f1_train, 'f1_test': f1_test,\n",
    "        'model_desc': str(model),\n",
    "        'run_name': run_name,\n",
    "        'data_desc': 'Maxlen %s' % MAXLEN\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, n_filters, cnn_kernel_size, init_function, lr=1e-4, dropout=0.5, epochs=30, log_every=1, comment='', _model=None):\n",
    "    start_time = time()\n",
    "#     CharIMDB.noise_level = noise_level\n",
    "#     task='IMDB binary classification'\n",
    "    MokoronDatasetOneHot.noise_level = noise_level\n",
    "    task='Mokoron binary classification'\n",
    "\n",
    "    if _model is None:\n",
    "        model = CharCNN(\n",
    "            n_filters=n_filters, cnn_kernel_size=cnn_kernel_size,\n",
    "            init_function=init_function, dropout=dropout\n",
    "        )\n",
    "        if CUDA:\n",
    "            model.cuda()\n",
    "        model.train()\n",
    "    \n",
    "    else:\n",
    "        model = _model\n",
    "\n",
    "    model_name = '_charCNN_embed_smaller2_lr%s_noise%s_dropout%s_filters%s_cnn_kernel%s' % (\n",
    "        int(-np.log10(lr)), noise_level, dropout, n_filters, cnn_kernel_size\n",
    "    ) + comment\n",
    "    \n",
    "    if '(' not in ALPHABET:\n",
    "        model_name += '_no_emoji'\n",
    "\n",
    "    writer = SummaryWriter(comment=model_name)\n",
    "    if len(list(writer.all_writers.keys())) > 1:\n",
    "        print('More than one writer! 0_o')\n",
    "        print(list(writer.all_writers.keys()))\n",
    "\n",
    "    run_name = list(writer.all_writers.keys())[0]\n",
    "    print('Writer: %s' % run_name)\n",
    "\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(1, 0, 2)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        if epoch % log_every == 0:\n",
    "            print('Epoch %s. Global step %s. T=%s min' % (epoch, global_step, (time() - start_time) / 60.))\n",
    "            print('Loss               : %s' % loss.data[0])\n",
    "\n",
    "        # in-batch\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        _labels = label.data.tolist()\n",
    "        _predictions = idx.data.tolist()\n",
    "        acc = accuracy_score(_labels, _predictions)\n",
    "        f1 = f1_score(_labels, _predictions)\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        writer.add_scalar('f1_train', f1, global_step=global_step)\n",
    "        if epoch % log_every == 0:\n",
    "            print('In-batch accuracy  :', acc)\n",
    "\n",
    "        # validation\n",
    "        metrics = get_metrics(model, val_dataloader)\n",
    "        if epoch % log_every == 0:\n",
    "            print('Validation accuracy: %s, f1: %s' % (metrics['accuracy'], metrics['f1']))\n",
    "            print()\n",
    "\n",
    "        writer.add_scalar('accuracy_val', metrics['accuracy'], global_step=global_step)\n",
    "        writer.add_scalar('f1_val', metrics['f1'], global_step=global_step)\n",
    "\n",
    "    with open('models/%s.torch' % run_name.split('/')[-1], 'wb') as f:\n",
    "        try:\n",
    "            torch.save(model, f)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('Continuing (probably) without saving')\n",
    "        \n",
    "    # Test\n",
    "    model.eval()\n",
    "\n",
    "    metrics_test = None\n",
    "\n",
    "    print('Calculating validation metrics... Time %s min' % ((time() - start_time) / 60.))\n",
    "    metrics_train = get_metrics(model, dataloader)\n",
    "    acc_train = metrics_train['accuracy']\n",
    "    f1_train = metrics_train['f1']\n",
    "\n",
    "    for test_noise in NOISE_LEVELS:\n",
    "        metrics = get_metrics(model, test, test_noise)\n",
    "        if test_noise == noise_level:\n",
    "            metrics_test = metrics\n",
    "\n",
    "        acc_test = metrics['accuracy']\n",
    "        f1_test = metrics['f1']\n",
    "        results.append(mk_dataline(\n",
    "            model_type='charCNN', epochs=epochs, lr=lr,\n",
    "            noise_level_train=noise_level, acc_train=acc_train, f1_train=f1_train,\n",
    "            noise_level_test=test_noise, acc_test=acc_test, f1_test=f1_test,\n",
    "            dropout=dropout, model=model,\n",
    "            init_function=init_function,\n",
    "            run_name=run_name,\n",
    "            task=task\n",
    "        ))\n",
    "    \n",
    "    # test original\n",
    "    metrics = get_metrics(model, test_original)\n",
    "    results.append(mk_dataline(\n",
    "        model_type='charCNN', epochs=epochs, lr=lr,\n",
    "        noise_level_train=noise_level, acc_train=acc_train, f1_train=f1_train,\n",
    "        noise_level_test=-1, acc_test=metrics['accuracy'], f1_test=metrics['f1'],\n",
    "        dropout=dropout, model=model,\n",
    "        init_function=init_function,\n",
    "        run_name=run_name,\n",
    "        task=task\n",
    "    ))\n",
    "    \n",
    "    print('Original dataset: acc %s, f1 %s' % (metrics['accuracy'], metrics['f1']))\n",
    "    writer.add_scalar('accuracy_test_original', metrics['accuracy'], global_step=global_step)\n",
    "    writer.add_scalar('f1_test_original', metrics['f1'], global_step=global_step)\n",
    "\n",
    "    print('Final test metrics: %s, Time %s min' % (metrics_test, ((time() - start_time) / 60.)))\n",
    "    if metrics_test is not None:\n",
    "        writer.add_scalar('accuracy_test_final', metrics_test['accuracy'], global_step=global_step)\n",
    "        writer.add_scalar('f1_test_final', metrics_test['f1'], global_step=global_step)\n",
    "    print()\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May15_23-38-40_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.26346145073572796 min\n",
      "Loss               : 0.7305917739868164\n",
      "In-batch accuracy  : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5077333333333334, f1: 0.6733899504600142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10. Global step 7315. T=3.226904360453288 min\n",
      "Loss               : 0.580379068851471\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6837333333333333, f1: 0.7291000456829604\n",
      "\n",
      "Epoch 20. Global step 13965. T=6.092093384265899 min\n",
      "Loss               : 0.5446941256523132\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.7282666666666666, f1: 0.7204389574759945\n",
      "\n",
      "Calculating validation metrics... Time 8.783432698249817 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7418, f1 0.7482940144277636\n",
      "Final test metrics: {'accuracy': 0.7418, 'f1': 0.7482940144277636}, Time 13.341286142667135 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = run_model_with(\n",
    "    noise_level=0, n_filters=64, cnn_kernel_size=5,\n",
    "    init_function=init.xavier_normal, log_every=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May15_07-39-40_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.07604155143102011 min\n",
      "Loss               : 0.6920870542526245\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5656, f1: 0.48595771536762383\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10. Global step 7315. T=0.985636814435323 min\n",
      "Loss               : 0.6295992136001587\n",
      "In-batch accuracy  : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6946666666666667, f1: 0.7094646028926669\n",
      "\n",
      "Epoch 20. Global step 13965. T=1.8904971639315287 min\n",
      "Loss               : 0.3419972062110901\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7226666666666667, f1: 0.7345584481878509\n",
      "\n",
      "Calculating validation metrics... Time 2.7216787219047545 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  9%|▉         | 1/11 [05:57<59:30, 357.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.73712, f1 0.7409947190037045\n",
      "Final test metrics: {'accuracy': 0.73616, 'f1': 0.7406009123800534}, Time 5.9513659079869585 min\n",
      "\n",
      "Writer: runs/May15_07-45-37_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.005_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.11152073939641317 min\n",
      "Loss               : 0.7022352814674377\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.5552, f1: 0.5919765166340508\n",
      "\n",
      "Epoch 10. Global step 7315. T=1.5042980035146079 min\n",
      "Loss               : 0.5270780324935913\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6981333333333334, f1: 0.7027310924369748\n",
      "\n",
      "Epoch 20. Global step 13965. T=2.896902032693227 min\n",
      "Loss               : 0.4095366895198822\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7128, f1: 0.7448471926083866\n",
      "\n",
      "Calculating validation metrics... Time 4.711442462603251 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [15:46<1:10:58, 473.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.74172, f1 0.7524061505425823\n",
      "Final test metrics: {'accuracy': 0.74136, 'f1': 0.7520705521472393}, Time 9.820373165607453 min\n",
      "\n",
      "Writer: runs/May15_07-55-26_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.01_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.1883750081062317 min\n",
      "Loss               : 0.7170911431312561\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5434666666666667, f1: 0.486502699460108\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.37151038646698 min\n",
      "Loss               : 0.8055444955825806\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.6725333333333333, f1: 0.6381850324101356\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.513528688748678 min\n",
      "Loss               : 0.3246620297431946\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7210666666666666, f1: 0.7276041666666668\n",
      "\n",
      "Calculating validation metrics... Time 6.500309022267659 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [27:22<1:12:59, 547.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.73864, f1 0.7465280471720072\n",
      "Final test metrics: {'accuracy': 0.73692, 'f1': 0.7448104605595003}, Time 11.59800528685252 min\n",
      "\n",
      "Writer: runs/May15_08-07-02_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.025_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.19005041519800822 min\n",
      "Loss               : 0.6560627222061157\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.5261333333333333, f1: 0.6587286345304397\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.3852654337882995 min\n",
      "Loss               : 0.6179137229919434\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6613333333333333, f1: 0.6547036432843938\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.554977452754974 min\n",
      "Loss               : 1.0299016237258911\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.7088, f1: 0.7245206861755803\n",
      "\n",
      "Calculating validation metrics... Time 6.637977600097656 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [39:32<1:09:12, 593.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.72468, f1 0.7139116338999959\n",
      "Final test metrics: {'accuracy': 0.72416, 'f1': 0.7132878762680857}, Time 12.178344980875652 min\n",
      "\n",
      "Writer: runs/May15_08-19-12_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.05_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.1909635861714681 min\n",
      "Loss               : 0.6384822130203247\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.5250666666666667, f1: 0.4601394361927857\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.5131717483202616 min\n",
      "Loss               : 0.7300280332565308\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6512, f1: 0.6414473684210525\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.803376424312591 min\n",
      "Loss               : 0.6986559629440308\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6890666666666667, f1: 0.7293407613741875\n",
      "\n",
      "Calculating validation metrics... Time 6.891248905658722 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [52:00<1:02:24, 624.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.71352, f1 0.7213229571984435\n",
      "Final test metrics: {'accuracy': 0.718, 'f1': 0.7265746199193299}, Time 12.454665855566661 min\n",
      "\n",
      "Writer: runs/May15_08-31-40_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.075_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.18850224415461223 min\n",
      "Loss               : 0.7039552927017212\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.4944, f1: 0.027692307692307693\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.49138286113739 min\n",
      "Loss               : 0.6377542018890381\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6290666666666667, f1: 0.5765601217656011\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.781709869702657 min\n",
      "Loss               : 0.2550310492515564\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6768, f1: 0.6992555831265509\n",
      "\n",
      "Calculating validation metrics... Time 6.863145315647126 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [1:02:42<52:15, 627.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.70052, f1 0.700052081246745\n",
      "Final test metrics: {'accuracy': 0.69848, 'f1': 0.6970013666693464}, Time 10.69947506984075 min\n",
      "\n",
      "Writer: runs/May15_08-42-22_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.1_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.13867592016855876 min\n",
      "Loss               : 0.6907225847244263\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.4965333333333333, f1: 0.06069651741293532\n",
      "\n",
      "Epoch 10. Global step 7315. T=1.846001962820689 min\n",
      "Loss               : 0.7267296314239502\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6381333333333333, f1: 0.6452287581699346\n",
      "\n",
      "Epoch 20. Global step 13965. T=3.5540513396263123 min\n",
      "Loss               : 0.43835192918777466\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6690666666666667, f1: 0.6641407307171854\n",
      "\n",
      "Calculating validation metrics... Time 5.107692666848501 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [1:12:59<41:42, 625.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.68364, f1 0.7032826861752016\n",
      "Final test metrics: {'accuracy': 0.68432, 'f1': 0.7030850263355906}, Time 10.29462761481603 min\n",
      "\n",
      "Writer: runs/May15_08-52-39_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.125_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.19807033538818358 min\n",
      "Loss               : 0.6840479969978333\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.512, f1: 0.49053452115812923\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.539535431067149 min\n",
      "Loss               : 0.7711414694786072\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6210666666666667, f1: 0.6148007590132827\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.8980390985806785 min\n",
      "Loss               : 0.3088642954826355\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.6429333333333334, f1: 0.6181921870544625\n",
      "\n",
      "Calculating validation metrics... Time 7.056734299659729 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [1:25:33<32:05, 641.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.64968, f1 0.7045209176788125\n",
      "Final test metrics: {'accuracy': 0.64888, 'f1': 0.7034860154033239}, Time 12.564697790145875 min\n",
      "\n",
      "Writer: runs/May15_09-05-13_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.15_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.2069850961367289 min\n",
      "Loss               : 0.6446655988693237\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.4925333333333333, f1: 0.011428571428571427\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.566296072800954 min\n",
      "Loss               : 0.6213182806968689\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.572, f1: 0.682618153055171\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.950214680035909 min\n",
      "Loss               : 1.0378543138504028\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.6488, f1: 0.6651411136536994\n",
      "\n",
      "Calculating validation metrics... Time 7.120599893728892 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 9/11 [1:38:14<21:49, 654.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.64324, f1 0.5904018369690012\n",
      "Final test metrics: {'accuracy': 0.64836, 'f1': 0.5950154328096928}, Time 12.672563286622365 min\n",
      "\n",
      "Writer: runs/May15_09-17-54_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.175_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.20301238298416138 min\n",
      "Loss               : 0.6737090349197388\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5053333333333333, f1: 0.24501424501424499\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.6100611686706543 min\n",
      "Loss               : 0.9757543802261353\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.5677333333333333, f1: 0.6680319475732132\n",
      "\n",
      "Epoch 20. Global step 13965. T=4.964823528130849 min\n",
      "Loss               : 0.6471542716026306\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6426666666666667, f1: 0.6712463199214915\n",
      "\n",
      "Calculating validation metrics... Time 7.133025042215983 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10/11 [1:50:58<11:05, 665.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.6402, f1 0.5819195909830351\n",
      "Final test metrics: {'accuracy': 0.636, 'f1': 0.5778829204935523}, Time 12.74777292807897 min\n",
      "\n",
      "Writer: runs/May15_09-30-39_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.2_dropout0.5_filters64_cnn_kernel5\n",
      "Epoch 0. Global step 665. T=0.20064572095870972 min\n",
      "Loss               : 0.7360313534736633\n",
      "In-batch accuracy  : 0.0\n",
      "Validation accuracy: 0.4984, f1: 0.11648661343353689\n",
      "\n",
      "Epoch 10. Global step 7315. T=2.6507937868436175 min\n",
      "Loss               : 0.6601804494857788\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5901333333333333, f1: 0.6233766233766234\n",
      "\n",
      "Epoch 20. Global step 13965. T=5.0814787228902185 min\n",
      "Loss               : 0.7808637619018555\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6293333333333333, f1: 0.6249325418240691\n",
      "\n",
      "Calculating validation metrics... Time 7.280388518174489 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [2:02:25<00:00, 667.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.63912, f1 0.6476331823152632\n",
      "Final test metrics: {'accuracy': 0.64376, 'f1': 0.653139118242717}, Time 11.445397675037384 min\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4becc1709e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    init_function=init.xavier_normal, log_every=10)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/CharCNN_IMDB.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for noise_level in tqdm(NOISE_LEVELS):\n",
    "    model = run_model_with(noise_level=noise_level, n_filters=64, cnn_kernel_size=5,\n",
    "                   init_function=init.xavier_normal, log_every=10)\n",
    "\n",
    "pd.DataFrame(results).to_csv('results/CharCNN_IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('results/CharCNN_IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "1      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "2      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "3      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "4      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "5      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "6      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "7      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "8      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "9      _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "10     _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "11     _embed_smaller2_lr4_noise0_dropout0.5_filters6...\n",
       "12     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "13     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "14     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "15     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "16     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "17     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "18     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "19     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "20     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "21     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "22     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "23     _embed_smaller2_lr4_noise0.005_dropout0.5_filt...\n",
       "24     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "25     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "26     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "27     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "28     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "29     _embed_smaller2_lr4_noise0.01_dropout0.5_filte...\n",
       "                             ...                        \n",
       "102    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "103    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "104    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "105    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "106    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "107    _embed_smaller2_lr4_noise0.15_dropout0.5_filte...\n",
       "108    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "109    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "110    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "111    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "112    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "113    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "114    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "115    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "116    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "117    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "118    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "119    _embed_smaller2_lr4_noise0.175_dropout0.5_filt...\n",
       "120    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "121    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "122    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "123    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "124    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "125    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "126    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "127    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "128    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "129    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "130    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "131    _embed_smaller2_lr4_noise0.2_dropout0.5_filter...\n",
       "Name: run_name, Length: 132, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)['run_name'].str[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May13_20-49-28_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3843465248743693 min\n",
      "Loss               : 0.4333800673484802\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7009443218052489, f1: 0.7026400829217732\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7659179250399272 min\n",
      "Loss               : 0.5420602560043335\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7258707382879568, f1: 0.7406376004409249\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1522807518641154 min\n",
      "Loss               : 0.3842434287071228\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7401888643610498, f1: 0.7459679836920678\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5361450552940368 min\n",
      "Loss               : 0.5443617105484009\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7494787834191807, f1: 0.753194188540188\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9242071827252707 min\n",
      "Loss               : 0.5320109128952026\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7582474858964925, f1: 0.7604581219430689\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.309605606396993 min\n",
      "Loss               : 0.5363168716430664\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7599644346333088, f1: 0.7739700320466554\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.6934273799260455 min\n",
      "Loss               : 0.5815877914428711\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7633676723080697, f1: 0.7652390801800705\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.0779828985532123 min\n",
      "Loss               : 0.4385793209075928\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.765728476821192, f1: 0.7599811528192241\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.463246297836304 min\n",
      "Loss               : 0.5213488936424255\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7653605592347315, f1: 0.7587098401488162\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.85017485221227 min\n",
      "Loss               : 0.29920411109924316\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7701434878587197, f1: 0.772756206238065\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.235769073168437 min\n",
      "Loss               : 0.38711151480674744\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7700515084621045, f1: 0.7649492290334711\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.6201080242792765 min\n",
      "Loss               : 0.49888333678245544\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7711552612214864, f1: 0.7689164086687306\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.004334493478139 min\n",
      "Loss               : 0.5542212724685669\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7711859210203581, f1: 0.764729989596797\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.391256662209829 min\n",
      "Loss               : 0.31682249903678894\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7745584988962473, f1: 0.7753093964858672\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.777279289563497 min\n",
      "Loss               : 0.39297616481781006\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7744665194996321, f1: 0.7730890246159541\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.162395719687144 min\n",
      "Loss               : 0.24002814292907715\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7746504782928624, f1: 0.7751193244400929\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.551410492261251 min\n",
      "Loss               : 0.3194461166858673\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7752636742702967, f1: 0.7816372735938989\n",
      "\n",
      "Epoch 17. Global step 85626. T=6.938550170262655 min\n",
      "Loss               : 0.22818046808242798\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7745278390973755, f1: 0.7817415563601828\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.32454559803009 min\n",
      "Loss               : 0.2695344388484955\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7756929114545008, f1: 0.7788525482135301\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.7109499335289 min\n",
      "Loss               : 0.24238501489162445\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7742825607064018, f1: 0.7822280068626871\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.099147673447927 min\n",
      "Loss               : 0.20705246925354004\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7753249938680402, f1: 0.7757787161128451\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.483199588457744 min\n",
      "Loss               : 0.16050870716571808\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7741292617120432, f1: 0.7779218038766467\n",
      "\n",
      "Epoch 22. Global step 109411. T=8.867450193564098 min\n",
      "Loss               : 0.3248004615306854\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7729641893549178, f1: 0.7725667250222672\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.257288102308909 min\n",
      "Loss               : 0.6849824786186218\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7721976943831248, f1: 0.7746846191169334\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.644729701677958 min\n",
      "Loss               : 0.09623543918132782\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7685491783173902, f1: 0.7838263509063315\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.03105741739273 min\n",
      "Loss               : 0.1342834085226059\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7734547461368654, f1: 0.7795973154362416\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.419286672274271 min\n",
      "Loss               : 0.17246052622795105\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7726882511650723, f1: 0.7791480488531426\n",
      "\n",
      "Epoch 27. Global step 133196. T=10.802682566642762 min\n",
      "Loss               : 0.20893928408622742\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7725349521707138, f1: 0.776623611236564\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.192809649308522 min\n",
      "Loss               : 0.0889795571565628\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7704194260485652, f1: 0.7825657703699402\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.574804683526358 min\n",
      "Loss               : 0.16153602302074432\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7714005396124601, f1: 0.7708947885939037\n",
      "\n",
      "Calculating validation metrics... Time 11.628193136056264 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "  9%|▉         | 1/11 [13:23<2:13:50, 803.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7708793230316409, f1 0.7708582467114341\n",
      "Final test metrics: {'f1': 0.7698217578365089, 'accuracy': 0.7703581064508217}, Time 13.3831045627594 min\n",
      "\n",
      "Writer: runs/May13_21-02-50_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.005_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.33614275058110554 min\n",
      "Loss               : 0.5651463270187378\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7065857247976454, f1: 0.7015716602220281\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.730189315478007 min\n",
      "Loss               : 0.44066038727760315\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7267905322541084, f1: 0.7325389440826006\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1234610994656882 min\n",
      "Loss               : 0.7339755296707153\n",
      "In-batch accuracy  : 0.4375\n",
      "Validation accuracy: 0.7391464311994114, f1: 0.7312867159370855\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5168570677439372 min\n",
      "Loss               : 0.44902440905570984\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7451250919793966, f1: 0.7341796437821764\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9152692914009095 min\n",
      "Loss               : 0.6318662762641907\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7510424331616384, f1: 0.7394429469901168\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.308656299114227 min\n",
      "Loss               : 0.5571317672729492\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7542310522442973, f1: 0.7706175241801637\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.7059864322344462 min\n",
      "Loss               : 0.4929240345954895\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7619573215599705, f1: 0.7615918442547442\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.104508558909098 min\n",
      "Loss               : 0.5565195679664612\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7580941869021339, f1: 0.7449243501875081\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.4984557549158732 min\n",
      "Loss               : 0.5844127535820007\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7659737552121658, f1: 0.7731716739472824\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.891846827665965 min\n",
      "Loss               : 0.48699721693992615\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7695609516801569, f1: 0.773081335668136\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.291704257329305 min\n",
      "Loss               : 0.35325735807418823\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7712472406181016, f1: 0.778926783015793\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.685101560751597 min\n",
      "Loss               : 0.5571887493133545\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7729641893549178, f1: 0.7729154527891072\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.080173714955648 min\n",
      "Loss               : 0.3465290069580078\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7738839833210694, f1: 0.7840473192585868\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.469327620665232 min\n",
      "Loss               : 0.30555638670921326\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7750490556781947, f1: 0.7735144312393888\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.863124612967173 min\n",
      "Loss               : 0.24142229557037354\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7770419426048565, f1: 0.7824578197917913\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.257698372999827 min\n",
      "Loss               : 0.52869713306427\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7773792003924455, f1: 0.7800963081861958\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.652474387486776 min\n",
      "Loss               : 0.7759470343589783\n",
      "In-batch accuracy  : 0.4375\n",
      "Validation accuracy: 0.7769499632082414, f1: 0.7803906179249555\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.048986868063609 min\n",
      "Loss               : 0.5397497415542603\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7766740250183959, f1: 0.7735215471674647\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.445104690392812 min\n",
      "Loss               : 0.44683578610420227\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7761528084375766, f1: 0.7856366892744943\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.840273209412893 min\n",
      "Loss               : 0.5904470086097717\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7748037772872209, f1: 0.7699006923342\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.234397701422374 min\n",
      "Loss               : 0.34835731983184814\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7749877360804514, f1: 0.7665935184301751\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.632212154070537 min\n",
      "Loss               : 0.4135739505290985\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7769806230071131, f1: 0.775035566276984\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.030263658364614 min\n",
      "Loss               : 0.3558211922645569\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7804145204807457, f1: 0.7819388625015224\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.424487268924713 min\n",
      "Loss               : 0.48741862177848816\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7784216335540839, f1: 0.7745859455413119\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.821397002538045 min\n",
      "Loss               : 0.333686888217926\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7790961491292617, f1: 0.7788995611747016\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.211908475557964 min\n",
      "Loss               : 0.32134363055229187\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7784216335540839, f1: 0.7789029277694496\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.608434410889943 min\n",
      "Loss               : 0.5748730301856995\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7798933038999264, f1: 0.7741529556107843\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.004286964734396 min\n",
      "Loss               : 0.24457520246505737\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7761834682364483, f1: 0.7798021235521235\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.399949749310812 min\n",
      "Loss               : 0.23962560296058655\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.7809970566593083, f1: 0.7793122624895727\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.801846583684286 min\n",
      "Loss               : 0.38517868518829346\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7814262938435124, f1: 0.7858709037935901\n",
      "\n",
      "Calculating validation metrics... Time 11.861878323554993 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 2/11 [27:02<2:01:40, 811.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7758462104488595, f1 0.7813500014953495\n",
      "Final test metrics: {'f1': 0.7857743097238895, 'accuracy': 0.7811503556536669}, Time 13.655587859948476 min\n",
      "\n",
      "Writer: runs/May13_21-16-29_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.01_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3356864054997762 min\n",
      "Loss               : 0.42460814118385315\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.6925741967132696, f1: 0.7160857377466943\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7333456357320149 min\n",
      "Loss               : 0.4754043519496918\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7175925925925926, f1: 0.7123629891015832\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1282407283782958 min\n",
      "Loss               : 0.5356807708740234\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7306230071130734, f1: 0.7163793660016785\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5222609519958497 min\n",
      "Loss               : 0.45465928316116333\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7419671326956095, f1: 0.7328932334645171\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9195545077323914 min\n",
      "Loss               : 0.4870145320892334\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7478231542801079, f1: 0.7528025726565082\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.3155498425165812 min\n",
      "Loss               : 0.45558962225914\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7548442482217317, f1: 0.758574879227053\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.7102791110674542 min\n",
      "Loss               : 0.4405940771102905\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7581248467010057, f1: 0.7604966756732142\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.104080565770467 min\n",
      "Loss               : 0.4105156362056732\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7618653421633554, f1: 0.7598404502025292\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.4988065004348754 min\n",
      "Loss               : 0.3126904368400574\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7620799607554575, f1: 0.7551278005680025\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.8927832802136737 min\n",
      "Loss               : 0.5416765213012695\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7609148883983321, f1: 0.7470481380563125\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.294664712746938 min\n",
      "Loss               : 0.5051099061965942\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7697142506745156, f1: 0.7743427970557307\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.688309848308563 min\n",
      "Loss               : 0.4413260519504547\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7705114054451803, f1: 0.7726375261990827\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.085168778896332 min\n",
      "Loss               : 0.2015499472618103\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7714311994113319, f1: 0.7740566752538264\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.4792371471722925 min\n",
      "Loss               : 0.5096214413642883\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7712779004169733, f1: 0.7699518934254348\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.874595713615418 min\n",
      "Loss               : 0.5058510899543762\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7717684571989207, f1: 0.7788735741444867\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.27468714316686 min\n",
      "Loss               : 0.3085242807865143\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7690703948982095, f1: 0.7581867214588417\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.667056914170583 min\n",
      "Loss               : 0.6276507377624512\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7731174883492764, f1: 0.7836130767881163\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.06212884982427 min\n",
      "Loss               : 0.48209115862846375\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7772872209958303, f1: 0.7795982765944535\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.455897883574168 min\n",
      "Loss               : 0.4442633092403412\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7742825607064018, f1: 0.7839661951992488\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.851000622908274 min\n",
      "Loss               : 0.6431087851524353\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7745278390973755, f1: 0.7710460772104607\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.2540207862854 min\n",
      "Loss               : 0.6362152099609375\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7766127054206524, f1: 0.7820650873414692\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.650644437472026 min\n",
      "Loss               : 0.43084168434143066\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7754169732646554, f1: 0.7878840529348741\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.04480084180832 min\n",
      "Loss               : 0.46916431188583374\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7786055923473142, f1: 0.7854787439470009\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.43929660320282 min\n",
      "Loss               : 0.5479443073272705\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7773792003924455, f1: 0.7878451424397371\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.833872052033742 min\n",
      "Loss               : 0.29326361417770386\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7793107677213638, f1: 0.7810427693618057\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.225476845105488 min\n",
      "Loss               : 0.19969697296619415\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7755396124601422, f1: 0.7876801716887561\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.61974804798762 min\n",
      "Loss               : 0.3886418044567108\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7787588913416728, f1: 0.7802278126332459\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.012024303277334 min\n",
      "Loss               : 0.6277426481246948\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7793414275202355, f1: 0.7836854918697965\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.410574245452882 min\n",
      "Loss               : 0.2625010907649994\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7764900662251656, f1: 0.7874015748031495\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.801577226320903 min\n",
      "Loss               : 0.4672672748565674\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7778697571743929, f1: 0.7753140021708792\n",
      "\n",
      "Calculating validation metrics... Time 11.862402482827504 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [40:40<1:48:28, 813.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7776857983811626, f1 0.7763210661072893\n",
      "Final test metrics: {'f1': 0.7766152317675185, 'accuracy': 0.7794027471179789}, Time 13.64095369974772 min\n",
      "\n",
      "Writer: runs/May13_21-30-07_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.025_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.33512759606043496 min\n",
      "Loss               : 0.4829114079475403\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.6939845474613686, f1: 0.6782709602552944\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7303391377131144 min\n",
      "Loss               : 0.7523029446601868\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.719401520726024, f1: 0.7205496183206106\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.121863806247711 min\n",
      "Loss               : 0.5633825063705444\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7240618101545254, f1: 0.7209821428571429\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.515214463075002 min\n",
      "Loss               : 0.2992437481880188\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7322173166544027, f1: 0.7431629712403695\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9088869015375773 min\n",
      "Loss               : 0.5390042662620544\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7406487613441256, f1: 0.750051709363827\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.3044729113578795 min\n",
      "Loss               : 0.5270489454269409\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.74518641157714, f1: 0.7434639009784857\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.6980138937632243 min\n",
      "Loss               : 0.6597767472267151\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7496320824135394, f1: 0.7587307215032796\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.0933234214782717 min\n",
      "Loss               : 0.3861367106437683\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7535258768702477, f1: 0.7433187521951532\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.4931156357129414 min\n",
      "Loss               : 0.49785375595092773\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7530353200883002, f1: 0.7445857247043157\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.8858217636744183 min\n",
      "Loss               : 0.5233050584793091\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.756561196958548, f1: 0.7659612096916818\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.2817905187606815 min\n",
      "Loss               : 0.39752835035324097\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7576956095168016, f1: 0.7714376608728345\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.679212971528371 min\n",
      "Loss               : 0.4889654219150543\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7608229090017169, f1: 0.7555235200100286\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.073926798502604 min\n",
      "Loss               : 0.3361785411834717\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7623558989453029, f1: 0.7538036400597148\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.470042622089386 min\n",
      "Loss               : 0.39806410670280457\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7610068677949473, f1: 0.7589597699372275\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.867123778661092 min\n",
      "Loss               : 0.38026392459869385\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7649926416482707, f1: 0.7651726356422903\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.263256168365478 min\n",
      "Loss               : 0.3370298445224762\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7641954868776061, f1: 0.7682665943535508\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.6605406125386555 min\n",
      "Loss               : 0.3120829463005066\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7641954868776061, f1: 0.7716381127705693\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.055831396579743 min\n",
      "Loss               : 0.5029163360595703\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7705114054451803, f1: 0.7727479734037707\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.4475409110387165 min\n",
      "Loss               : 0.33314308524131775\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7699901888643611, f1: 0.7738726790450927\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.841483771800995 min\n",
      "Loss               : 0.4105178117752075\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.767046848172676, f1: 0.7629329173166928\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.23557417790095 min\n",
      "Loss               : 0.34931981563568115\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7691623742948246, f1: 0.7763685508064276\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.633587316672008 min\n",
      "Loss               : 0.3676154613494873\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7678746627422124, f1: 0.7592304022897122\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.026073424021403 min\n",
      "Loss               : 0.4632571339607239\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7671081677704195, f1: 0.7643335815338793\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.42160667181015 min\n",
      "Loss               : 0.37968873977661133\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7696222712779004, f1: 0.769692882976767\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.818184232711792 min\n",
      "Loss               : 0.23911096155643463\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7695916114790287, f1: 0.7824324715555426\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.209994836648304 min\n",
      "Loss               : 0.37322378158569336\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7712472406181016, f1: 0.7688303640588691\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.6070396900177 min\n",
      "Loss               : 0.45869916677474976\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7711859210203581, f1: 0.772822745121914\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.004213237762452 min\n",
      "Loss               : 0.4636535942554474\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7687637969094923, f1: 0.7705646142613776\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.401284925142924 min\n",
      "Loss               : 0.1847708523273468\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7708793230316409, f1: 0.7803286398777154\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.796859399477642 min\n",
      "Loss               : 0.43490612506866455\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7742212411086583, f1: 0.7807027992852889\n",
      "\n",
      "Calculating validation metrics... Time 11.857102191448211 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [54:19<1:35:03, 814.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7736080451312239, f1 0.7806689241371116\n",
      "Final test metrics: {'f1': 0.7788470132578579, 'accuracy': 0.7724123129752268}, Time 13.639712619781495 min\n",
      "\n",
      "Writer: runs/May13_21-43-46_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.05_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3341816544532776 min\n",
      "Loss               : 0.729953408241272\n",
      "In-batch accuracy  : 0.4375\n",
      "Validation accuracy: 0.6847559480009812, f1: 0.6779023870684794\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7405523379643758 min\n",
      "Loss               : 0.5235426425933838\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7006990434142752, f1: 0.7061585696225392\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1382336338361105 min\n",
      "Loss               : 0.5956830978393555\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7155077262693157, f1: 0.7156385032637677\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5346531748771668 min\n",
      "Loss               : 0.725429892539978\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7201680156978171, f1: 0.698490304251594\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9329213579495748 min\n",
      "Loss               : 0.5004796385765076\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7278942850134903, f1: 0.711447800500699\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.325188036759694 min\n",
      "Loss               : 0.5262130498886108\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7330757910228108, f1: 0.7281753465717498\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.7200137933095294 min\n",
      "Loss               : 0.5094314217567444\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7396369879813588, f1: 0.7454741637693322\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.1167501330375673 min\n",
      "Loss               : 0.6893176436424255\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7419058130978661, f1: 0.7413348082595871\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.511898624897003 min\n",
      "Loss               : 0.5471055507659912\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7427029678685307, f1: 0.7306284907235026\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.9042433698972068 min\n",
      "Loss               : 0.40692415833473206\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7475778758891342, f1: 0.7551524163568774\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.299990554650624 min\n",
      "Loss               : 0.5334797501564026\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7488042678440029, f1: 0.7453296447110752\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.699126589298248 min\n",
      "Loss               : 0.5456634163856506\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7483750306597988, f1: 0.7601204220617893\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.095868504047393 min\n",
      "Loss               : 0.4591704308986664\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7500919793966152, f1: 0.7576199113860062\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.493030412991842 min\n",
      "Loss               : 0.5115214586257935\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7521768457198921, f1: 0.7510088408341805\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.88898065884908 min\n",
      "Loss               : 0.44884663820266724\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7530353200883002, f1: 0.7562562411111448\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.285924355189006 min\n",
      "Loss               : 0.40286409854888916\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7529740004905567, f1: 0.748697794828608\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.6842475771903995 min\n",
      "Loss               : 0.5848945379257202\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7538324748589649, f1: 0.7678473326586671\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.082632756233215 min\n",
      "Loss               : 0.3904579281806946\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7590753004660289, f1: 0.7664506925043095\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.479707554976145 min\n",
      "Loss               : 0.5197467803955078\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7566225165562914, f1: 0.7562189054726368\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.874175715446472 min\n",
      "Loss               : 0.5031926035881042\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7522688251165073, f1: 0.7469939879759518\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.26851756175359 min\n",
      "Loss               : 0.34155184030532837\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7588913416727986, f1: 0.7534950786784529\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.663556969165802 min\n",
      "Loss               : 0.5814664363861084\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7589526612705421, f1: 0.768369571622179\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.06027982632319 min\n",
      "Loss               : 0.564548671245575\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7580941869021339, f1: 0.7502690384250174\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.452960920333862 min\n",
      "Loss               : 0.42716479301452637\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7645940642629384, f1: 0.771038349138188\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.845976626873016 min\n",
      "Loss               : 0.3002511262893677\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7611295069904341, f1: 0.7596631397106458\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.240988262494405 min\n",
      "Loss               : 0.358410120010376\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.758523424086338, f1: 0.759760858955588\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.632826085885366 min\n",
      "Loss               : 0.3048587143421173\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7621412803532008, f1: 0.7605259908630696\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.029425323009491 min\n",
      "Loss               : 0.6226557493209839\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7615894039735099, f1: 0.7586891757696128\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.423419551054637 min\n",
      "Loss               : 0.46488890051841736\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7611295069904341, f1: 0.7696537858853443\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.818726599216461 min\n",
      "Loss               : 0.5223202109336853\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7578795683100319, f1: 0.75147128245476\n",
      "\n",
      "Calculating validation metrics... Time 11.879789598782857 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 5/11 [1:07:58<1:21:34, 815.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7624172185430463, f1 0.7570465590217903\n",
      "Final test metrics: {'f1': 0.7541622164980838, 'accuracy': 0.760056414029924}, Time 13.656627666950225 min\n",
      "\n",
      "Writer: runs/May13_21-57-25_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.075_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3359651565551758 min\n",
      "Loss               : 0.6112332344055176\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.6780107922492028, f1: 0.6744575325480471\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7363389531771342 min\n",
      "Loss               : 0.7393947839736938\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.6967745891586952, f1: 0.7033415321854941\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.135967202981313 min\n",
      "Loss               : 0.4217904806137085\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7073522197694383, f1: 0.7064612356613464\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.537773108482361 min\n",
      "Loss               : 0.46832719445228577\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7131162619573216, f1: 0.7046681185493797\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.937010125319163 min\n",
      "Loss               : 0.6322650909423828\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.71897228354182, f1: 0.7066316732812701\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.33837118546168 min\n",
      "Loss               : 0.4346279799938202\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7167034584253127, f1: 0.6889098377213656\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.7406588554382325 min\n",
      "Loss               : 0.4933357834815979\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7275570272259014, f1: 0.7190819423368741\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.1475930054982504 min\n",
      "Loss               : 0.6792982816696167\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7337503065979887, f1: 0.7400000000000001\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.5487968285878497 min\n",
      "Loss               : 0.31647053360939026\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7326158940397351, f1: 0.7389000329331458\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.9493005355199178 min\n",
      "Loss               : 0.5023236274719238\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.736233750306598, f1: 0.735544557499001\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.352257835865021 min\n",
      "Loss               : 0.5209116339683533\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7370309050772627, f1: 0.7338401861908456\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.7532735705375675 min\n",
      "Loss               : 0.40593090653419495\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7327998528329654, f1: 0.7117006847729002\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.14974315961202 min\n",
      "Loss               : 0.44776326417922974\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7423963698798136, f1: 0.7443247519931836\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.545420543352763 min\n",
      "Loss               : 0.5936225652694702\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7413845965170468, f1: 0.7522105696072384\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.939186803499857 min\n",
      "Loss               : 0.5190100073814392\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7444812362030905, f1: 0.7530373970248325\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.33459567228953 min\n",
      "Loss               : 0.4193543791770935\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7447878341918077, f1: 0.7535090316849274\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.729273498058319 min\n",
      "Loss               : 0.5282912850379944\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.743009565857248, f1: 0.7464456409946155\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.1225190679232275 min\n",
      "Loss               : 0.4755527079105377\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7410779985283297, f1: 0.7265662943176299\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.5169413685798645 min\n",
      "Loss               : 0.42642706632614136\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7449411331861663, f1: 0.7364819918274257\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.911834462483724 min\n",
      "Loss               : 0.37589383125305176\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7500919793966152, f1: 0.750573762967043\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.309842157363892 min\n",
      "Loss               : 0.5394952893257141\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7500919793966152, f1: 0.7567954647172908\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.708964633941651 min\n",
      "Loss               : 0.6119178533554077\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7501839587932303, f1: 0.7462314687928242\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.106770924727122 min\n",
      "Loss               : 0.46816083788871765\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.753280598479274, f1: 0.7562180011512011\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.50183842976888 min\n",
      "Loss               : 0.5148224830627441\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7503679175864606, f1: 0.7436720816018134\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.899832173188527 min\n",
      "Loss               : 0.6140835881233215\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7511037527593819, f1: 0.7505837532260047\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.296610450744629 min\n",
      "Loss               : 0.5903403759002686\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7531886190826588, f1: 0.7496890547263682\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.695574096838634 min\n",
      "Loss               : 0.5601959228515625\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7522688251165073, f1: 0.7633136094674555\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.093800063927969 min\n",
      "Loss               : 0.5241153240203857\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7503985773853323, f1: 0.7437922895357987\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.487229363123577 min\n",
      "Loss               : 0.4461207091808319\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7523914643119941, f1: 0.7562330214307273\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.88085651397705 min\n",
      "Loss               : 0.5195601582527161\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7539551140544518, f1: 0.7481246665201972\n",
      "\n",
      "Calculating validation metrics... Time 11.941277774175008 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 6/11 [1:21:42<1:08:05, 817.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7520848663232769, f1 0.7467268057382698\n",
      "Final test metrics: {'f1': 0.747085370440015, 'accuracy': 0.7525754231052244}, Time 13.732470726966858 min\n",
      "\n",
      "Writer: runs/May13_22-11-09_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.1_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3339157819747925 min\n",
      "Loss               : 0.6387908458709717\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.6652563159185676, f1: 0.6376128518321826\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7288359483083089 min\n",
      "Loss               : 0.5573965907096863\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.6880978660779985, f1: 0.6895730981660614\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1228139638900756 min\n",
      "Loss               : 0.56484055519104\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.6984608780966397, f1: 0.7121491497643926\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5152902722358703 min\n",
      "Loss               : 0.5416707992553711\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7037650233014472, f1: 0.6862987012987013\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9115082939465842 min\n",
      "Loss               : 0.5218300819396973\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7133922001471671, f1: 0.708639820471263\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.308312670389811 min\n",
      "Loss               : 0.6031030416488647\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7128403237674761, f1: 0.702930728241563\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.702000880241394 min\n",
      "Loss               : 0.5285276174545288\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7177152317880795, f1: 0.7270301520946367\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.0954360802968344 min\n",
      "Loss               : 0.3732573688030243\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7227127790041697, f1: 0.7174632927210248\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.4898500442504883 min\n",
      "Loss               : 0.44534459710121155\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7250122639195486, f1: 0.7285000756773119\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.88637691338857 min\n",
      "Loss               : 0.42064374685287476\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7212104488594555, f1: 0.7013695031035502\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.280061499277751 min\n",
      "Loss               : 0.5371447801589966\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7274037282315428, f1: 0.7160604221888672\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.6772532025973 min\n",
      "Loss               : 0.47614240646362305\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7333210694137846, f1: 0.7285437862805069\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.0721443096796675 min\n",
      "Loss               : 0.4294814169406891\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.7355285749325484, f1: 0.7378274876907178\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.84357277949651 min\n",
      "Loss               : 0.4262239634990692\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7407407407407407, f1: 0.734705402522432\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.243363658587137 min\n",
      "Loss               : 0.3874756991863251\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.739943585970076, f1: 0.7547846198323215\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.636056490739186 min\n",
      "Loss               : 0.32091274857521057\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7427949472651459, f1: 0.7405918550357155\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.03303618033727 min\n",
      "Loss               : 0.5931413769721985\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7440826588177581, f1: 0.7351251864309968\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.43020838101705 min\n",
      "Loss               : 0.48335105180740356\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7477311748834927, f1: 0.747235192922094\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.82561161518097 min\n",
      "Loss               : 0.3678533434867859\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7472099583026736, f1: 0.7492625368731564\n",
      "\n",
      "Calculating validation metrics... Time 11.888608888785045 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 7/11 [1:35:23<54:30, 817.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7443279372087319, f1 0.7473413119224359\n",
      "Final test metrics: {'f1': 0.7461721466479594, 'accuracy': 0.7448491537895512}, Time 13.681911969184876 min\n",
      "\n",
      "Writer: runs/May13_22-24-50_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.125_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3358120242754618 min\n",
      "Loss               : 0.5713484287261963\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.6546786853078244, f1: 0.6060097247000386\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7310911774635315 min\n",
      "Loss               : 0.4563905894756317\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.6788999264164827, f1: 0.6470528763522394\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.1284239172935486 min\n",
      "Loss               : 0.5607260465621948\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.6932180524895757, f1: 0.681601221918157\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.5249507109324136 min\n",
      "Loss               : 0.47985750436782837\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.6982769193034094, f1: 0.7001066585403017\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.9204196254412333 min\n",
      "Loss               : 0.840850830078125\n",
      "In-batch accuracy  : 0.3125\n",
      "Validation accuracy: 0.7045928378709836, f1: 0.7158068607497862\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.319960590203603 min\n",
      "Loss               : 0.6837022304534912\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.7110620554329163, f1: 0.7057758351545425\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.717822484175364 min\n",
      "Loss               : 0.6665555238723755\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7094677458915869, f1: 0.7202409069437884\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.1125543395678203 min\n",
      "Loss               : 0.5630872845649719\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7176232523914643, f1: 0.723406811219893\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.511517858505249 min\n",
      "Loss               : 0.4201875329017639\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7181138091734118, f1: 0.7169334975369459\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.9084872722625734 min\n",
      "Loss               : 0.4430161714553833\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7150784890851116, f1: 0.6988560873651123\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.306177151203156 min\n",
      "Loss               : 0.5838990211486816\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7244603875398578, f1: 0.7321071928935523\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.703210322062175 min\n",
      "Loss               : 0.4086836576461792\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.7225288202109394, f1: 0.7171875000000001\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.101373485724131 min\n",
      "Loss               : 0.5325868725776672\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7238471915624234, f1: 0.7274652788284063\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.50034206310908 min\n",
      "Loss               : 0.6532344818115234\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7282008830022075, f1: 0.7264479896318697\n",
      "\n",
      "Epoch 14. Global step 71355. T=5.895140274365743 min\n",
      "Loss               : 0.4829515814781189\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7264532744665195, f1: 0.7263022271304989\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.288484489917755 min\n",
      "Loss               : 0.477791965007782\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7273730684326711, f1: 0.7348837209302326\n",
      "\n",
      "Epoch 16. Global step 80869. T=6.685414886474609 min\n",
      "Loss               : 0.4823782444000244\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7295805739514348, f1: 0.7307527932108187\n",
      "\n",
      "Epoch 17. Global step 85626. T=7.079424548149109 min\n",
      "Loss               : 0.5119428634643555\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7301017905322541, f1: 0.7383563679595779\n",
      "\n",
      "Epoch 18. Global step 90383. T=7.473737363020579 min\n",
      "Loss               : 0.4508906602859497\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7339342653912191, f1: 0.7266427266427267\n",
      "\n",
      "Epoch 19. Global step 95140. T=7.867295809586843 min\n",
      "Loss               : 0.5940606594085693\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7353139563404464, f1: 0.7373353211427877\n",
      "\n",
      "Epoch 20. Global step 99897. T=8.258481403191885 min\n",
      "Loss               : 0.47765350341796875\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7349460387539858, f1: 0.7398983061046424\n",
      "\n",
      "Epoch 21. Global step 104654. T=8.655344593524934 min\n",
      "Loss               : 0.5326293110847473\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.7328305126318372, f1: 0.7422960903767669\n",
      "\n",
      "Epoch 22. Global step 109411. T=9.046945722897847 min\n",
      "Loss               : 0.703669548034668\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.7343635025754232, f1: 0.7423422351751621\n",
      "\n",
      "Epoch 23. Global step 114168. T=9.443404428164165 min\n",
      "Loss               : 0.5378830432891846\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7354365955359333, f1: 0.7396433636061914\n",
      "\n",
      "Epoch 24. Global step 118925. T=9.841305979092915 min\n",
      "Loss               : 0.46449217200279236\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7351913171449596, f1: 0.7341070713911892\n",
      "\n",
      "Epoch 25. Global step 123682. T=10.23295427163442 min\n",
      "Loss               : 0.6475061774253845\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7376134412558254, f1: 0.7475665152498377\n",
      "\n",
      "Epoch 26. Global step 128439. T=10.627320984999338 min\n",
      "Loss               : 0.6067520380020142\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7363257297032132, f1: 0.74781537739722\n",
      "\n",
      "Epoch 27. Global step 133196. T=11.022606499989827 min\n",
      "Loss               : 0.7572207450866699\n",
      "In-batch accuracy  : 0.375\n",
      "Validation accuracy: 0.7341488839833211, f1: 0.7284116891659097\n",
      "\n",
      "Epoch 28. Global step 137953. T=11.417939241727193 min\n",
      "Loss               : 0.3795716166496277\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7382572970321315, f1: 0.7381850522893857\n",
      "\n",
      "Epoch 29. Global step 142710. T=11.811171519756318 min\n",
      "Loss               : 0.5764259696006775\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7350993377483444, f1: 0.7396335583413693\n",
      "\n",
      "Calculating validation metrics... Time 11.871801356474558 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 8/11 [1:49:02<40:53, 817.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.7375521216580819, f1 0.7441874364951288\n",
      "Final test metrics: {'f1': 0.7404779798587104, 'accuracy': 0.7353139563404464}, Time 13.654931231339772 min\n",
      "\n",
      "Writer: runs/May13_22-38-29_phobos-aijun_charCNN_embed_smaller2_lr4_noise0.15_dropout0.5_no_emoji\n",
      "Epoch 0. Global step 4757. T=0.3329009493192037 min\n",
      "Loss               : 0.622446596622467\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.6607799852832965, f1: 0.6651737077835613\n",
      "\n",
      "Epoch 1. Global step 9514. T=0.7281931877136231 min\n",
      "Loss               : 0.6457914113998413\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.6765391219033603, f1: 0.6775869445632907\n",
      "\n",
      "Epoch 2. Global step 14271. T=1.123043922583262 min\n",
      "Loss               : 0.5680097341537476\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.6869941133186166, f1: 0.6813769857370245\n",
      "\n",
      "Epoch 3. Global step 19028. T=1.518110485871633 min\n",
      "Loss               : 0.7019524574279785\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.6930954132940887, f1: 0.6842271293375394\n",
      "\n",
      "Epoch 4. Global step 23785. T=1.913189951578776 min\n",
      "Loss               : 0.5772716999053955\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.6962227127790042, f1: 0.6873066969639587\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.3058461785316466 min\n",
      "Loss               : 0.4012497067451477\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.6973264655383861, f1: 0.6817537072856222\n",
      "\n",
      "Epoch 6. Global step 33299. T=2.700575113296509 min\n",
      "Loss               : 0.4602878987789154\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7043475594800098, f1: 0.7164240552859873\n",
      "\n",
      "Epoch 7. Global step 38056. T=3.096491030852 min\n",
      "Loss               : 0.5603386163711548\n",
      "In-batch accuracy  : 0.5625\n",
      "Validation accuracy: 0.7068616629874908, f1: 0.6966591579682097\n",
      "\n",
      "Epoch 8. Global step 42813. T=3.4907043019930524 min\n",
      "Loss               : 0.5360425710678101\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.7068923227863625, f1: 0.69880277252678\n",
      "\n",
      "Epoch 9. Global step 47570. T=3.8913727760314942 min\n",
      "Loss               : 0.5890128016471863\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7110313956340446, f1: 0.7039236012942544\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.289673590660096 min\n",
      "Loss               : 0.6385514140129089\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7133615403482954, f1: 0.7083814217536416\n",
      "\n",
      "Epoch 11. Global step 57084. T=4.688193261623383 min\n",
      "Loss               : 0.5784770250320435\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.7148025508952661, f1: 0.7305017962683972\n",
      "\n",
      "Epoch 12. Global step 61841. T=5.087394313017527 min\n",
      "Loss               : 0.5152278542518616\n",
      "In-batch accuracy  : 0.6875\n",
      "Validation accuracy: 0.7149865096884964, f1: 0.725943396226415\n",
      "\n",
      "Epoch 13. Global step 66598. T=5.4851771831512455 min\n",
      "Loss               : 0.3477727770805359\n",
      "In-batch accuracy  : 0.875\n"
     ]
    }
   ],
   "source": [
    "for noise_level in tqdm(NOISE_LEVELS):\n",
    "    run_model_with(noise_level=noise_level, init_function=init.xavier_normal)\n",
    "pd.DataFrame(results.to_csv('results/CharCNN_mokoron_noemoji.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for noise_level in tqdm(NOISE_LEVELS):\n",
    "    run_model_with(noise_level=noise_level, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# searching for phase transition\n",
    "\n",
    "for noise_level in tqdm(np.arange(0, .01, 0.001)):\n",
    "    run_model_with(noise_level=noise_level, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_19-31-46_madrugado_charCNN_embed_smaller2_lr4_noise0_dropout0.5_spellchecked\n"
     ]
    }
   ],
   "source": [
    "for noise_level in tqdm(NOISE_LEVELS):\n",
    "    run_model_with(\n",
    "        noise_level=noise_level, init_function=init.xavier_normal, log_every=5, epochs=30, comment='_spellchecked'\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results).to_csv('CharCNN_spellchecked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('CharCNN_with_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp (other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May14_00-37-34_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout0_filters256_cnn_kernel15\n",
      "Epoch 0. Global step 217. T=0.01633059581120809 min\n",
      "Loss               : 0.6889715790748596\n",
      "In-batch accuracy  : 0.5\n",
      "Validation accuracy: 0.5114678899082569, f1: 0.6753048780487805\n",
      "\n",
      "Epoch 10. Global step 2387. T=0.21625566482543945 min\n",
      "Loss               : 0.5218710899353027\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.6731651376146789, f1: 0.7046632124352331\n",
      "\n",
      "Epoch 20. Global step 4557. T=0.4164242744445801 min\n",
      "Loss               : 0.3434000015258789\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.6869266055045872, f1: 0.7135362014690451\n",
      "\n",
      "Calculating validation metrics... Time 0.5979397575060527 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.700164744645799, f1 0.7077087794432547\n",
      "Final test metrics: {'accuracy': 0.6974190005491488, 'f1': 0.7039226222461042}, Time 0.6913856983184814 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = run_model_with(\n",
    "    noise_level=0, n_filters=256, cnn_kernel_size=15, init_function=init.xavier_normal, dropout=0, log_every=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May14_00-29-01_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout16_filters5_cnn_kernel0.5_makaron_test\n",
      "Epoch 0. Global step 217. T=0.014664558569590251 min\n",
      "Loss               : 0.7041813135147095\n",
      "In-batch accuracy  : 0.25\n",
      "Validation accuracy: 0.5126146788990825, f1: 0.6748278500382554\n",
      "\n",
      "Calculating validation metrics... Time 0.018363038698832195 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.500823723228995, f1 0.6654398233345602\n",
      "Final test metrics: {'accuracy': 0.500274574409665, 'f1': 0.6651949963208241}, Time 0.11014003753662109 min\n",
      "\n",
      "CPU times: user 5.62 s, sys: 765 ms, total: 6.39 s\n",
      "Wall time: 6.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (embedding): Linear(in_features=74, out_features=74, bias=True)\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(74, 16, kernel_size=(5,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=64, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0, n_filters=16, cnn_kernel_size=5,\n",
    "               init_function=init.xavier_normal, comment='_makaron_test', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May14_00-09-42_phobos-aijun_charCNN_embed_smaller2_lr4_noise0_dropout0.5_makaron_test\n",
      "Epoch 0. Global step 4757. T=0.3195761243502299 min\n",
      "Loss               : 0.034621015191078186\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.984271523178808, f1: 0.9844068208760144\n",
      "\n",
      "Calculating validation metrics... Time 0.3735865354537964 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phobos_aijun/.virtualenvs/pytorch-env/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: acc 0.9840569045867059, f1 0.9841839527951821\n",
      "Final test metrics: {'accuracy': 0.9840569045867059, 'f1': 0.9841897233201581}, Time 2.071729278564453 min\n",
      "\n",
      "CPU times: user 1min 49s, sys: 11.1 s, total: 2min\n",
      "Wall time: 2min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (embedding): Linear(in_features=74, out_features=74, bias=True)\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(74, 16, kernel_size=(5,), stride=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=64, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=16, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0, n_filters=16, cnn_kernel_size=5,\n",
    "               init_function=init.xavier_normal, comment='_makaron_test', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_18-45-28_madrugado_charCNN_embed_smaller2_lr4_noise0_dropout0.5\n",
      "Epoch 0. Global step 4757. T=0.34553041458129885 min\n",
      "Loss               : 1.6093254089355469e-06\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.998589649252, f1: 0.998609851919\n",
      "\n",
      "Calculating validation metrics... Time 0.3979764183362325 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.9977005150846211, 'f1': 0.99773311168203116}, Time 1.8905688643455505 min\n",
      "\n",
      "CPU times: user 1min 37s, sys: 11 s, total: 1min 48s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_14-42-03_madrugado_charCNN_embed_smaller2_lr4_noise0_dropout0.5no_emoji\n",
      "Epoch 0. Global step 4962. T=0.32575590213139854 min\n",
      "Loss               : 0.5092490911483765\n",
      "In-batch accuracy  : 0.625\n",
      "Validation accuracy: 0.716708302719, f1: 0.698149249992\n",
      "\n",
      "Epoch 1. Global step 9924. T=0.705766232808431 min\n",
      "Loss               : 0.44099992513656616\n",
      "In-batch accuracy  : 0.84375\n",
      "Validation accuracy: 0.744217487142, f1: 0.737125079288\n",
      "\n",
      "Epoch 2. Global step 14886. T=1.085922352472941 min\n",
      "Loss               : 0.3741908669471741\n",
      "In-batch accuracy  : 0.90625\n",
      "Validation accuracy: 0.75664952241, f1: 0.750962463908\n",
      "\n",
      "Epoch 3. Global step 19848. T=1.4666020234425863 min\n",
      "Loss               : 0.41205355525016785\n",
      "In-batch accuracy  : 0.78125\n",
      "Validation accuracy: 0.766789125643, f1: 0.765797939848\n",
      "\n",
      "Epoch 4. Global step 24810. T=1.847240976492564 min\n",
      "Loss               : 0.3329382538795471\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.770345334313, f1: 0.761739236492\n",
      "\n",
      "Epoch 5. Global step 29772. T=2.2268149574597675 min\n",
      "Loss               : 0.3973809480667114\n",
      "In-batch accuracy  : 0.84375\n",
      "Validation accuracy: 0.776605437179, f1: 0.779201161946\n",
      "\n",
      "Epoch 6. Global step 34734. T=2.6068729639053343 min\n",
      "Loss               : 0.3425600826740265\n",
      "In-batch accuracy  : 0.84375\n",
      "Validation accuracy: 0.776781778104, f1: 0.778694017891\n",
      "\n",
      "Epoch 7. Global step 39696. T=2.9892195105552672 min\n",
      "Loss               : 0.23578746616840363\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.778839088905, f1: 0.775353016688\n",
      "\n",
      "Epoch 8. Global step 44658. T=3.3731504241625467 min\n",
      "Loss               : 0.2545797824859619\n",
      "In-batch accuracy  : 0.90625\n",
      "Validation accuracy: 0.780808229243, f1: 0.783612835838\n",
      "\n",
      "Epoch 9. Global step 49620. T=3.7537151098251345 min\n",
      "Loss               : 0.4160690903663635\n",
      "In-batch accuracy  : 0.84375\n",
      "Validation accuracy: 0.778956649522, f1: 0.785500385021\n",
      "\n",
      "Epoch 10. Global step 54582. T=4.135397851467133 min\n",
      "Loss               : 0.3794422745704651\n",
      "In-batch accuracy  : 0.71875\n",
      "Validation accuracy: 0.767817781043, f1: 0.752614767959\n",
      "\n",
      "Epoch 11. Global step 59544. T=4.5176941076914465 min\n",
      "Loss               : 0.1121596172451973\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.776017634093, f1: 0.78710506467\n",
      "\n",
      "Epoch 12. Global step 64506. T=4.8998143951098125 min\n",
      "Loss               : 0.1779635101556778\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.775900073475, f1: 0.784086082401\n",
      "\n",
      "Epoch 13. Global step 69468. T=5.281371593475342 min\n",
      "Loss               : 0.18726378679275513\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.772255694342, f1: 0.769984267862\n",
      "\n",
      "Epoch 14. Global step 74430. T=5.66314713160197 min\n",
      "Loss               : 0.19758465886116028\n",
      "In-batch accuracy  : 0.90625\n",
      "Validation accuracy: 0.770404114622, f1: 0.779022403259\n",
      "\n",
      "Epoch 15. Global step 79392. T=6.044425638516744 min\n",
      "Loss               : 0.11031151562929153\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.77108008817, f1: 0.773661116439\n",
      "\n",
      "Epoch 16. Global step 84354. T=6.426197179158529 min\n",
      "Loss               : 0.05796609818935394\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.769140337987, f1: 0.766380156441\n",
      "\n",
      "Epoch 17. Global step 89316. T=6.807935154438018 min\n",
      "Loss               : 0.11115290224552155\n",
      "In-batch accuracy  : 0.96875\n",
      "Validation accuracy: 0.76772961058, f1: 0.776454614884\n",
      "\n",
      "Epoch 18. Global step 94278. T=7.188097846508026 min\n",
      "Loss               : 0.06374621391296387\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.766789125643, f1: 0.760134216015\n",
      "\n",
      "Epoch 19. Global step 99240. T=7.571721835931142 min\n",
      "Loss               : 0.05209808796644211\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.766171932403, f1: 0.77874186551\n",
      "\n",
      "Epoch 20. Global step 104202. T=7.953083205223083 min\n",
      "Loss               : 0.03010118566453457\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.764202792065, f1: 0.772841813188\n",
      "\n",
      "Epoch 21. Global step 109164. T=8.33647575378418 min\n",
      "Loss               : 0.05161166191101074\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.764731814842, f1: 0.765983570614\n",
      "\n",
      "Epoch 22. Global step 114126. T=8.71623596350352 min\n",
      "Loss               : 0.015090713277459145\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.767817781043, f1: 0.771438490915\n",
      "\n",
      "Epoch 23. Global step 119088. T=9.095849883556365 min\n",
      "Loss               : 0.045939020812511444\n",
      "In-batch accuracy  : 0.96875\n",
      "Validation accuracy: 0.765260837619, f1: 0.77551364569\n",
      "\n",
      "Epoch 24. Global step 124050. T=9.477930609385172 min\n",
      "Loss               : 0.02362372726202011\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.764878765614, f1: 0.767630998025\n",
      "\n",
      "Epoch 25. Global step 129012. T=9.860115087032318 min\n",
      "Loss               : 0.02049407549202442\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.76417340191, f1: 0.771435082322\n",
      "\n",
      "Epoch 26. Global step 133974. T=10.24193989833196 min\n",
      "Loss               : 0.031574856489896774\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.762762674504, f1: 0.77580268859\n",
      "\n",
      "Epoch 27. Global step 138936. T=10.620728846391042 min\n",
      "Loss               : 0.005978217348456383\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.76335047759, f1: 0.772336575435\n",
      "\n",
      "Epoch 28. Global step 143898. T=11.002714331944784 min\n",
      "Loss               : 0.017407704144716263\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.763027185893, f1: 0.764604560185\n",
      "\n",
      "Epoch 29. Global step 148860. T=11.383488754431406 min\n",
      "Loss               : 0.0014100708067417145\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.763820720059, f1: 0.768694951356\n",
      "\n",
      "Calculating validation metrics... Time 11.437665895620983 min\n",
      "Final test metrics: {'accuracy': 0.76285084496693611, 'f1': 0.7682853286620912}, Time 12.984772717952728 min\n",
      "\n",
      "CPU times: user 9min 19s, sys: 2min 45s, total: 12min 5s\n",
      "Wall time: 12min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal, log_every=5, epochs=30, comment='no_emoji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_15-47-15_madrugado_charCNN_embed_smaller2_lr4_noise0_dropout0.5no_emoji_enabled_dropout\n",
      "Epoch 0. Global step 4962. T=0.32687731583913165 min\n",
      "Loss               : 0.6044824123382568\n",
      "In-batch accuracy  : 0.65625\n",
      "Validation accuracy: 0.70407053637, f1: 0.690041557642\n",
      "\n",
      "Epoch 5. Global step 29772. T=2.251354956626892 min\n",
      "Loss               : 0.3281029462814331\n",
      "In-batch accuracy  : 0.90625\n",
      "Validation accuracy: 0.762762674504, f1: 0.764183464797\n",
      "\n",
      "Epoch 10. Global step 54582. T=4.174359858036041 min\n",
      "Loss               : 0.396010160446167\n",
      "In-batch accuracy  : 0.8125\n",
      "Validation accuracy: 0.780014695077, f1: 0.785302469667\n",
      "\n",
      "Epoch 15. Global step 79392. T=6.104336130619049 min\n",
      "Loss               : 0.4849695861339569\n",
      "In-batch accuracy  : 0.78125\n",
      "Validation accuracy: 0.780044085231, f1: 0.785706104684\n",
      "\n",
      "Epoch 20. Global step 104202. T=8.03821431795756 min\n",
      "Loss               : 0.357676237821579\n",
      "In-batch accuracy  : 0.75\n",
      "Validation accuracy: 0.782806759735, f1: 0.789110210604\n",
      "\n",
      "Epoch 25. Global step 129012. T=9.97509299516678 min\n",
      "Loss               : 0.401644766330719\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.780867009552, f1: 0.785562266322\n",
      "\n",
      "Calculating validation metrics... Time 11.572997200489045 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.78104335047758999, 'f1': 0.7861898748708529}, Time 13.131581568717957 min\n",
      "\n",
      "CPU times: user 9min 32s, sys: 2min 41s, total: 12min 13s\n",
      "Wall time: 13min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal, log_every=5, epochs=30, comment='no_emoji_enabled_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_16-20-08_madrugado_charCNN_embed_smaller2_lr4_noise0_dropout0.5_enabled_dropout\n",
      "Epoch 0. Global step 4962. T=0.3338169852892558 min\n",
      "Loss               : 9.800493717193604e-05\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999000734754, f1: 0.999017624964\n",
      "\n",
      "Epoch 5. Global step 29772. T=2.276704251766205 min\n",
      "Loss               : 8.940696716308594e-08\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999764878766, f1: 0.999768906349\n",
      "\n",
      "Epoch 10. Global step 54582. T=4.223753829797109 min\n",
      "Loss               : 8.940696716308594e-08\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999764878766, f1: 0.999768906349\n",
      "\n",
      "Epoch 15. Global step 79392. T=6.173992296059926 min\n",
      "Loss               : 0.0\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999764878766, f1: 0.9997689197\n",
      "\n",
      "Epoch 20. Global step 104202. T=8.125758945941925 min\n",
      "Loss               : 0.0\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999823659074, f1: 0.999826699786\n",
      "\n",
      "Epoch 25. Global step 129012. T=10.077120367685954 min\n",
      "Loss               : 0.0\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.999764878766, f1: 0.999768906349\n",
      "\n",
      "Calculating validation metrics... Time 11.691335602601368 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.99994121969140337, 'f1': 0.99994241621559377}, Time 13.275928223133088 min\n",
      "\n",
      "CPU times: user 9min 41s, sys: 2min 44s, total: 12min 25s\n",
      "Wall time: 13min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal, log_every=5, epochs=30, comment='_enabled_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer: runs/May12_19-15-08_madrugado_charCNN_embed_smaller2_lr4_noise0.1_dropout0.5_spellchecked\n",
      "Epoch 0. Global step 4757. T=0.32279518445332844 min\n",
      "Loss               : 0.23855933547019958\n",
      "In-batch accuracy  : 0.875\n",
      "Validation accuracy: 0.960111601668, f1: 0.961088679527\n",
      "\n",
      "Epoch 5. Global step 28542. T=2.233179748058319 min\n",
      "Loss               : 0.11236453801393509\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.965538386068, f1: 0.965873208647\n",
      "\n",
      "Epoch 10. Global step 52327. T=4.14134658575058 min\n",
      "Loss               : 0.05149190500378609\n",
      "In-batch accuracy  : 0.9375\n",
      "Validation accuracy: 0.966918077017, f1: 0.967321844998\n",
      "\n",
      "Epoch 15. Global step 76112. T=6.052044069766998 min\n",
      "Loss               : 0.006237946450710297\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.966887417219, f1: 0.967575357272\n",
      "\n",
      "Epoch 20. Global step 99897. T=7.961504407723745 min\n",
      "Loss               : 0.032453540712594986\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.970903850871, f1: 0.971349213537\n",
      "\n",
      "Epoch 25. Global step 123682. T=9.87264054218928 min\n",
      "Loss               : 0.04163382202386856\n",
      "In-batch accuracy  : 1.0\n",
      "Validation accuracy: 0.969278881531, f1: 0.969700635017\n",
      "\n",
      "Calculating validation metrics... Time 11.462045482794444 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/.local/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type CharCNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test metrics: {'accuracy': 0.96894162374294823, 'f1': 0.96946863980228459}, Time 13.229927579561869 min\n",
      "\n",
      "CPU times: user 9min 35s, sys: 2min 33s, total: 12min 9s\n",
      "Wall time: 13min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0.1, init_function=init.xavier_normal, log_every=5, epochs=30, comment='_spellchecked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv('CharCNN_with_emoji_spellchecked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@envoyatthenet и мы под предводительтвом пу боль<UNK>ими скачками несемся в совок,а потом и в деспотию(((',\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, label = train[2]\n",
    "train.onehot2text(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ахахахаха пипец, прикольная фигня :d http://t.co/tsvhwraala', 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, label = train[20000]\n",
    "train.onehot2text(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1.2101\n",
       " [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n",
       "  0\n",
       " [torch.cuda.LongTensor of size 1 (GPU 0)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('ахахахаха пипец, прикольная фигня').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Новые Мстители потрясающие!').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Новые Мстители потрясающие! =)').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Это было ужасно! =)').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Это было ужасно! =()').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Это было ужасно! =(').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(\n",
    "    model.forward(Variable(test._preprocess_text_nobatch('Это было ужасно!').unsqueeze(0).permute(1, 0, 2).cuda())),\n",
    "    1\n",
    ")[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.2101 -1.1104\n",
       "[torch.cuda.FloatTensor of size 1x2 (GPU 0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(Variable(test._preprocess_text_nobatch('ахахахаха пипец, прикольная фигня').unsqueeze(0).permute(1, 0, 2).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7154096364974976\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6276\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3147427439689636\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.43052104115486145\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7732\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.14214535057544708\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8052\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.16783644258975983\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8112\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.5878106951713562\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.82\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.1835513859987259\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.036214977502822876\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8056\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.036427706480026245\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.09720713645219803\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8232\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.027575135231018066\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.06920866668224335\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.015279620885848999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.032747477293014526\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8172\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.02133116126060486\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.0014932751655578613\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0026256442070007324\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.00022476911544799805\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "1.52587890625e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8168\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "3.4570693969726562e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.828\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "4.4465065002441406e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00014007091522216797\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.812\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "4.76837158203125e-07\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8216\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "2.7179718017578125e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8252\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.005523800849914551\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.792\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "1.800060272216797e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "3.933906555175781e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.818\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00014293193817138672\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.11518393456935883\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Final test accuracy: 0.77836\n",
      "\n",
      "CPU times: user 5min 50s, sys: 2min 26s, total: 8min 17s\n",
      "Wall time: 8min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=30464, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.785068154335022\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.6084\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3312198519706726\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7292\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.2843222916126251\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.1944502741098404\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7604\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.24288120865821838\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8008\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.36140114068984985\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8036\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.2669448256492615\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8048\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.18363156914710999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.48155519366264343\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.47901251912117004\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.802\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.03075912594795227\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.822\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.2517656683921814\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.08778958022594452\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1717863380908966\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8276\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.14468592405319214\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.013375252485275269\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8308\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.07788994908332825\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.005857408046722412\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8136\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.10116563737392426\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8044\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.01556655764579773\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.01607152819633484\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8204\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00832277536392212\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.826\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.036525875329971313\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8268\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.00587010383605957\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.0029016733169555664\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8284\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.012174874544143677\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8124\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.02179431915283203\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8156\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00522458553314209\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0005469918251037598\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8316\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0004094839096069336\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8324\n",
      "\n",
      "Final test accuracy: 0.82348\n",
      "\n",
      "CPU times: user 3min 42s, sys: 1min 33s, total: 5min 15s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=30464, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.8411439657211304\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5012\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.5809738636016846\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.66\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.4452686309814453\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6824\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.23656554520130157\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7136\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.5787070393562317\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.502457857131958\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.12519408762454987\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.731816291809082\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.736\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.12233468890190125\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.09430167078971863\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7312\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.09161564707756042\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.734\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.08762294054031372\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7312\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.105124831199646\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7328\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.0444985032081604\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7316\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.09123039245605469\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7304\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.06530529260635376\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.03109598159790039\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7328\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.004562437534332275\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.010403096675872803\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7324\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.006136536598205566\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.017438173294067383\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.004397451877593994\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.0013630986213684082\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.0010037422180175781\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.000855863094329834\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.0008487105369567871\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7264\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.0002518296241760254\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.0006242990493774414\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7264\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.00048047304153442383\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.000341951847076416\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7256\n",
      "\n",
      "Final test accuracy: 0.70608\n",
      "\n",
      "CPU times: user 1min 20s, sys: 32.3 s, total: 1min 53s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7073005437850952\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6404\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.5612970590591431\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7176\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.9215638637542725\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7228\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.3698350191116333\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.584014356136322\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7556\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.19489029049873352\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.758\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.41615644097328186\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7776\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.2622656226158142\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7752\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.16676472127437592\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7824\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.051940202713012695\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.75\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.11029338836669922\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7792\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.025028765201568604\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7872\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.028858810663223267\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.784\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.0239579975605011\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7716\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.029768288135528564\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7836\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.003383457660675049\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0065698325634002686\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7804\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.005014777183532715\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7788\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.0012508034706115723\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.018134474754333496\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.782\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.0017946362495422363\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7828\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.0020844340324401855\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7832\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.0012060999870300293\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.0019055008888244629\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7784\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "8.893013000488281e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7816\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.00021791458129882812\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7832\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "8.130073547363281e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00023221969604492188\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7828\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.00013083219528198242\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7816\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.00019437074661254883\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.78\n",
      "\n",
      "Final test accuracy: 0.77552\n",
      "\n",
      "CPU times: user 2min 4s, sys: 52.9 s, total: 2min 57s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    text = preprocess_text_nobatch(text)\n",
    "    text = text.unsqueeze(0).permute(0, 2, 1)\n",
    "    text = Variable(text.cuda())\n",
    "    prediction = model(text)\n",
    "    _, prediction = torch.max(prediction, 1)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I hate it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I have seen this film as I was a child and it was awersome! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'Love it! Love it!  Love it! Love it! Love it! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"Maybe just long enough text if really suficcient so let's write something neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"We need more emotions! Like when film is cool you are so happy to rank it 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"So only long texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is not good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is very good for tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то такое себе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить на малой длине (140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.70023113489151\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5332\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.7055613398551941\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6228\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.46998968720436096\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6316\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.7275577783584595\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6564\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.33533045649528503\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6628\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.6466774940490723\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.3631550967693329\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6668\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.3672349154949188\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6776\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.18997327983379364\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6776\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.45411497354507446\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.682\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.12608222663402557\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.688\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.32205089926719666\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6888\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.3059559464454651\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6888\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1519184708595276\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6704\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.11397160589694977\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.676\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.22693216800689697\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6872\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.2246621549129486\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6816\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.046780407428741455\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.684\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.07688425481319427\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6784\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.0199909508228302\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.68\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.027406424283981323\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.68\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.038487911224365234\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6752\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.013645201921463013\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6736\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.04285439848899841\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6764\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.011004775762557983\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6756\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.004669070243835449\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.003603041172027588\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6744\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00252532958984375\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6788\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0018059015274047852\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6712\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0011753439903259277\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6724\n",
      "\n",
      "Final test accuracy: 0.65416\n",
      "\n",
      "CPU times: user 1min 1s, sys: 21.5 s, total: 1min 22s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = run_model_with(noise_level=0, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I love it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I hate it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'I have seen this film as I was a child and it was awersome! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'Love it! Love it!  Love it! Love it! Love it! Love it! Love it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"Maybe just long enough text if really suficcient so let's write something neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"We need more emotions! Like when film is cool you are so happy to rank it 10\") # Изменилось с 1 на 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"So only long texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is not good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.cuda.LongTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, \"This is very good for tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OneHotDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, alphabet=None, noise_level=0, maxlen=512):\n",
    "        \"\"\"\n",
    "        :param dataframe: pandas dataframe with fields \"text\": str and \"label\": int\n",
    "        \"\"\"\n",
    "        if alphabet is None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            self.alphabet = alphabet\n",
    "        self.char2int = {s: i for s, i in zip(self.alphabet, range(len(self.alphabet)))}\n",
    "\n",
    "        self.maxlen = maxlen\n",
    "        self.dataframe = dataframe\n",
    "        self.noise_level = noise_level\n",
    "        if self.noise_level > 0:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        line = self.dataframe.iloc[idx]\n",
    "        text = self._preprocess_text_nobatch(line.text)\n",
    "        label = line.label\n",
    "        return text, label\n",
    "\n",
    "    def _noise_generator(string):\n",
    "        noised = \"\"\n",
    "        for c in string:\n",
    "            if random() > self.noise_level:\n",
    "                noised += c\n",
    "            if random() < self.noise_level:\n",
    "                noised += choice(self.alphabet)\n",
    "        return noised\n",
    "\n",
    "    def _one_hot(self, char):\n",
    "        zeros = np.zeros(len(self.alphabet))\n",
    "        if char in self.char2int:\n",
    "            zeros[self.char2int[char]] = 1.\n",
    "        else:\n",
    "            zeros[self.char2int['UNK']] = 1.\n",
    "\n",
    "    def _preprocess_text_nobatch(self, text):\n",
    "        one_hotted_text = np.zeros((self.maxlen, len(self.alphabet)))\n",
    "        for i, char in enumerate(text):\n",
    "            if i >= self.maxlen:\n",
    "                break\n",
    "            one_hotted_text[i, self.char2int.get(char, self.char2int['UNK'])] = 1.\n",
    "        if i < self.maxlen:\n",
    "            for j in range(i+1, self.maxlen):\n",
    "                one_hotted_text[j, self.char2int['PAD']] = 1.\n",
    "\n",
    "        return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "    def onehot2text(self, one_hotted_text):\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = self.alphabet[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('/media/data/nlp/data/twitter_sentiment/twitter_sentiment_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282205</th>\n",
       "      <td>294537</td>\n",
       "      <td>294549</td>\n",
       "      <td>1</td>\n",
       "      <td>@julianna12369 Hon those two tweets together w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  ItemID  Sentiment  \\\n",
       "282205      294537  294549          1   \n",
       "\n",
       "                                            SentimentText  \n",
       "282205  @julianna12369 Hon those two tweets together w...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_df.columns = ['idxx', 'ItemID', 'label', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_ds = OneHotDataset(twitter_df, alphabet=ALPHABET, maxlen=140)\n",
    "twitter_dl = torch.utils.data.DataLoader(twitter_ds, batch_size=BATCH_SIZE, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 s, sys: 13.8 s, total: 46.8 s\n",
      "Wall time: 48.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5117747288379131"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# MAXLEN 512\n",
    "get_accuracy(model, twitter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 4.83 s, total: 19.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5006580369517948"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# MAXLEN 140\n",
    "get_accuracy(model, twitter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
