{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchtext\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Долгий способ сделать всё ЗБС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "label = torchtext.data.Field(sequential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torchtext.datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.fields {'text': <torchtext.data.field.Field object at 0x7f64bc9505c0>, 'label': <torchtext.data.field.Field object at 0x7f64bc950588>}\n",
      "len(train) 25000\n",
      "vars(train[0]) {'label': ['pos'], 'text': ['this', 'musical', 'is', 'decidedly', 'mixed,', 'and', 'none', 'of', 'the', 'elements', 'really', 'fit', 'together,', 'but', 'it', 'somehow', 'manages', 'to', 'be', 'mostly', 'enjoyable.', 'the', 'plot', 'contains', 'some', 'of', 'the', 'elements', 'of', \"wodehouse's\", 'novel,', 'but', 'none', 'of', 'its', 'virtues,', 'though', 'he', 'co-wrote', 'the', 'script.', 'the', 'songs,', 'though', 'charming,', 'have', 'nothing', 'to', 'do', 'with', 'this', 'particular', 'film,', 'and', 'are', 'unusually', 'crudely', 'squeezed', 'into', 'the', 'plot,', 'even', 'by', 'pre-oklahoma', 'standards.', 'burns', 'and', 'allen', 'do', 'their', 'usual', 'shtick', 'quite', 'competently,', 'but', 'it', 'misses', 'the', 'tone', 'of', 'the', 'rest', 'of', 'the', 'film', 'by', 'about', 'forty', 'iq', 'points.<br', '/><br', '/>there', 'are', 'a', 'few', 'high', 'points.', 'reginald', 'gardiner', 'does', 'good', 'work', 'when', 'he', 'remembers', 'that', 'this', 'is', 'a', 'talkie,', 'and', 'stops', 'mugging', 'like', 'a', 'silent', 'actor.', 'and', 'there', 'are', 'a', 'few', 'bits', 'of', 'writing', 'which', 'could', 'only', 'have', 'been', 'written', 'by', 'wodehouse,', 'though', 'most', 'of', 'the', 'film', 'feels', 'like', 'the', 'production', 'of', 'one', 'of', 'the', 'hollywood', 'meetings', 'he', 'later', 'parodied.']}\n"
     ]
    }
   ],
   "source": [
    "# print information about the data\n",
    "print('train.fields', train.fields)\n",
    "print('len(train)', len(train))\n",
    "print('vars(train[0])', vars(train[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = torchtext.vocab.GloVe(name='6B', dim=300, cache='/media/data/nlp/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(train, vectors=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(TEXT.vocab) 251639\n",
      "TEXT.vocab.vectors.size() torch.Size([251639, 300])\n"
     ]
    }
   ],
   "source": [
    "print('len(TEXT.vocab)', len(text.vocab))\n",
    "print('TEXT.vocab.vectors.size()', text.vocab.vectors.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train, test), batch_size=16, device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 9.0000e+00  1.9000e+01  1.5250e+03  ...   3.2250e+03  1.9000e+01  1.4100e+02\n",
      " 9.0000e+01  1.2800e+02  2.7200e+02  ...   8.0000e+01  5.4000e+01  1.6700e+02\n",
      " 2.0700e+02  1.7900e+02  4.0600e+02  ...   5.4563e+04  1.5720e+03  2.0000e+02\n",
      "                ...                   ⋱                   ...                \n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.2000e+01  1.5000e+01  6.0770e+04\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   7.0000e+00  2.0000e+00  4.0000e+00\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0093e+04  9.5111e+04  1.2900e+02\n",
      "[torch.cuda.LongTensor of size 211x32 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      "[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print batch information\n",
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Короткий способ сделать всё збс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = torchtext.datasets.IMDB.iters(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 5.1504e+04  1.9000e+01  1.9000e+01  ...   1.6000e+02  4.9000e+01  1.2300e+02\n",
      " 1.1248e+04  2.4100e+02  6.1000e+02  ...   7.8700e+02  1.0540e+03  2.8100e+02\n",
      " 9.1800e+02  2.4000e+01  7.0000e+00  ...   6.5870e+03  1.1570e+03  6.0000e+00\n",
      "                ...                   ⋱                   ...                \n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   3.4000e+01  1.3000e+01  1.7000e+01\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.2089e+04  2.3394e+04  1.5300e+02\n",
      " 1.0000e+00  1.0000e+00  1.0000e+00  ...   1.0000e+00  1.0000e+00  9.1000e+02\n",
      "[torch.cuda.LongTensor of size 238x32 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 2\n",
      " 1\n",
      " 2\n",
      " 2\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print batch information\n",
    "batch = next(iter(train_iter))\n",
    "print(batch.text)\n",
    "print(batch.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуем простые модели\n",
    "* CNN\n",
    "* LSTM\n",
    "\n",
    "#### Потом модели посложнее\n",
    "* biLSTM\n",
    "* SRU\n",
    "* RNN_CNN\n",
    "* RCNN\n",
    "\n",
    "#### Отдельно стоит выделить класс\n",
    "* Char CNN\n",
    "* Char CNN with spip gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = torchtext.data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "label = torchtext.data.Field(sequential=True)\n",
    "\n",
    "train, test = torchtext.datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'musical',\n",
       " 'is',\n",
       " 'decidedly',\n",
       " 'mixed,',\n",
       " 'and',\n",
       " 'none',\n",
       " 'of',\n",
       " 'the',\n",
       " 'elements',\n",
       " 'really',\n",
       " 'fit',\n",
       " 'together,',\n",
       " 'but',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'manages',\n",
       " 'to',\n",
       " 'be',\n",
       " 'mostly',\n",
       " 'enjoyable.',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'contains',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'elements',\n",
       " 'of',\n",
       " \"wodehouse's\",\n",
       " 'novel,',\n",
       " 'but',\n",
       " 'none',\n",
       " 'of',\n",
       " 'its',\n",
       " 'virtues,',\n",
       " 'though',\n",
       " 'he',\n",
       " 'co-wrote',\n",
       " 'the',\n",
       " 'script.',\n",
       " 'the',\n",
       " 'songs,',\n",
       " 'though',\n",
       " 'charming,',\n",
       " 'have',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'this',\n",
       " 'particular',\n",
       " 'film,',\n",
       " 'and',\n",
       " 'are',\n",
       " 'unusually',\n",
       " 'crudely',\n",
       " 'squeezed',\n",
       " 'into',\n",
       " 'the',\n",
       " 'plot,',\n",
       " 'even',\n",
       " 'by',\n",
       " 'pre-oklahoma',\n",
       " 'standards.',\n",
       " 'burns',\n",
       " 'and',\n",
       " 'allen',\n",
       " 'do',\n",
       " 'their',\n",
       " 'usual',\n",
       " 'shtick',\n",
       " 'quite',\n",
       " 'competently,',\n",
       " 'but',\n",
       " 'it',\n",
       " 'misses',\n",
       " 'the',\n",
       " 'tone',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'film',\n",
       " 'by',\n",
       " 'about',\n",
       " 'forty',\n",
       " 'iq',\n",
       " 'points.<br',\n",
       " '/><br',\n",
       " '/>there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'few',\n",
       " 'high',\n",
       " 'points.',\n",
       " 'reginald',\n",
       " 'gardiner',\n",
       " 'does',\n",
       " 'good',\n",
       " 'work',\n",
       " 'when',\n",
       " 'he',\n",
       " 'remembers',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'talkie,',\n",
       " 'and',\n",
       " 'stops',\n",
       " 'mugging',\n",
       " 'like',\n",
       " 'a',\n",
       " 'silent',\n",
       " 'actor.',\n",
       " 'and',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'few',\n",
       " 'bits',\n",
       " 'of',\n",
       " 'writing',\n",
       " 'which',\n",
       " 'could',\n",
       " 'only',\n",
       " 'have',\n",
       " 'been',\n",
       " 'written',\n",
       " 'by',\n",
       " 'wodehouse,',\n",
       " 'though',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " 'film',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'the',\n",
       " 'production',\n",
       " 'of',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hollywood',\n",
       " 'meetings',\n",
       " 'he',\n",
       " 'later',\n",
       " 'parodied.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='_model_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, hidden_dim=128, batch_size=BATCH_SIZE):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embeddings.dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
