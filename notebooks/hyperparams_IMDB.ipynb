{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18 13:46 summarizer.preprocessing.cleaner INFO     'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cfg\n",
    "\n",
    "from text_classification import trainutils\n",
    "from text_classification.layers import *\n",
    "from text_classification.logger import logger\n",
    "from text_classification.datautils import *\n",
    "from text_classification.trainutils import get_metrics\n",
    "\n",
    "from train import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "CharIMDB.maxlen = 512\n",
    "train_data, test_data = CharIMDB.splits(text_field, label_field, root='../.data')\n",
    "\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-04 18:06 root         INFO     Writer: runs/Jul04_18-06-09_lyalin_CharCNN_lr0_dropout0.5_noise_level0.0000\n",
      "07-04 18:06 root         INFO     Epoch 0. Global step 665. T=0.17min\n",
      "07-04 18:06 root         INFO     In-batch loss      : 0.6937\n",
      "07-04 18:06 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:06 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "07-04 18:07 root         INFO     Epoch 9. Global step 6650. T=1.65min\n",
      "07-04 18:07 root         INFO     In-batch loss      : 0.6934\n",
      "07-04 18:07 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Calculating test metrics... Time T=1.65min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n",
      "07-04 18:07 root         INFO     Original dataset accuracy: 0.5000, f1: 0.0000\n",
      "07-04 18:07 root         INFO     Final test accuracy:0.5000, f1: 0.0000. Time 1.8032399932543437 min\n",
      "07-04 18:07 root         INFO     Writer: runs/Jul04_18-07-57_lyalin_CharCNN_lr1_dropout0.5_noise_level0.0000\n",
      "07-04 18:08 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-04 18:08 root         INFO     In-batch loss      : 0.6641\n",
      "07-04 18:08 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:08 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:09 root         INFO     Epoch 9. Global step 6650. T=1.68min\n",
      "07-04 18:09 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:09 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:09 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:09 root         INFO     Calculating test metrics... Time T=1.68min\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.00s/it]\n",
      "07-04 18:09 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:09 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.8411134799321494 min\n",
      "07-04 18:09 root         INFO     Writer: runs/Jul04_18-09-47_lyalin_CharCNN_lr2_dropout0.5_noise_level0.0000\n",
      "07-04 18:09 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-04 18:09 root         INFO     In-batch loss      : 0.6981\n",
      "07-04 18:09 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:09 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:11 root         INFO     Epoch 9. Global step 6650. T=1.72min\n",
      "07-04 18:11 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:11 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:11 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:11 root         INFO     Calculating test metrics... Time T=1.72min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
      "07-04 18:11 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:11 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.9072402000427247 min\n",
      "07-04 18:11 root         INFO     Writer: runs/Jul04_18-11-42_lyalin_CharCNN_lr3_dropout0.5_noise_level0.0000\n",
      "07-04 18:11 root         INFO     Epoch 0. Global step 665. T=0.22min\n",
      "07-04 18:11 root         INFO     In-batch loss      : 0.6919\n",
      "07-04 18:11 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:11 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Epoch 9. Global step 6650. T=1.85min\n",
      "07-04 18:13 root         INFO     In-batch loss      : 0.6910\n",
      "07-04 18:13 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Calculating test metrics... Time T=1.85min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n",
      "07-04 18:13 root         INFO     Original dataset accuracy: 0.5000, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Final test accuracy:0.5000, f1: 0.0000. Time 2.0057247122128805 min\n",
      "07-04 18:13 root         INFO     Writer: runs/Jul04_18-13-42_lyalin_CharCNN_lr4_dropout0.5_noise_level0.0000\n",
      "07-04 18:13 root         INFO     Epoch 0. Global step 665. T=0.19min\n",
      "07-04 18:13 root         INFO     In-batch loss      : 0.6932\n",
      "07-04 18:13 root         INFO     Training accuracy  : 0.4992, f1: 0.0000\n",
      "07-04 18:13 root         INFO     Validation accuracy: 0.5045, f1: 0.0000\n",
      "07-04 18:15 root         INFO     Epoch 9. Global step 6650. T=1.71min\n",
      "07-04 18:15 root         INFO     In-batch loss      : 0.6915\n",
      "07-04 18:15 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-04 18:15 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-04 18:15 root         INFO     Calculating test metrics... Time T=1.71min\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "07-04 18:15 root         INFO     Original dataset accuracy: 0.5000, f1: 0.6667\n",
      "07-04 18:15 root         INFO     Final test accuracy:0.5000, f1: 0.6667. Time 1.870841427644094 min\n"
     ]
    }
   ],
   "source": [
    "model = CharCNN(128, 5, 512, len(cfg.alphabet))\n",
    "\n",
    "for lr in [1e0, 1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "    trained_model, results = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              test_dataloader,\n",
    "              test_dataloader,\n",
    "              lr=lr,\n",
    "              noise_level=0,\n",
    "              comment='',\n",
    "              save_model_path=None,\n",
    "              save_results_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(150)):\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand()\n",
    "    \n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7391752577319587,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 5,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.09851507346853383,\n",
       "  'accuracy': 0.7301333333333333,\n",
       "  'f1': 0.7391752577319587})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/150 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A07-05 18:09 root         INFO     {'n_filters': 16, 'cnn_kernel_size': 3, 'maxlen': 512, 'dropout': 0.7587327768268632}\n",
      "07-05 18:09 root         INFO     Writer: runs/Jul05_18-09-08_lyalin_CharCNN_lr4_dropout0.7587327768268632_noise_level0.0000hyperparameters_search\n",
      "07-05 18:09 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-05 18:09 root         INFO     In-batch loss      : 0.7718\n",
      "07-05 18:09 root         INFO     Training accuracy  : 0.5236, f1: 0.6120\n",
      "07-05 18:09 root         INFO     Validation accuracy: 0.5096, f1: 0.5986\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(150)):\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand() * 0.5 + 0.5\n",
    "    \n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7124064998710343,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 7,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.6716150874837757,\n",
       "  'accuracy': 0.7026666666666667,\n",
       "  'f1': 0.7124064998710343})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(150)):\n",
    "    lr = np.random.uniform()\n",
    "    n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "#     maxlen = int(np.random.choice([256, 512, 1024]))\n",
    "    maxlen = 512\n",
    "    dropout = np.random.rand() * 0.5 + 0.5\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'maxlen': maxlen,\n",
    "        'dropout': dropout\n",
    "    }\n",
    "    \n",
    "    logger.info(params)\n",
    "\n",
    "    try:\n",
    "        model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "        trained_model = \\\n",
    "            train(model,\n",
    "                  train_dataloader,\n",
    "                  val_dataloader,\n",
    "                  noise_level=0,\n",
    "                  lr=lr,\n",
    "                  comment='hyperparameters_search',\n",
    "                  save_model_path=None)\n",
    "        metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_model = model\n",
    "            best_params = params\n",
    "\n",
    "        params.update(metrics)\n",
    "        results.append(params)\n",
    "        pd.DataFrame(results).to_csv('../results/CharCNN_hyperparams.csv')\n",
    "    except Exception as e:\n",
    "        logger.error(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7124064998710343,\n",
       " {'n_filters': 1024,\n",
       "  'cnn_kernel_size': 7,\n",
       "  'maxlen': 512,\n",
       "  'dropout': 0.6716150874837757,\n",
       "  'accuracy': 0.7026666666666667,\n",
       "  'f1': 0.7124064998710343})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10**np.random.uniform(-4, 0)\n",
    "n_filters = int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "maxlen = 512\n",
    "dropout = np.random.rand() * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0.7124064998710343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 14:12 root         INFO     Writer: runs/Jul09_14-12-47_lyalin_CharCNN_lr3_dropout0.5_noise_level0.0000hyperparameters_search\n",
      "07-09 14:12 root         INFO     Epoch 0. Global step 665. T=0.16min\n",
      "07-09 14:12 root         INFO     In-batch loss      : 0.7336\n",
      "07-09 14:12 root         INFO     Training accuracy  : 0.6725, f1: 0.6801\n",
      "07-09 14:12 root         INFO     Validation accuracy: 0.6603, f1: 0.6687\n",
      "07-09 14:13 root         INFO     Epoch 2. Global step 1995. T=0.50min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.2334\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7330, f1: 0.7254\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7120, f1: 0.7005\n",
      "07-09 14:13 root         INFO     Epoch 4. Global step 3325. T=0.82min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.5750\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7641, f1: 0.7677\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7368, f1: 0.7380\n",
      "07-09 14:13 root         INFO     Epoch 6. Global step 4655. T=1.16min\n",
      "07-09 14:13 root         INFO     In-batch loss      : 0.3988\n",
      "07-09 14:13 root         INFO     Training accuracy  : 0.7850, f1: 0.7847\n",
      "07-09 14:13 root         INFO     Validation accuracy: 0.7464, f1: 0.7416\n",
      "07-09 14:14 root         INFO     Epoch 8. Global step 5985. T=1.50min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.1454\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8040, f1: 0.8059\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7549, f1: 0.7555\n",
      "07-09 14:14 root         INFO     Epoch 10. Global step 7315. T=1.83min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.6503\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8136, f1: 0.8139\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7587, f1: 0.7574\n",
      "07-09 14:14 root         INFO     Epoch 12. Global step 8645. T=2.17min\n",
      "07-09 14:14 root         INFO     In-batch loss      : 0.4744\n",
      "07-09 14:14 root         INFO     Training accuracy  : 0.8253, f1: 0.8244\n",
      "07-09 14:14 root         INFO     Validation accuracy: 0.7632, f1: 0.7609\n",
      "07-09 14:15 root         INFO     Epoch 14. Global step 9975. T=2.49min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.1294\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8327, f1: 0.8377\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7672, f1: 0.7732\n",
      "07-09 14:15 root         INFO     Epoch 16. Global step 11305. T=2.82min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.6567\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8418, f1: 0.8459\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7725, f1: 0.7778\n",
      "07-09 14:15 root         INFO     Epoch 18. Global step 12635. T=3.16min\n",
      "07-09 14:15 root         INFO     In-batch loss      : 0.4790\n",
      "07-09 14:15 root         INFO     Training accuracy  : 0.8482, f1: 0.8505\n",
      "07-09 14:15 root         INFO     Validation accuracy: 0.7672, f1: 0.7683\n",
      "07-09 14:16 root         INFO     Epoch 20. Global step 13965. T=3.49min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 1.2805\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8539, f1: 0.8556\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7664, f1: 0.7683\n",
      "07-09 14:16 root         INFO     Epoch 22. Global step 15295. T=3.82min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 0.2380\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8596, f1: 0.8633\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7688, f1: 0.7743\n",
      "07-09 14:16 root         INFO     Epoch 24. Global step 16625. T=4.14min\n",
      "07-09 14:16 root         INFO     In-batch loss      : 0.1049\n",
      "07-09 14:16 root         INFO     Training accuracy  : 0.8688, f1: 0.8707\n",
      "07-09 14:16 root         INFO     Validation accuracy: 0.7664, f1: 0.7686\n",
      "07-09 14:17 root         INFO     Epoch 26. Global step 17955. T=4.47min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.0648\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8731, f1: 0.8733\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7691, f1: 0.7675\n",
      "07-09 14:17 root         INFO     Epoch 28. Global step 19285. T=4.80min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.5017\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8797, f1: 0.8794\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7616, f1: 0.7595\n",
      "07-09 14:17 root         INFO     Epoch 29. Global step 19950. T=4.96min\n",
      "07-09 14:17 root         INFO     In-batch loss      : 0.0165\n",
      "07-09 14:17 root         INFO     Training accuracy  : 0.8805, f1: 0.8822\n",
      "07-09 14:17 root         INFO     Validation accuracy: 0.7680, f1: 0.7712\n",
      "07-09 14:17 root         WARNING  Model is evaluating in training mode!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES!\n",
      "{'n_filters': 128, 'cnn_kernel_size': 5, 'maxlen': 512, 'dropout': 0.5}\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "lr = 0.001\n",
    "n_filters = 128\n",
    "cnn_kernel_size = 5\n",
    "maxlen = 512\n",
    "dropout = 0.5\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'maxlen': maxlen,\n",
    "    'dropout': dropout\n",
    "}\n",
    "\n",
    "model = CharCNN(alphabet_len=len(cfg.alphabet), **params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    print('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharCNN(128, 5, 512, len(cfg.alphabet))\n",
    "\n",
    "trained_model, results = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          lr=1e-3,\n",
    "          noise_level=0,\n",
    "          comment='',\n",
    "          save_model_path=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AttentionedYoonKim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize='spacy', use_vocab=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train_data, test_data = HierarchicalIMDB.splits(text_field, label_field, root='../.data')\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 15:21 root         INFO     Writer: runs/Jul09_15-21-51_lyalin_AttentionedYoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search\n",
      "07-09 15:23 root         INFO     Epoch 0. Global step 665. T=2.03min\n",
      "07-09 15:23 root         INFO     In-batch loss      : 0.7096\n",
      "07-09 15:23 root         INFO     Training accuracy  : 0.5078, f1: 0.4185\n",
      "07-09 15:23 root         INFO     Validation accuracy: 0.5064, f1: 0.4210\n",
      "07-09 15:28 root         INFO     Epoch 2. Global step 1995. T=6.32min\n",
      "07-09 15:28 root         INFO     In-batch loss      : 0.7181\n",
      "07-09 15:28 root         INFO     Training accuracy  : 0.6406, f1: 0.6223\n",
      "07-09 15:28 root         INFO     Validation accuracy: 0.6248, f1: 0.6051\n",
      "07-09 15:32 root         INFO     Epoch 4. Global step 3325. T=10.43min\n",
      "07-09 15:32 root         INFO     In-batch loss      : 0.6390\n",
      "07-09 15:32 root         INFO     Training accuracy  : 0.7547, f1: 0.7503\n",
      "07-09 15:32 root         INFO     Validation accuracy: 0.7453, f1: 0.7410\n",
      "07-09 15:36 root         INFO     Epoch 6. Global step 4655. T=14.53min\n",
      "07-09 15:36 root         INFO     In-batch loss      : 0.3805\n",
      "07-09 15:36 root         INFO     Training accuracy  : 0.8479, f1: 0.8495\n",
      "07-09 15:36 root         INFO     Validation accuracy: 0.8285, f1: 0.8291\n",
      "07-09 15:40 root         INFO     Epoch 8. Global step 5985. T=18.64min\n",
      "07-09 15:40 root         INFO     In-batch loss      : 0.1037\n",
      "07-09 15:40 root         INFO     Training accuracy  : 0.8748, f1: 0.8753\n",
      "07-09 15:40 root         INFO     Validation accuracy: 0.8501, f1: 0.8503\n",
      "07-09 15:44 root         INFO     Epoch 10. Global step 7315. T=22.72min\n",
      "07-09 15:44 root         INFO     In-batch loss      : 0.0217\n",
      "07-09 15:44 root         INFO     Training accuracy  : 0.8937, f1: 0.8951\n",
      "07-09 15:44 root         INFO     Validation accuracy: 0.8680, f1: 0.8689\n",
      "07-09 15:48 root         INFO     Epoch 12. Global step 8645. T=26.81min\n",
      "07-09 15:48 root         INFO     In-batch loss      : 0.7714\n",
      "07-09 15:48 root         INFO     Training accuracy  : 0.9061, f1: 0.9049\n",
      "07-09 15:48 root         INFO     Validation accuracy: 0.8685, f1: 0.8657\n",
      "07-09 15:52 root         INFO     Epoch 14. Global step 9975. T=30.90min\n",
      "07-09 15:52 root         INFO     In-batch loss      : 1.0344\n",
      "07-09 15:52 root         INFO     Training accuracy  : 0.9181, f1: 0.9182\n",
      "07-09 15:52 root         INFO     Validation accuracy: 0.8757, f1: 0.8757\n",
      "07-09 15:56 root         INFO     Epoch 16. Global step 11305. T=34.98min\n",
      "07-09 15:56 root         INFO     In-batch loss      : 0.0940\n",
      "07-09 15:56 root         INFO     Training accuracy  : 0.9275, f1: 0.9276\n",
      "07-09 15:56 root         INFO     Validation accuracy: 0.8757, f1: 0.8757\n",
      "Process Process-206:\n",
      "Process Process-208:\n",
      "Process Process-205:\n",
      "Process Process-207:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-064b96edd3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m           save_model_path=None)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# TODO: change dataloaders and remove premute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mwords_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_modules'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "lr = 0.001\n",
    "n_filters = 128  # int(np.random.choice([16, 32, 64, 128, 256, 512, 1024]))\n",
    "cnn_kernel_size = 5\n",
    "maxlen = 512\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 128\n",
    "embedding_dim = 74\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'heads': 1,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "#     'pool_kernel_size': 4\n",
    "}\n",
    "\n",
    "model = AttentionedYoonKimModel(**params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    print('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 118)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 19:44 root         INFO     Parameters: {'n_filters': 64, 'cnn_kernel_size': 5, 'hidden_dim_out': 256, 'heads': 1, 'embedding_dim': 51, 'dropout': 0.49569537913353157}\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49569537913353157 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 19:44 root         INFO     Writer: runs/Jul09_19-44-56_lyalin_AttentionedYoonKimModel_lr3_dropout0.49569537913353157_noise_level0.0000hyperparameters_search_manual\n",
      "07-09 19:47 root         INFO     Epoch 0. Global step 665. T=2.07min\n",
      "07-09 19:47 root         INFO     In-batch loss      : 0.6998\n",
      "07-09 19:47 root         INFO     Training accuracy  : 0.5013, f1: 0.6622\n",
      "07-09 19:47 root         INFO     Validation accuracy: 0.5016, f1: 0.6605\n",
      "07-09 19:51 root         INFO     Epoch 2. Global step 1995. T=6.23min\n",
      "07-09 19:51 root         INFO     In-batch loss      : 0.6561\n",
      "07-09 19:51 root         INFO     Training accuracy  : 0.6108, f1: 0.6203\n",
      "07-09 19:51 root         INFO     Validation accuracy: 0.6021, f1: 0.6084\n",
      "07-09 19:55 root         INFO     Epoch 4. Global step 3325. T=10.39min\n",
      "07-09 19:55 root         INFO     In-batch loss      : 0.6962\n",
      "07-09 19:55 root         INFO     Training accuracy  : 0.7150, f1: 0.7130\n",
      "07-09 19:55 root         INFO     Validation accuracy: 0.7024, f1: 0.7003\n",
      "07-09 19:59 root         INFO     Epoch 6. Global step 4655. T=14.56min\n",
      "07-09 19:59 root         INFO     In-batch loss      : 0.6482\n",
      "07-09 19:59 root         INFO     Training accuracy  : 0.8055, f1: 0.8024\n",
      "07-09 19:59 root         INFO     Validation accuracy: 0.7981, f1: 0.7961\n",
      "07-09 20:03 root         INFO     Epoch 8. Global step 5985. T=18.72min\n",
      "07-09 20:03 root         INFO     In-batch loss      : 0.0697\n",
      "07-09 20:03 root         INFO     Training accuracy  : 0.8556, f1: 0.8558\n",
      "07-09 20:03 root         INFO     Validation accuracy: 0.8349, f1: 0.8348\n",
      "07-09 20:07 root         INFO     Epoch 10. Global step 7315. T=22.90min\n",
      "07-09 20:07 root         INFO     In-batch loss      : 0.1638\n",
      "07-09 20:07 root         INFO     Training accuracy  : 0.8720, f1: 0.8735\n",
      "07-09 20:07 root         INFO     Validation accuracy: 0.8485, f1: 0.8500\n",
      "07-09 20:11 root         INFO     Epoch 12. Global step 8645. T=27.06min\n",
      "07-09 20:11 root         INFO     In-batch loss      : 0.0301\n",
      "07-09 20:11 root         INFO     Training accuracy  : 0.8877, f1: 0.8879\n",
      "07-09 20:11 root         INFO     Validation accuracy: 0.8571, f1: 0.8571\n",
      "07-09 20:16 root         INFO     Epoch 14. Global step 9975. T=31.23min\n",
      "07-09 20:16 root         INFO     In-batch loss      : 0.8798\n",
      "07-09 20:16 root         INFO     Training accuracy  : 0.8951, f1: 0.8953\n",
      "07-09 20:16 root         INFO     Validation accuracy: 0.8507, f1: 0.8508\n",
      "07-09 20:20 root         INFO     Epoch 16. Global step 11305. T=35.39min\n",
      "07-09 20:20 root         INFO     In-batch loss      : 0.0013\n",
      "07-09 20:20 root         INFO     Training accuracy  : 0.9068, f1: 0.9062\n",
      "07-09 20:20 root         INFO     Validation accuracy: 0.8603, f1: 0.8596\n",
      "Process Process-1741:\n",
      "Process Process-1744:\n",
      "Process Process-1743:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-825e30ffd436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_manual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           save_model_path=None)\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/trainutils.py\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, test_data, noise_level, frac)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_text_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_word_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-1742:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"../text_classification/datautils.py\", line 35, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../text_classification/datautils.py\", line 51, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 64\n",
    "cnn_kernel_size = 5\n",
    "dropout = np.random.rand() * 0.9 + 0.1\n",
    "hidden_dim_out = 256\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "    'heads': 1,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "#     'pool_kernel_size': 4\n",
    "}\n",
    "\n",
    "logger.info('Parameters: %s' % params)\n",
    "model = AttentionedYoonKimModel(**params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=30,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!')\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-09 20:22 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 7, 'hidden_dim_out': 64, 'heads': 1, 'embedding_dim': 67, 'dropout': 0.363531569594306}\n",
      "/home/not_a_robot/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.363531569594306 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "07-09 20:22 root         INFO     Writer: runs/Jul09_20-22-54_lyalin_AttentionedYoonKimModel_lr3_dropout0.363531569594306_noise_level0.0000hyperparameters_search_random\n",
      "07-09 20:24 root         INFO     Epoch 0. Global step 665. T=2.03min\n",
      "07-09 20:24 root         INFO     In-batch loss      : 0.7092\n",
      "07-09 20:24 root         INFO     Training accuracy  : 0.5140, f1: 0.3765\n",
      "07-09 20:24 root         INFO     Validation accuracy: 0.5061, f1: 0.3743\n"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    n_filters = int(np.random.choice([32, 64, 128, 256]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "    hidden_dim_out = int(np.random.choice([64, 128, 256]))\n",
    "    embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'hidden_dim_out': hidden_dim_out,\n",
    "        'heads': 1,\n",
    "    #     'maxlen': maxlen,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "    #     'pool_kernel_size': 4\n",
    "    }\n",
    "\n",
    "    model = AttentionedYoonKimModel(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=20,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8667728237791931"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoonKimModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 9s, sys: 1.35 s, total: 3min 11s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize='spacy', use_vocab=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train_data, test_data = HierarchicalIMDB.splits(text_field, label_field, root='../.data')\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-18 13:49 root         INFO     Parameters: {'n_filters': 32, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 101, 'dropout': 0.5, 'lr': 0.001}\n",
      "07-18 13:49 root         INFO     Writer: runs/Jul18_13-49-42_lyalin_YoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search_manual\n",
      "07-18 13:51 root         INFO     Texts ninth symbols:\n",
      " tensor([ 23,  21,   3,   7,   7,  15,   7,  16,  42,  11,   3,   3,\n",
      "          3,  21,   3,  22,  21,  23,  17,  11,   0,  15,   8,  11,\n",
      "         20,  21,  27,  17,  20,  14,  17,   0], device='cuda:0')\n",
      "07-18 13:51 root         INFO     Prediction:\n",
      " tensor([[-0.1029, -0.1313],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1982, -0.0447],\n",
      "        [-0.1462, -0.0942],\n",
      "        [-0.1234, -0.0969],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1129, -0.1155],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1720, -0.0784],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1300, -0.1040],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1377, -0.0919],\n",
      "        [-0.1703, -0.0401],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1714, -0.0846],\n",
      "        [-0.1490, -0.0729],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1122, -0.0995]], device='cuda:0')\n",
      "07-18 13:51 root         INFO     Texts ninth symbols:\n",
      " tensor([ 17,  17,  10,  21,  20,  11,  21,  17,   3,   7,  16,  17,\n",
      "         22,  11,  10,  11,  11,  17,  17,  21,   7,   3,  21,   5,\n",
      "          0,  20,  10,  15,   7,  20,   3,   3], device='cuda:0')\n",
      "07-18 13:51 root         INFO     Prediction:\n",
      " tensor([[-0.1872, -0.0920],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1631, -0.0833],\n",
      "        [-0.1761, -0.0867],\n",
      "        [-0.1281, -0.1016],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1468, -0.0756],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1326, -0.0983],\n",
      "        [-0.1369, -0.1001],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1192, -0.0903],\n",
      "        [-0.1305, -0.0920],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1730, -0.1048],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1587, -0.0812],\n",
      "        [-0.1155, -0.0997],\n",
      "        [-0.0771, -0.0883],\n",
      "        [-0.0846, -0.1315],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1868, -0.0779],\n",
      "        [-0.1114, -0.1208],\n",
      "        [-0.1970, -0.0802]], device='cuda:0')\n",
      "07-18 13:51 root         INFO     Epoch 0. Global step 665. T=1.38min\n",
      "07-18 13:51 root         INFO     In-batch loss      : 0.7258\n",
      "07-18 13:51 root         INFO     Training accuracy  : 0.5285, f1: 0.4344\n",
      "07-18 13:51 root         INFO     Validation accuracy: 0.5219, f1: 0.4241\n",
      "Process Process-14:\n",
      "Process Process-16:\n",
      "Process Process-13:\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../text_classification/datautils.py\", line 34, in __getitem__\n",
      "    _text_tensor = self.preprocess(item.text)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../text_classification/datautils.py\", line 50, in preprocess\n",
      "    _text_tensor[i*self.max_word_len + j, char2int.get(char, char2int['<UNK>'])] = 1.\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-63afd7638aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_manual'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           save_model_path=None)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# TODO: use embedding lookup instead of one-hot vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/text_classification/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchars_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mwords_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 176\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 32\n",
    "cnn_kernel_size = 5\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 64\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=20,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, acc: %s, parameters: %s' % (\n",
    "        metrics['f1'], metrics['acc'], str(params)\n",
    "    ))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-10 12:36 root         INFO     Parameters: {'n_filters': 512, 'cnn_kernel_size': 7, 'hidden_dim_out': 512, 'embedding_dim': 37, 'dropout': 0.5, 'lr': 0.001}\n",
      "07-10 12:36 root         INFO     Writer: runs/Jul10_12-36-20_lyalin_YoonKimModel_lr3_dropout0.5_noise_level0.0000hyperparameters_search_manual\n",
      "07-10 12:39 root         INFO     Epoch 0. Global step 665. T=2.85min\n",
      "07-10 12:39 root         INFO     In-batch loss      : 0.6960\n",
      "07-10 12:39 root         INFO     Training accuracy  : 0.5008, f1: 0.6674\n",
      "07-10 12:39 root         INFO     Validation accuracy: 0.4955, f1: 0.6626\n",
      "07-10 12:44 root         INFO     Epoch 2. Global step 1995. T=8.49min\n",
      "07-10 12:44 root         INFO     In-batch loss      : 0.7064\n",
      "07-10 12:44 root         INFO     Training accuracy  : 0.5242, f1: 0.3710\n",
      "07-10 12:44 root         INFO     Validation accuracy: 0.5139, f1: 0.3588\n",
      "07-10 12:50 root         INFO     Epoch 4. Global step 3325. T=14.10min\n",
      "07-10 12:50 root         INFO     In-batch loss      : 0.6994\n",
      "07-10 12:50 root         INFO     Training accuracy  : 0.5361, f1: 0.6585\n",
      "07-10 12:50 root         INFO     Validation accuracy: 0.5064, f1: 0.6347\n",
      "07-10 12:56 root         INFO     Epoch 6. Global step 4655. T=19.69min\n",
      "07-10 12:56 root         INFO     In-batch loss      : 0.6396\n",
      "07-10 12:56 root         INFO     Training accuracy  : 0.5636, f1: 0.4160\n",
      "07-10 12:56 root         INFO     Validation accuracy: 0.5216, f1: 0.3652\n",
      "07-10 13:01 root         INFO     Epoch 8. Global step 5985. T=25.29min\n",
      "07-10 13:01 root         INFO     In-batch loss      : 0.4394\n",
      "07-10 13:01 root         INFO     Training accuracy  : 0.6848, f1: 0.6667\n",
      "07-10 13:01 root         INFO     Validation accuracy: 0.6488, f1: 0.6361\n",
      "07-10 13:07 root         INFO     Epoch 10. Global step 7315. T=30.89min\n",
      "07-10 13:07 root         INFO     In-batch loss      : 0.6907\n",
      "07-10 13:07 root         INFO     Training accuracy  : 0.8023, f1: 0.7902\n",
      "07-10 13:07 root         INFO     Validation accuracy: 0.7595, f1: 0.7436\n",
      "07-10 13:12 root         INFO     Epoch 12. Global step 8645. T=36.47min\n",
      "07-10 13:12 root         INFO     In-batch loss      : 1.6833\n",
      "07-10 13:12 root         INFO     Training accuracy  : 0.8899, f1: 0.8899\n",
      "07-10 13:12 root         INFO     Validation accuracy: 0.8320, f1: 0.8320\n",
      "07-10 13:18 root         INFO     Epoch 14. Global step 9975. T=42.13min\n",
      "07-10 13:18 root         INFO     In-batch loss      : 0.0568\n",
      "07-10 13:18 root         INFO     Training accuracy  : 0.9243, f1: 0.9250\n",
      "07-10 13:18 root         INFO     Validation accuracy: 0.8469, f1: 0.8481\n",
      "07-10 13:24 root         INFO     Epoch 16. Global step 11305. T=47.85min\n",
      "07-10 13:24 root         INFO     In-batch loss      : 0.4473\n",
      "07-10 13:24 root         INFO     Training accuracy  : 0.9481, f1: 0.9485\n",
      "07-10 13:24 root         INFO     Validation accuracy: 0.8501, f1: 0.8506\n",
      "07-10 13:29 root         INFO     Epoch 18. Global step 12635. T=53.63min\n",
      "07-10 13:29 root         INFO     In-batch loss      : 0.0022\n",
      "07-10 13:29 root         INFO     Training accuracy  : 0.9687, f1: 0.9686\n",
      "07-10 13:29 root         INFO     Validation accuracy: 0.8467, f1: 0.8459\n",
      "07-10 13:32 root         INFO     Epoch 19. Global step 13300. T=56.49min\n",
      "07-10 13:32 root         INFO     In-batch loss      : 0.0540\n",
      "07-10 13:32 root         INFO     Training accuracy  : 0.9762, f1: 0.9762\n",
      "07-10 13:32 root         INFO     Validation accuracy: 0.8443, f1: 0.8429\n",
      "07-10 13:32 root         WARNING  Model is evaluating in training mode!\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_filters = 512\n",
    "cnn_kernel_size = 7\n",
    "dropout = 0.5\n",
    "hidden_dim_out = 512\n",
    "embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "params = {\n",
    "    'n_filters': n_filters,\n",
    "    'cnn_kernel_size': cnn_kernel_size,\n",
    "    'hidden_dim_out': hidden_dim_out,\n",
    "#     'maxlen': maxlen,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'dropout': dropout,\n",
    "}\n",
    "\n",
    "model = YoonKimModel(**params)\n",
    "params['lr'] = lr\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=20,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='hyperparameters_search_manual',\n",
    "          save_model_path=None)\n",
    "metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "if metrics['f1'] > best_f1:\n",
    "    logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "    best_f1 = metrics['f1']\n",
    "    best_model = model\n",
    "    best_params = params\n",
    "    logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-11 19:29 root         INFO     Parameters: {'n_filters': 128, 'cnn_kernel_size': 5, 'hidden_dim_out': 64, 'embedding_dim': 103, 'dropout': 0.741404662378827, 'lr': 0.0001287332116002057}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d51800f37c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     trained_model =         train(model,\n\u001b[0;32m---> 26\u001b[0;31m               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    n_filters = int(np.random.choice([32, 64, 128, 256]))\n",
    "    cnn_kernel_size = int(np.random.choice([3, 5, 7]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "    hidden_dim_out = int(np.random.choice([64, 128, 256]))\n",
    "    embedding_dim = int(np.random.randint(32, 128))\n",
    "\n",
    "    params = {\n",
    "        'n_filters': n_filters,\n",
    "        'cnn_kernel_size': cnn_kernel_size,\n",
    "        'hidden_dim_out': hidden_dim_out,\n",
    "    #     'maxlen': maxlen,\n",
    "        'embedding_dim': embedding_dim,\n",
    "        'dropout': dropout,\n",
    "    }\n",
    "\n",
    "    model = YoonKimModel(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=20,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8641318798191969,\n",
       " {'n_filters': 256,\n",
       "  'cnn_kernel_size': 5,\n",
       "  'hidden_dim_out': 64,\n",
       "  'embedding_dim': 72,\n",
       "  'dropout': 0.6243415666771305,\n",
       "  'lr': 0.000667854542403568})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-13 16:18 gensim.models.fasttext INFO     loading 111051 words for fastText model from /data/embeddings/wiki.simple.bin\n",
      "07-13 16:18 gensim.models.fasttext INFO     loading weights for 111051 words for fastText model from /data/embeddings/wiki.simple.bin\n",
      "07-13 16:18 gensim.models.fasttext INFO     loaded (111051, 300) weight matrix for fastText model from /data/embeddings/wiki.simple.bin\n"
     ]
    }
   ],
   "source": [
    "embeddings = FastText.load_fasttext_format(cfg.data.fasttext_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got embeddings\n",
      "Got embeddings\n"
     ]
    }
   ],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize='spacy', use_vocab=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train_data, test_data = FastTextIMDB.splits(text_field, label_field, embeddings=embeddings, root='../.data')\n",
    "train_dataloader, val_dataloader, test_dataloader = \\\n",
    "    trainutils.get_dataloaders(train_data, test_data, batch_size=cfg.train.batch_size,\n",
    "                               valid_size=cfg.train.val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 118)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-11 19:43 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.7517732019887394, 'input_dim': 300, 'lr': 0.0002307763213920885}\n",
      "07-11 19:43 root         INFO     Writer: runs/Jul11_19-43-31_lyalin_RNNBinaryClassifier_lr3_dropout0.7517732019887394_noise_level0.0000hyperparameters_search_random\n",
      "07-11 19:44 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-11 19:44 root         INFO     In-batch loss      : 0.7073\n",
      "07-11 19:44 root         INFO     Training accuracy  : 0.5188, f1: 0.6450\n",
      "07-11 19:44 root         INFO     Validation accuracy: 0.5173, f1: 0.6438\n",
      "07-11 19:45 root         INFO     Epoch 2. Global step 1995. T=2.33min\n",
      "07-11 19:45 root         INFO     In-batch loss      : 1.1621\n",
      "07-11 19:45 root         INFO     Training accuracy  : 0.6085, f1: 0.4900\n",
      "07-11 19:45 root         INFO     Validation accuracy: 0.6216, f1: 0.5109\n",
      "07-11 19:47 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-11 19:47 root         INFO     In-batch loss      : 0.1725\n",
      "07-11 19:47 root         INFO     Training accuracy  : 0.7787, f1: 0.7844\n",
      "07-11 19:47 root         INFO     Validation accuracy: 0.7787, f1: 0.7826\n",
      "07-11 19:48 root         INFO     Epoch 6. Global step 4655. T=5.45min\n",
      "07-11 19:48 root         INFO     In-batch loss      : 0.4980\n",
      "07-11 19:48 root         INFO     Training accuracy  : 0.7969, f1: 0.7937\n",
      "07-11 19:48 root         INFO     Validation accuracy: 0.8064, f1: 0.8021\n",
      "07-11 19:50 root         INFO     Epoch 8. Global step 5985. T=7.00min\n",
      "07-11 19:50 root         INFO     In-batch loss      : 1.0306\n",
      "07-11 19:50 root         INFO     Training accuracy  : 0.8138, f1: 0.8154\n",
      "07-11 19:50 root         INFO     Validation accuracy: 0.8240, f1: 0.8252\n",
      "07-11 19:52 root         INFO     Epoch 10. Global step 7315. T=8.53min\n",
      "07-11 19:52 root         INFO     In-batch loss      : 0.2225\n",
      "07-11 19:52 root         INFO     Training accuracy  : 0.8264, f1: 0.8289\n",
      "07-11 19:52 root         INFO     Validation accuracy: 0.8344, f1: 0.8371\n",
      "07-11 19:53 root         INFO     Epoch 12. Global step 8645. T=10.06min\n",
      "07-11 19:53 root         INFO     In-batch loss      : 0.3635\n",
      "07-11 19:53 root         INFO     Training accuracy  : 0.8370, f1: 0.8397\n",
      "07-11 19:53 root         INFO     Validation accuracy: 0.8456, f1: 0.8477\n",
      "07-11 19:55 root         INFO     Epoch 14. Global step 9975. T=11.60min\n",
      "07-11 19:55 root         INFO     In-batch loss      : 0.0449\n",
      "07-11 19:55 root         INFO     Training accuracy  : 0.8487, f1: 0.8494\n",
      "07-11 19:55 root         INFO     Validation accuracy: 0.8512, f1: 0.8514\n",
      "07-11 19:56 root         INFO     Epoch 16. Global step 11305. T=13.14min\n",
      "07-11 19:56 root         INFO     In-batch loss      : 0.1823\n",
      "07-11 19:56 root         INFO     Training accuracy  : 0.8558, f1: 0.8532\n",
      "07-11 19:56 root         INFO     Validation accuracy: 0.8565, f1: 0.8536\n",
      "07-11 19:58 root         INFO     Epoch 18. Global step 12635. T=14.68min\n",
      "07-11 19:58 root         INFO     In-batch loss      : 0.0153\n",
      "07-11 19:58 root         INFO     Training accuracy  : 0.8633, f1: 0.8636\n",
      "07-11 19:58 root         INFO     Validation accuracy: 0.8603, f1: 0.8606\n",
      "07-11 19:58 root         INFO     Epoch 19. Global step 13300. T=15.45min\n",
      "07-11 19:58 root         INFO     In-batch loss      : 2.3931\n",
      "07-11 19:58 root         INFO     Training accuracy  : 0.8673, f1: 0.8677\n",
      "07-11 19:58 root         INFO     Validation accuracy: 0.8603, f1: 0.8606\n",
      "07-11 19:58 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 19:59 root         INFO     YES!, f1: 0.8604961323019473, parameters: {'hidden_dim': 128, 'dropout': 0.7517732019887394, 'input_dim': 300, 'lr': 0.0002307763213920885}\n",
      "07-11 19:59 root         INFO     {'hidden_dim': 128, 'dropout': 0.7517732019887394, 'input_dim': 300, 'lr': 0.0002307763213920885}\n",
      "07-11 19:59 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.6243415666771305, 'input_dim': 300, 'lr': 0.0006540574778883669}\n",
      "07-11 19:59 root         INFO     Writer: runs/Jul11_19-59-03_lyalin_RNNBinaryClassifier_lr3_dropout0.6243415666771305_noise_level0.0000hyperparameters_search_random\n",
      "07-11 20:00 root         INFO     Epoch 0. Global step 665. T=0.95min\n",
      "07-11 20:00 root         INFO     In-batch loss      : 0.5652\n",
      "07-11 20:00 root         INFO     Training accuracy  : 0.5408, f1: 0.3254\n",
      "07-11 20:00 root         INFO     Validation accuracy: 0.5459, f1: 0.3282\n",
      "07-11 20:01 root         INFO     Epoch 2. Global step 1995. T=2.87min\n",
      "07-11 20:01 root         INFO     In-batch loss      : 0.7686\n",
      "07-11 20:01 root         INFO     Training accuracy  : 0.5335, f1: 0.4049\n",
      "07-11 20:01 root         INFO     Validation accuracy: 0.5427, f1: 0.4157\n",
      "07-11 20:03 root         INFO     Epoch 4. Global step 3325. T=4.80min\n",
      "07-11 20:03 root         INFO     In-batch loss      : 0.0807\n",
      "07-11 20:03 root         INFO     Training accuracy  : 0.8488, f1: 0.8485\n",
      "07-11 20:03 root         INFO     Validation accuracy: 0.8525, f1: 0.8501\n",
      "07-11 20:05 root         INFO     Epoch 6. Global step 4655. T=6.72min\n",
      "07-11 20:05 root         INFO     In-batch loss      : 0.0335\n",
      "07-11 20:05 root         INFO     Training accuracy  : 0.8799, f1: 0.8803\n",
      "07-11 20:05 root         INFO     Validation accuracy: 0.8629, f1: 0.8621\n",
      "07-11 20:07 root         INFO     Epoch 8. Global step 5985. T=8.63min\n",
      "07-11 20:07 root         INFO     In-batch loss      : 0.0382\n",
      "07-11 20:07 root         INFO     Training accuracy  : 0.9095, f1: 0.9086\n",
      "07-11 20:07 root         INFO     Validation accuracy: 0.8699, f1: 0.8681\n",
      "07-11 20:09 root         INFO     Epoch 10. Global step 7315. T=10.56min\n",
      "07-11 20:09 root         INFO     In-batch loss      : 0.2192\n",
      "07-11 20:09 root         INFO     Training accuracy  : 0.9410, f1: 0.9408\n",
      "07-11 20:09 root         INFO     Validation accuracy: 0.8669, f1: 0.8664\n",
      "07-11 20:11 root         INFO     Epoch 12. Global step 8645. T=12.48min\n",
      "07-11 20:11 root         INFO     In-batch loss      : 0.0015\n",
      "07-11 20:11 root         INFO     Training accuracy  : 0.9693, f1: 0.9692\n",
      "07-11 20:11 root         INFO     Validation accuracy: 0.8659, f1: 0.8653\n",
      "07-11 20:13 root         INFO     Epoch 14. Global step 9975. T=14.40min\n",
      "07-11 20:13 root         INFO     In-batch loss      : 0.0005\n",
      "07-11 20:13 root         INFO     Training accuracy  : 0.9864, f1: 0.9864\n",
      "07-11 20:13 root         INFO     Validation accuracy: 0.8664, f1: 0.8666\n",
      "07-11 20:15 root         INFO     Epoch 16. Global step 11305. T=16.32min\n",
      "07-11 20:15 root         INFO     In-batch loss      : 0.0002\n",
      "07-11 20:15 root         INFO     Training accuracy  : 0.9936, f1: 0.9936\n",
      "07-11 20:15 root         INFO     Validation accuracy: 0.8683, f1: 0.8680\n",
      "07-11 20:17 root         INFO     Epoch 18. Global step 12635. T=18.25min\n",
      "07-11 20:17 root         INFO     In-batch loss      : 0.0012\n",
      "07-11 20:17 root         INFO     Training accuracy  : 0.9957, f1: 0.9957\n",
      "07-11 20:17 root         INFO     Validation accuracy: 0.8600, f1: 0.8628\n",
      "07-11 20:18 root         INFO     Epoch 19. Global step 13300. T=19.21min\n",
      "07-11 20:18 root         INFO     In-batch loss      : 0.0006\n",
      "07-11 20:18 root         INFO     Training accuracy  : 0.9972, f1: 0.9972\n",
      "07-11 20:18 root         INFO     Validation accuracy: 0.8645, f1: 0.8650\n",
      "07-11 20:18 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 20:18 root         INFO     YES!, f1: 0.8669322709163346, parameters: {'hidden_dim': 1024, 'dropout': 0.6243415666771305, 'input_dim': 300, 'lr': 0.0006540574778883669}\n",
      "07-11 20:18 root         INFO     {'hidden_dim': 1024, 'dropout': 0.6243415666771305, 'input_dim': 300, 'lr': 0.0006540574778883669}\n",
      "07-11 20:18 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.6475671297455317, 'input_dim': 300, 'lr': 0.0004365147302303688}\n",
      "07-11 20:18 root         INFO     Writer: runs/Jul11_20-18-19_lyalin_RNNBinaryClassifier_lr3_dropout0.6475671297455317_noise_level0.0000hyperparameters_search_random\n",
      "07-11 20:19 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 20:19 root         INFO     In-batch loss      : 1.1630\n",
      "07-11 20:19 root         INFO     Training accuracy  : 0.6291, f1: 0.6416\n",
      "07-11 20:19 root         INFO     Validation accuracy: 0.6269, f1: 0.6367\n",
      "07-11 20:20 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 20:20 root         INFO     In-batch loss      : 0.3606\n",
      "07-11 20:20 root         INFO     Training accuracy  : 0.7202, f1: 0.7074\n",
      "07-11 20:20 root         INFO     Validation accuracy: 0.7200, f1: 0.7070\n",
      "07-11 20:22 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-11 20:22 root         INFO     In-batch loss      : 0.2311\n",
      "07-11 20:22 root         INFO     Training accuracy  : 0.7735, f1: 0.7818\n",
      "07-11 20:22 root         INFO     Validation accuracy: 0.7701, f1: 0.7777\n",
      "07-11 20:23 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-11 20:23 root         INFO     In-batch loss      : 0.2126\n",
      "07-11 20:23 root         INFO     Training accuracy  : 0.8248, f1: 0.8285\n",
      "07-11 20:23 root         INFO     Validation accuracy: 0.8251, f1: 0.8286\n",
      "07-11 20:25 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-11 20:25 root         INFO     In-batch loss      : 0.6639\n",
      "07-11 20:25 root         INFO     Training accuracy  : 0.8536, f1: 0.8563\n",
      "07-11 20:25 root         INFO     Validation accuracy: 0.8483, f1: 0.8503\n",
      "07-11 20:26 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-11 20:26 root         INFO     In-batch loss      : 0.0177\n",
      "07-11 20:26 root         INFO     Training accuracy  : 0.8711, f1: 0.8708\n",
      "07-11 20:26 root         INFO     Validation accuracy: 0.8579, f1: 0.8565\n",
      "07-11 20:28 root         INFO     Epoch 12. Global step 8645. T=10.02min\n",
      "07-11 20:28 root         INFO     In-batch loss      : 0.0379\n",
      "07-11 20:28 root         INFO     Training accuracy  : 0.8840, f1: 0.8829\n",
      "07-11 20:28 root         INFO     Validation accuracy: 0.8632, f1: 0.8615\n",
      "07-11 20:29 root         INFO     Epoch 14. Global step 9975. T=11.56min\n",
      "07-11 20:29 root         INFO     In-batch loss      : 0.0208\n",
      "07-11 20:29 root         INFO     Training accuracy  : 0.8945, f1: 0.8935\n",
      "07-11 20:29 root         INFO     Validation accuracy: 0.8701, f1: 0.8690\n",
      "07-11 20:31 root         INFO     Epoch 16. Global step 11305. T=13.09min\n",
      "07-11 20:31 root         INFO     In-batch loss      : 0.2961\n",
      "07-11 20:31 root         INFO     Training accuracy  : 0.9055, f1: 0.9054\n",
      "07-11 20:31 root         INFO     Validation accuracy: 0.8680, f1: 0.8673\n",
      "07-11 20:32 root         INFO     Epoch 18. Global step 12635. T=14.63min\n",
      "07-11 20:32 root         INFO     In-batch loss      : 0.0245\n",
      "07-11 20:32 root         INFO     Training accuracy  : 0.9172, f1: 0.9166\n",
      "07-11 20:32 root         INFO     Validation accuracy: 0.8688, f1: 0.8675\n",
      "07-11 20:33 root         INFO     Epoch 19. Global step 13300. T=15.39min\n",
      "07-11 20:33 root         INFO     In-batch loss      : 0.4896\n",
      "07-11 20:33 root         INFO     Training accuracy  : 0.9229, f1: 0.9225\n",
      "07-11 20:33 root         INFO     Validation accuracy: 0.8688, f1: 0.8678\n",
      "07-11 20:33 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 20:33 root         INFO     YES!, f1: 0.8679549114331724, parameters: {'hidden_dim': 256, 'dropout': 0.6475671297455317, 'input_dim': 300, 'lr': 0.0004365147302303688}\n",
      "07-11 20:33 root         INFO     {'hidden_dim': 256, 'dropout': 0.6475671297455317, 'input_dim': 300, 'lr': 0.0004365147302303688}\n",
      "07-11 20:33 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.5656088852732918, 'input_dim': 300, 'lr': 0.00023196682611679867}\n",
      "07-11 20:33 root         INFO     Writer: runs/Jul11_20-33-47_lyalin_RNNBinaryClassifier_lr3_dropout0.5656088852732918_noise_level0.0000hyperparameters_search_random\n",
      "07-11 20:34 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 20:34 root         INFO     In-batch loss      : 0.7206\n",
      "07-11 20:34 root         INFO     Training accuracy  : 0.5285, f1: 0.2901\n",
      "07-11 20:34 root         INFO     Validation accuracy: 0.5373, f1: 0.3012\n",
      "07-11 20:36 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 20:36 root         INFO     In-batch loss      : 0.3248\n",
      "07-11 20:36 root         INFO     Training accuracy  : 0.7645, f1: 0.7582\n",
      "07-11 20:36 root         INFO     Validation accuracy: 0.7632, f1: 0.7564\n",
      "07-11 20:37 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-11 20:37 root         INFO     In-batch loss      : 0.2823\n",
      "07-11 20:37 root         INFO     Training accuracy  : 0.7915, f1: 0.7921\n",
      "07-11 20:37 root         INFO     Validation accuracy: 0.7904, f1: 0.7905\n",
      "07-11 20:39 root         INFO     Epoch 6. Global step 4655. T=5.38min\n",
      "07-11 20:39 root         INFO     In-batch loss      : 0.1105\n",
      "07-11 20:39 root         INFO     Training accuracy  : 0.8118, f1: 0.8108\n",
      "07-11 20:39 root         INFO     Validation accuracy: 0.8144, f1: 0.8128\n",
      "07-11 20:40 root         INFO     Epoch 8. Global step 5985. T=6.92min\n",
      "07-11 20:40 root         INFO     In-batch loss      : 0.4072\n",
      "07-11 20:40 root         INFO     Training accuracy  : 0.8313, f1: 0.8293\n",
      "07-11 20:40 root         INFO     Validation accuracy: 0.8339, f1: 0.8314\n",
      "07-11 20:42 root         INFO     Epoch 10. Global step 7315. T=8.45min\n",
      "07-11 20:42 root         INFO     In-batch loss      : 0.2629\n",
      "07-11 20:42 root         INFO     Training accuracy  : 0.8475, f1: 0.8467\n",
      "07-11 20:42 root         INFO     Validation accuracy: 0.8499, f1: 0.8483\n",
      "07-11 20:43 root         INFO     Epoch 12. Global step 8645. T=9.99min\n",
      "07-11 20:43 root         INFO     In-batch loss      : 0.7589\n",
      "07-11 20:43 root         INFO     Training accuracy  : 0.8586, f1: 0.8590\n",
      "07-11 20:43 root         INFO     Validation accuracy: 0.8573, f1: 0.8575\n",
      "07-11 20:45 root         INFO     Epoch 14. Global step 9975. T=11.53min\n",
      "07-11 20:45 root         INFO     In-batch loss      : 0.0401\n",
      "07-11 20:45 root         INFO     Training accuracy  : 0.8662, f1: 0.8663\n",
      "07-11 20:45 root         INFO     Validation accuracy: 0.8571, f1: 0.8566\n",
      "07-11 20:46 root         INFO     Epoch 16. Global step 11305. T=13.07min\n",
      "07-11 20:46 root         INFO     In-batch loss      : 0.1327\n",
      "07-11 20:46 root         INFO     Training accuracy  : 0.8754, f1: 0.8741\n",
      "07-11 20:46 root         INFO     Validation accuracy: 0.8629, f1: 0.8609\n",
      "07-11 20:48 root         INFO     Epoch 18. Global step 12635. T=14.60min\n",
      "07-11 20:48 root         INFO     In-batch loss      : 0.1005\n",
      "07-11 20:48 root         INFO     Training accuracy  : 0.8817, f1: 0.8827\n",
      "07-11 20:48 root         INFO     Validation accuracy: 0.8672, f1: 0.8682\n",
      "07-11 20:49 root         INFO     Epoch 19. Global step 13300. T=15.37min\n",
      "07-11 20:49 root         INFO     In-batch loss      : 0.0907\n",
      "07-11 20:49 root         INFO     Training accuracy  : 0.8861, f1: 0.8856\n",
      "07-11 20:49 root         INFO     Validation accuracy: 0.8651, f1: 0.8640\n",
      "07-11 20:49 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 20:49 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.5206228161570272, 'input_dim': 300, 'lr': 0.0001566044432148894}\n",
      "07-11 20:49 root         INFO     Writer: runs/Jul11_20-49-14_lyalin_RNNBinaryClassifier_lr3_dropout0.5206228161570272_noise_level0.0000hyperparameters_search_random\n",
      "07-11 20:50 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-11 20:50 root         INFO     In-batch loss      : 0.5486\n",
      "07-11 20:50 root         INFO     Training accuracy  : 0.5398, f1: 0.3400\n",
      "07-11 20:50 root         INFO     Validation accuracy: 0.5491, f1: 0.3519\n",
      "07-11 20:51 root         INFO     Epoch 2. Global step 1995. T=2.38min\n",
      "07-11 20:51 root         INFO     In-batch loss      : 0.3180\n",
      "07-11 20:51 root         INFO     Training accuracy  : 0.7635, f1: 0.7557\n",
      "07-11 20:51 root         INFO     Validation accuracy: 0.7640, f1: 0.7556\n",
      "07-11 20:53 root         INFO     Epoch 4. Global step 3325. T=3.96min\n",
      "07-11 20:53 root         INFO     In-batch loss      : 0.2669\n",
      "07-11 20:53 root         INFO     Training accuracy  : 0.7909, f1: 0.7881\n",
      "07-11 20:53 root         INFO     Validation accuracy: 0.7944, f1: 0.7894\n",
      "07-11 20:54 root         INFO     Epoch 6. Global step 4655. T=5.55min\n",
      "07-11 20:54 root         INFO     In-batch loss      : 0.9913\n",
      "07-11 20:54 root         INFO     Training accuracy  : 0.8048, f1: 0.8012\n",
      "07-11 20:54 root         INFO     Validation accuracy: 0.8107, f1: 0.8058\n",
      "07-11 20:56 root         INFO     Epoch 8. Global step 5985. T=7.13min\n",
      "07-11 20:56 root         INFO     In-batch loss      : 0.0927\n",
      "07-11 20:56 root         INFO     Training accuracy  : 0.8198, f1: 0.8145\n",
      "07-11 20:56 root         INFO     Validation accuracy: 0.8288, f1: 0.8228\n",
      "07-11 20:57 root         INFO     Epoch 10. Global step 7315. T=8.73min\n",
      "07-11 20:57 root         INFO     In-batch loss      : 1.2237\n",
      "07-11 20:57 root         INFO     Training accuracy  : 0.8398, f1: 0.8367\n",
      "07-11 20:57 root         INFO     Validation accuracy: 0.8419, f1: 0.8382\n",
      "07-11 20:59 root         INFO     Epoch 12. Global step 8645. T=10.32min\n",
      "07-11 20:59 root         INFO     In-batch loss      : 0.3745\n",
      "07-11 20:59 root         INFO     Training accuracy  : 0.8517, f1: 0.8515\n",
      "07-11 20:59 root         INFO     Validation accuracy: 0.8496, f1: 0.8490\n",
      "07-11 21:01 root         INFO     Epoch 14. Global step 9975. T=11.91min\n",
      "07-11 21:01 root         INFO     In-batch loss      : 0.0497\n",
      "07-11 21:01 root         INFO     Training accuracy  : 0.8610, f1: 0.8596\n",
      "07-11 21:01 root         INFO     Validation accuracy: 0.8549, f1: 0.8531\n",
      "07-11 21:02 root         INFO     Epoch 16. Global step 11305. T=13.48min\n",
      "07-11 21:02 root         INFO     In-batch loss      : 0.3536\n",
      "07-11 21:02 root         INFO     Training accuracy  : 0.8693, f1: 0.8701\n",
      "07-11 21:02 root         INFO     Validation accuracy: 0.8581, f1: 0.8587\n",
      "07-11 21:04 root         INFO     Epoch 18. Global step 12635. T=15.07min\n",
      "07-11 21:04 root         INFO     In-batch loss      : 0.2278\n",
      "07-11 21:04 root         INFO     Training accuracy  : 0.8778, f1: 0.8789\n",
      "07-11 21:04 root         INFO     Validation accuracy: 0.8648, f1: 0.8658\n",
      "07-11 21:05 root         INFO     Epoch 19. Global step 13300. T=15.87min\n",
      "07-11 21:05 root         INFO     In-batch loss      : 0.5458\n",
      "07-11 21:05 root         INFO     Training accuracy  : 0.8821, f1: 0.8825\n",
      "07-11 21:05 root         INFO     Validation accuracy: 0.8624, f1: 0.8632\n",
      "07-11 21:05 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 21:05 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.48874008102712896, 'input_dim': 300, 'lr': 0.0005292725470864853}\n",
      "07-11 21:05 root         INFO     Writer: runs/Jul11_21-05-10_lyalin_RNNBinaryClassifier_lr3_dropout0.48874008102712896_noise_level0.0000hyperparameters_search_random\n",
      "07-11 21:05 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 21:05 root         INFO     In-batch loss      : 0.7218\n",
      "07-11 21:05 root         INFO     Training accuracy  : 0.5209, f1: 0.3367\n",
      "07-11 21:05 root         INFO     Validation accuracy: 0.5312, f1: 0.3518\n",
      "07-11 21:07 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 21:07 root         INFO     In-batch loss      : 0.4640\n",
      "07-11 21:07 root         INFO     Training accuracy  : 0.5790, f1: 0.6736\n",
      "07-11 21:07 root         INFO     Validation accuracy: 0.5720, f1: 0.6654\n",
      "07-11 21:09 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-11 21:09 root         INFO     In-batch loss      : 0.3341\n",
      "07-11 21:09 root         INFO     Training accuracy  : 0.7499, f1: 0.7413\n",
      "07-11 21:09 root         INFO     Validation accuracy: 0.7480, f1: 0.7386\n",
      "07-11 21:10 root         INFO     Epoch 6. Global step 4655. T=5.38min\n",
      "07-11 21:10 root         INFO     In-batch loss      : 0.6404\n",
      "07-11 21:10 root         INFO     Training accuracy  : 0.7920, f1: 0.7948\n",
      "07-11 21:10 root         INFO     Validation accuracy: 0.7955, f1: 0.7999\n",
      "07-11 21:12 root         INFO     Epoch 8. Global step 5985. T=6.92min\n",
      "07-11 21:12 root         INFO     In-batch loss      : 0.3841\n",
      "07-11 21:12 root         INFO     Training accuracy  : 0.8177, f1: 0.8215\n",
      "07-11 21:12 root         INFO     Validation accuracy: 0.8221, f1: 0.8266\n",
      "07-11 21:13 root         INFO     Epoch 10. Global step 7315. T=8.45min\n",
      "07-11 21:13 root         INFO     In-batch loss      : 0.1551\n",
      "07-11 21:13 root         INFO     Training accuracy  : 0.8361, f1: 0.8383\n",
      "07-11 21:13 root         INFO     Validation accuracy: 0.8384, f1: 0.8404\n",
      "07-11 21:15 root         INFO     Epoch 12. Global step 8645. T=9.99min\n",
      "07-11 21:15 root         INFO     In-batch loss      : 0.7715\n",
      "07-11 21:15 root         INFO     Training accuracy  : 0.8493, f1: 0.8485\n",
      "07-11 21:15 root         INFO     Validation accuracy: 0.8517, f1: 0.8504\n",
      "07-11 21:16 root         INFO     Epoch 14. Global step 9975. T=11.52min\n",
      "07-11 21:16 root         INFO     In-batch loss      : 0.1600\n",
      "07-11 21:16 root         INFO     Training accuracy  : 0.8596, f1: 0.8603\n",
      "07-11 21:16 root         INFO     Validation accuracy: 0.8552, f1: 0.8559\n",
      "07-11 21:18 root         INFO     Epoch 16. Global step 11305. T=13.05min\n",
      "07-11 21:18 root         INFO     In-batch loss      : 0.0871\n",
      "07-11 21:18 root         INFO     Training accuracy  : 0.8671, f1: 0.8650\n",
      "07-11 21:18 root         INFO     Validation accuracy: 0.8592, f1: 0.8561\n",
      "07-11 21:19 root         INFO     Epoch 18. Global step 12635. T=14.59min\n",
      "07-11 21:19 root         INFO     In-batch loss      : 0.0792\n",
      "07-11 21:19 root         INFO     Training accuracy  : 0.8760, f1: 0.8770\n",
      "07-11 21:19 root         INFO     Validation accuracy: 0.8624, f1: 0.8635\n",
      "07-11 21:20 root         INFO     Epoch 19. Global step 13300. T=15.35min\n",
      "07-11 21:20 root         INFO     In-batch loss      : 0.2172\n",
      "07-11 21:20 root         INFO     Training accuracy  : 0.8783, f1: 0.8769\n",
      "07-11 21:20 root         INFO     Validation accuracy: 0.8627, f1: 0.8610\n",
      "07-11 21:20 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 21:20 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.49223155699823873, 'input_dim': 300, 'lr': 0.00025722052100092026}\n",
      "07-11 21:20 root         INFO     Writer: runs/Jul11_21-20-35_lyalin_RNNBinaryClassifier_lr3_dropout0.49223155699823873_noise_level0.0000hyperparameters_search_random\n",
      "07-11 21:21 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 21:21 root         INFO     In-batch loss      : 0.6403\n",
      "07-11 21:21 root         INFO     Training accuracy  : 0.5187, f1: 0.3123\n",
      "07-11 21:21 root         INFO     Validation accuracy: 0.5213, f1: 0.3120\n",
      "07-11 21:22 root         INFO     Epoch 2. Global step 1995. T=2.29min\n",
      "07-11 21:22 root         INFO     In-batch loss      : 0.6766\n",
      "07-11 21:22 root         INFO     Training accuracy  : 0.5326, f1: 0.6466\n",
      "07-11 21:22 root         INFO     Validation accuracy: 0.5328, f1: 0.6424\n",
      "07-11 21:24 root         INFO     Epoch 4. Global step 3325. T=3.84min\n",
      "07-11 21:24 root         INFO     In-batch loss      : 0.3496\n",
      "07-11 21:24 root         INFO     Training accuracy  : 0.6876, f1: 0.6579\n",
      "07-11 21:24 root         INFO     Validation accuracy: 0.6837, f1: 0.6584\n",
      "07-11 21:25 root         INFO     Epoch 6. Global step 4655. T=5.37min\n",
      "07-11 21:25 root         INFO     In-batch loss      : 0.6230\n",
      "07-11 21:25 root         INFO     Training accuracy  : 0.7280, f1: 0.7099\n",
      "07-11 21:25 root         INFO     Validation accuracy: 0.7229, f1: 0.7054\n",
      "07-11 21:27 root         INFO     Epoch 8. Global step 5985. T=6.91min\n",
      "07-11 21:27 root         INFO     In-batch loss      : 0.7349\n",
      "07-11 21:27 root         INFO     Training accuracy  : 0.7628, f1: 0.7553\n",
      "07-11 21:27 root         INFO     Validation accuracy: 0.7576, f1: 0.7494\n",
      "07-11 21:29 root         INFO     Epoch 10. Global step 7315. T=8.45min\n",
      "07-11 21:29 root         INFO     In-batch loss      : 0.2306\n",
      "07-11 21:29 root         INFO     Training accuracy  : 0.7656, f1: 0.7425\n",
      "07-11 21:29 root         INFO     Validation accuracy: 0.7619, f1: 0.7379\n",
      "07-11 21:30 root         INFO     Epoch 12. Global step 8645. T=9.99min\n",
      "07-11 21:30 root         INFO     In-batch loss      : 1.5241\n",
      "07-11 21:30 root         INFO     Training accuracy  : 0.7928, f1: 0.7902\n",
      "07-11 21:30 root         INFO     Validation accuracy: 0.7885, f1: 0.7863\n",
      "07-11 21:32 root         INFO     Epoch 14. Global step 9975. T=11.52min\n",
      "07-11 21:32 root         INFO     In-batch loss      : 0.5180\n",
      "07-11 21:32 root         INFO     Training accuracy  : 0.8032, f1: 0.7948\n",
      "07-11 21:32 root         INFO     Validation accuracy: 0.7952, f1: 0.7864\n",
      "07-11 21:33 root         INFO     Epoch 16. Global step 11305. T=13.06min\n",
      "07-11 21:33 root         INFO     In-batch loss      : 0.5555\n",
      "07-11 21:33 root         INFO     Training accuracy  : 0.8170, f1: 0.8115\n",
      "07-11 21:33 root         INFO     Validation accuracy: 0.8157, f1: 0.8095\n",
      "07-11 21:35 root         INFO     Epoch 18. Global step 12635. T=14.60min\n",
      "07-11 21:35 root         INFO     In-batch loss      : 0.1929\n",
      "07-11 21:35 root         INFO     Training accuracy  : 0.8291, f1: 0.8270\n",
      "07-11 21:35 root         INFO     Validation accuracy: 0.8299, f1: 0.8270\n",
      "07-11 21:35 root         INFO     Epoch 19. Global step 13300. T=15.37min\n",
      "07-11 21:35 root         INFO     In-batch loss      : 0.0771\n",
      "07-11 21:35 root         INFO     Training accuracy  : 0.8334, f1: 0.8323\n",
      "07-11 21:35 root         INFO     Validation accuracy: 0.8333, f1: 0.8313\n",
      "07-11 21:35 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 21:36 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.886844823932365, 'input_dim': 300, 'lr': 0.00014080785556174058}\n",
      "07-11 21:36 root         INFO     Writer: runs/Jul11_21-36-01_lyalin_RNNBinaryClassifier_lr3_dropout0.886844823932365_noise_level0.0000hyperparameters_search_random\n",
      "07-11 21:36 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 21:36 root         INFO     In-batch loss      : 0.6583\n",
      "07-11 21:36 root         INFO     Training accuracy  : 0.5039, f1: 0.6172\n",
      "07-11 21:36 root         INFO     Validation accuracy: 0.5000, f1: 0.6108\n",
      "07-11 21:38 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 21:38 root         INFO     In-batch loss      : 0.7206\n",
      "07-11 21:38 root         INFO     Training accuracy  : 0.5079, f1: 0.6453\n",
      "07-11 21:38 root         INFO     Validation accuracy: 0.5029, f1: 0.6395\n",
      "07-11 21:39 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-11 21:39 root         INFO     In-batch loss      : 0.6666\n",
      "07-11 21:39 root         INFO     Training accuracy  : 0.5140, f1: 0.6446\n",
      "07-11 21:39 root         INFO     Validation accuracy: 0.5075, f1: 0.6369\n",
      "07-11 21:41 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-11 21:41 root         INFO     In-batch loss      : 0.6226\n",
      "07-11 21:41 root         INFO     Training accuracy  : 0.5153, f1: 0.6521\n",
      "07-11 21:41 root         INFO     Validation accuracy: 0.5080, f1: 0.6453\n",
      "07-11 21:42 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-11 21:42 root         INFO     In-batch loss      : 0.6071\n",
      "07-11 21:42 root         INFO     Training accuracy  : 0.5225, f1: 0.3451\n",
      "07-11 21:42 root         INFO     Validation accuracy: 0.5277, f1: 0.3539\n",
      "07-11 21:44 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-11 21:44 root         INFO     In-batch loss      : 0.6902\n",
      "07-11 21:44 root         INFO     Training accuracy  : 0.5233, f1: 0.3333\n",
      "07-11 21:44 root         INFO     Validation accuracy: 0.5251, f1: 0.3367\n",
      "07-11 21:46 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-11 21:46 root         INFO     In-batch loss      : 0.6964\n",
      "07-11 21:46 root         INFO     Training accuracy  : 0.5265, f1: 0.3527\n",
      "07-11 21:46 root         INFO     Validation accuracy: 0.5293, f1: 0.3589\n",
      "07-11 21:47 root         INFO     Epoch 14. Global step 9975. T=11.55min\n",
      "07-11 21:47 root         INFO     In-batch loss      : 0.6853\n",
      "07-11 21:47 root         INFO     Training accuracy  : 0.5315, f1: 0.3621\n",
      "07-11 21:47 root         INFO     Validation accuracy: 0.5328, f1: 0.3693\n",
      "07-11 21:49 root         INFO     Epoch 16. Global step 11305. T=13.08min\n",
      "07-11 21:49 root         INFO     In-batch loss      : 0.5900\n",
      "07-11 21:49 root         INFO     Training accuracy  : 0.5459, f1: 0.3480\n",
      "07-11 21:49 root         INFO     Validation accuracy: 0.5467, f1: 0.3511\n",
      "07-11 21:50 root         INFO     Epoch 18. Global step 12635. T=14.62min\n",
      "07-11 21:50 root         INFO     In-batch loss      : 0.5802\n",
      "07-11 21:50 root         INFO     Training accuracy  : 0.6143, f1: 0.5180\n",
      "07-11 21:50 root         INFO     Validation accuracy: 0.6216, f1: 0.5343\n",
      "07-11 21:51 root         INFO     Epoch 19. Global step 13300. T=15.39min\n",
      "07-11 21:51 root         INFO     In-batch loss      : 0.5198\n",
      "07-11 21:51 root         INFO     Training accuracy  : 0.6536, f1: 0.5955\n",
      "07-11 21:51 root         INFO     Validation accuracy: 0.6587, f1: 0.6044\n",
      "07-11 21:51 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 21:51 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.9063182248583417, 'input_dim': 300, 'lr': 0.0007636340878962797}\n",
      "07-11 21:51 root         INFO     Writer: runs/Jul11_21-51-29_lyalin_RNNBinaryClassifier_lr3_dropout0.9063182248583417_noise_level0.0000hyperparameters_search_random\n",
      "07-11 21:52 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-11 21:52 root         INFO     In-batch loss      : 0.8253\n",
      "07-11 21:52 root         INFO     Training accuracy  : 0.5344, f1: 0.3744\n",
      "07-11 21:52 root         INFO     Validation accuracy: 0.5395, f1: 0.3869\n",
      "07-11 21:54 root         INFO     Epoch 2. Global step 1995. T=2.89min\n",
      "07-11 21:54 root         INFO     In-batch loss      : 0.9320\n",
      "07-11 21:54 root         INFO     Training accuracy  : 0.5194, f1: 0.5432\n",
      "07-11 21:54 root         INFO     Validation accuracy: 0.5051, f1: 0.5212\n",
      "07-11 21:56 root         INFO     Epoch 4. Global step 3325. T=4.80min\n",
      "07-11 21:56 root         INFO     In-batch loss      : 0.6844\n",
      "07-11 21:56 root         INFO     Training accuracy  : 0.5641, f1: 0.5754\n",
      "07-11 21:56 root         INFO     Validation accuracy: 0.5549, f1: 0.5693\n",
      "07-11 21:58 root         INFO     Epoch 6. Global step 4655. T=6.72min\n",
      "07-11 21:58 root         INFO     In-batch loss      : 0.8454\n",
      "07-11 21:58 root         INFO     Training accuracy  : 0.6004, f1: 0.5762\n",
      "07-11 21:58 root         INFO     Validation accuracy: 0.5955, f1: 0.5669\n",
      "07-11 22:00 root         INFO     Epoch 8. Global step 5985. T=8.65min\n",
      "07-11 22:00 root         INFO     In-batch loss      : 1.1773\n",
      "07-11 22:00 root         INFO     Training accuracy  : 0.6402, f1: 0.6403\n",
      "07-11 22:00 root         INFO     Validation accuracy: 0.6197, f1: 0.6156\n",
      "07-11 22:02 root         INFO     Epoch 10. Global step 7315. T=10.59min\n",
      "07-11 22:02 root         INFO     In-batch loss      : 0.4637\n",
      "07-11 22:02 root         INFO     Training accuracy  : 0.7639, f1: 0.7665\n",
      "07-11 22:02 root         INFO     Validation accuracy: 0.7600, f1: 0.7637\n",
      "07-11 22:03 root         INFO     Epoch 12. Global step 8645. T=12.51min\n",
      "07-11 22:03 root         INFO     In-batch loss      : 0.1082\n",
      "07-11 22:03 root         INFO     Training accuracy  : 0.8297, f1: 0.8307\n",
      "07-11 22:03 root         INFO     Validation accuracy: 0.8309, f1: 0.8308\n",
      "07-11 22:05 root         INFO     Epoch 14. Global step 9975. T=14.42min\n",
      "07-11 22:05 root         INFO     In-batch loss      : 0.8134\n",
      "07-11 22:05 root         INFO     Training accuracy  : 0.8643, f1: 0.8636\n",
      "07-11 22:05 root         INFO     Validation accuracy: 0.8493, f1: 0.8476\n",
      "07-11 22:07 root         INFO     Epoch 16. Global step 11305. T=16.36min\n",
      "07-11 22:07 root         INFO     In-batch loss      : 0.3283\n",
      "07-11 22:07 root         INFO     Training accuracy  : 0.8882, f1: 0.8874\n",
      "07-11 22:07 root         INFO     Validation accuracy: 0.8595, f1: 0.8578\n",
      "07-11 22:09 root         INFO     Epoch 18. Global step 12635. T=18.29min\n",
      "07-11 22:09 root         INFO     In-batch loss      : 0.6173\n",
      "07-11 22:09 root         INFO     Training accuracy  : 0.9072, f1: 0.9077\n",
      "07-11 22:09 root         INFO     Validation accuracy: 0.8667, f1: 0.8670\n",
      "07-11 22:10 root         INFO     Epoch 19. Global step 13300. T=19.25min\n",
      "07-11 22:10 root         INFO     In-batch loss      : 0.1287\n",
      "07-11 22:10 root         INFO     Training accuracy  : 0.9163, f1: 0.9167\n",
      "07-11 22:10 root         INFO     Validation accuracy: 0.8643, f1: 0.8646\n",
      "07-11 22:10 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 22:10 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.7540804516584123, 'input_dim': 300, 'lr': 0.00021955899381804532}\n",
      "07-11 22:10 root         INFO     Writer: runs/Jul11_22-10-48_lyalin_RNNBinaryClassifier_lr3_dropout0.7540804516584123_noise_level0.0000hyperparameters_search_random\n",
      "07-11 22:11 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-11 22:11 root         INFO     In-batch loss      : 0.7145\n",
      "07-11 22:11 root         INFO     Training accuracy  : 0.5343, f1: 0.3590\n",
      "07-11 22:11 root         INFO     Validation accuracy: 0.5493, f1: 0.3787\n",
      "07-11 22:13 root         INFO     Epoch 2. Global step 1995. T=2.89min\n",
      "07-11 22:13 root         INFO     In-batch loss      : 0.8758\n",
      "07-11 22:13 root         INFO     Training accuracy  : 0.6950, f1: 0.6740\n",
      "07-11 22:13 root         INFO     Validation accuracy: 0.6984, f1: 0.6790\n",
      "07-11 22:15 root         INFO     Epoch 4. Global step 3325. T=4.82min\n",
      "07-11 22:15 root         INFO     In-batch loss      : 0.7496\n",
      "07-11 22:15 root         INFO     Training accuracy  : 0.7164, f1: 0.6626\n",
      "07-11 22:15 root         INFO     Validation accuracy: 0.7125, f1: 0.6584\n",
      "07-11 22:17 root         INFO     Epoch 6. Global step 4655. T=6.74min\n",
      "07-11 22:17 root         INFO     In-batch loss      : 0.4577\n",
      "07-11 22:17 root         INFO     Training accuracy  : 0.7832, f1: 0.7670\n",
      "07-11 22:17 root         INFO     Validation accuracy: 0.7813, f1: 0.7662\n",
      "07-11 22:19 root         INFO     Epoch 8. Global step 5985. T=8.67min\n",
      "07-11 22:19 root         INFO     In-batch loss      : 1.0769\n",
      "07-11 22:19 root         INFO     Training accuracy  : 0.8508, f1: 0.8494\n",
      "07-11 22:19 root         INFO     Validation accuracy: 0.8544, f1: 0.8525\n",
      "07-11 22:21 root         INFO     Epoch 10. Global step 7315. T=10.60min\n",
      "07-11 22:21 root         INFO     In-batch loss      : 0.0147\n",
      "07-11 22:21 root         INFO     Training accuracy  : 0.8726, f1: 0.8722\n",
      "07-11 22:21 root         INFO     Validation accuracy: 0.8627, f1: 0.8612\n",
      "07-11 22:23 root         INFO     Epoch 12. Global step 8645. T=12.51min\n",
      "07-11 22:23 root         INFO     In-batch loss      : 0.0309\n",
      "07-11 22:23 root         INFO     Training accuracy  : 0.8840, f1: 0.8855\n",
      "07-11 22:23 root         INFO     Validation accuracy: 0.8659, f1: 0.8670\n",
      "07-11 22:25 root         INFO     Epoch 14. Global step 9975. T=14.43min\n",
      "07-11 22:25 root         INFO     In-batch loss      : 0.0083\n",
      "07-11 22:25 root         INFO     Training accuracy  : 0.8969, f1: 0.8970\n",
      "07-11 22:25 root         INFO     Validation accuracy: 0.8661, f1: 0.8649\n",
      "07-11 22:27 root         INFO     Epoch 16. Global step 11305. T=16.36min\n",
      "07-11 22:27 root         INFO     In-batch loss      : 0.0098\n",
      "07-11 22:27 root         INFO     Training accuracy  : 0.9072, f1: 0.9066\n",
      "07-11 22:27 root         INFO     Validation accuracy: 0.8659, f1: 0.8632\n",
      "07-11 22:29 root         INFO     Epoch 18. Global step 12635. T=18.28min\n",
      "07-11 22:29 root         INFO     In-batch loss      : 0.0250\n",
      "07-11 22:29 root         INFO     Training accuracy  : 0.9192, f1: 0.9194\n",
      "07-11 22:29 root         INFO     Validation accuracy: 0.8683, f1: 0.8673\n",
      "07-11 22:30 root         INFO     Epoch 19. Global step 13300. T=19.24min\n",
      "07-11 22:30 root         INFO     In-batch loss      : 0.1210\n",
      "07-11 22:30 root         INFO     Training accuracy  : 0.9243, f1: 0.9241\n",
      "07-11 22:30 root         INFO     Validation accuracy: 0.8635, f1: 0.8616\n",
      "07-11 22:30 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 22:30 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.6591355803329944, 'input_dim': 300, 'lr': 0.00020169556095466108}\n",
      "07-11 22:30 root         INFO     Writer: runs/Jul11_22-30-07_lyalin_RNNBinaryClassifier_lr3_dropout0.6591355803329944_noise_level0.0000hyperparameters_search_random\n",
      "07-11 22:30 root         INFO     Epoch 0. Global step 665. T=0.76min\n",
      "07-11 22:30 root         INFO     In-batch loss      : 0.7320\n",
      "07-11 22:30 root         INFO     Training accuracy  : 0.5123, f1: 0.3068\n",
      "07-11 22:30 root         INFO     Validation accuracy: 0.5157, f1: 0.3116\n",
      "07-11 22:32 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 22:32 root         INFO     In-batch loss      : 0.8212\n",
      "07-11 22:32 root         INFO     Training accuracy  : 0.5215, f1: 0.3127\n",
      "07-11 22:32 root         INFO     Validation accuracy: 0.5331, f1: 0.3335\n",
      "07-11 22:33 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-11 22:33 root         INFO     In-batch loss      : 0.8212\n",
      "07-11 22:33 root         INFO     Training accuracy  : 0.5270, f1: 0.3179\n",
      "07-11 22:33 root         INFO     Validation accuracy: 0.5328, f1: 0.3343\n",
      "07-11 22:35 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-11 22:35 root         INFO     In-batch loss      : 0.6942\n",
      "07-11 22:35 root         INFO     Training accuracy  : 0.5334, f1: 0.3264\n",
      "07-11 22:35 root         INFO     Validation accuracy: 0.5419, f1: 0.3438\n",
      "07-11 22:37 root         INFO     Epoch 8. Global step 5985. T=6.94min\n",
      "07-11 22:37 root         INFO     In-batch loss      : 0.6880\n",
      "07-11 22:37 root         INFO     Training accuracy  : 0.6068, f1: 0.4638\n",
      "07-11 22:37 root         INFO     Validation accuracy: 0.6088, f1: 0.4671\n",
      "07-11 22:38 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-11 22:38 root         INFO     In-batch loss      : 0.5803\n",
      "07-11 22:38 root         INFO     Training accuracy  : 0.7296, f1: 0.7166\n",
      "07-11 22:38 root         INFO     Validation accuracy: 0.7240, f1: 0.7110\n",
      "07-11 22:40 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-11 22:40 root         INFO     In-batch loss      : 0.2093\n",
      "07-11 22:40 root         INFO     Training accuracy  : 0.7599, f1: 0.7478\n",
      "07-11 22:40 root         INFO     Validation accuracy: 0.7552, f1: 0.7399\n",
      "07-11 22:41 root         INFO     Epoch 14. Global step 9975. T=11.55min\n",
      "07-11 22:41 root         INFO     In-batch loss      : 1.2831\n",
      "07-11 22:41 root         INFO     Training accuracy  : 0.7826, f1: 0.7817\n",
      "07-11 22:41 root         INFO     Validation accuracy: 0.7757, f1: 0.7730\n",
      "07-11 22:43 root         INFO     Epoch 16. Global step 11305. T=13.09min\n",
      "07-11 22:43 root         INFO     In-batch loss      : 0.1902\n",
      "07-11 22:43 root         INFO     Training accuracy  : 0.7982, f1: 0.7915\n",
      "07-11 22:43 root         INFO     Validation accuracy: 0.7899, f1: 0.7816\n",
      "07-11 22:44 root         INFO     Epoch 18. Global step 12635. T=14.63min\n",
      "07-11 22:44 root         INFO     In-batch loss      : 0.8927\n",
      "07-11 22:44 root         INFO     Training accuracy  : 0.8094, f1: 0.8058\n",
      "07-11 22:44 root         INFO     Validation accuracy: 0.8093, f1: 0.8045\n",
      "07-11 22:45 root         INFO     Epoch 19. Global step 13300. T=15.40min\n",
      "07-11 22:45 root         INFO     In-batch loss      : 0.1191\n",
      "07-11 22:45 root         INFO     Training accuracy  : 0.8152, f1: 0.8127\n",
      "07-11 22:45 root         INFO     Validation accuracy: 0.8171, f1: 0.8129\n",
      "07-11 22:45 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 22:45 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.6666031503956319, 'input_dim': 300, 'lr': 0.0003466656937507074}\n",
      "07-11 22:45 root         INFO     Writer: runs/Jul11_22-45-35_lyalin_RNNBinaryClassifier_lr3_dropout0.6666031503956319_noise_level0.0000hyperparameters_search_random\n",
      "07-11 22:46 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-11 22:46 root         INFO     In-batch loss      : 0.5604\n",
      "07-11 22:46 root         INFO     Training accuracy  : 0.5356, f1: 0.3484\n",
      "07-11 22:46 root         INFO     Validation accuracy: 0.5403, f1: 0.3586\n",
      "07-11 22:47 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-11 22:47 root         INFO     In-batch loss      : 0.2996\n",
      "07-11 22:47 root         INFO     Training accuracy  : 0.7594, f1: 0.7586\n",
      "07-11 22:47 root         INFO     Validation accuracy: 0.7552, f1: 0.7534\n",
      "07-11 22:49 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-11 22:49 root         INFO     In-batch loss      : 0.1912\n",
      "07-11 22:49 root         INFO     Training accuracy  : 0.7917, f1: 0.7904\n",
      "07-11 22:49 root         INFO     Validation accuracy: 0.7963, f1: 0.7951\n",
      "07-11 22:51 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-11 22:51 root         INFO     In-batch loss      : 0.9918\n",
      "07-11 22:51 root         INFO     Training accuracy  : 0.8302, f1: 0.8356\n",
      "07-11 22:51 root         INFO     Validation accuracy: 0.8333, f1: 0.8375\n",
      "07-11 22:52 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-11 22:52 root         INFO     In-batch loss      : 0.0422\n",
      "07-11 22:52 root         INFO     Training accuracy  : 0.8529, f1: 0.8549\n",
      "07-11 22:52 root         INFO     Validation accuracy: 0.8533, f1: 0.8546\n",
      "07-11 22:54 root         INFO     Epoch 10. Global step 7315. T=8.52min\n",
      "07-11 22:54 root         INFO     In-batch loss      : 0.2276\n",
      "07-11 22:54 root         INFO     Training accuracy  : 0.8665, f1: 0.8680\n",
      "07-11 22:54 root         INFO     Validation accuracy: 0.8573, f1: 0.8584\n",
      "07-11 22:55 root         INFO     Epoch 12. Global step 8645. T=10.07min\n",
      "07-11 22:55 root         INFO     In-batch loss      : 0.0233\n",
      "07-11 22:55 root         INFO     Training accuracy  : 0.8761, f1: 0.8766\n",
      "07-11 22:55 root         INFO     Validation accuracy: 0.8656, f1: 0.8653\n",
      "07-11 22:57 root         INFO     Epoch 14. Global step 9975. T=11.62min\n",
      "07-11 22:57 root         INFO     In-batch loss      : 0.4713\n",
      "07-11 22:57 root         INFO     Training accuracy  : 0.8860, f1: 0.8851\n",
      "07-11 22:57 root         INFO     Validation accuracy: 0.8648, f1: 0.8634\n",
      "07-11 22:58 root         INFO     Epoch 16. Global step 11305. T=13.18min\n",
      "07-11 22:58 root         INFO     In-batch loss      : 0.3049\n",
      "07-11 22:58 root         INFO     Training accuracy  : 0.8958, f1: 0.8954\n",
      "07-11 22:58 root         INFO     Validation accuracy: 0.8683, f1: 0.8673\n",
      "07-11 23:00 root         INFO     Epoch 18. Global step 12635. T=14.74min\n",
      "07-11 23:00 root         INFO     In-batch loss      : 0.0170\n",
      "07-11 23:00 root         INFO     Training accuracy  : 0.9044, f1: 0.9053\n",
      "07-11 23:00 root         INFO     Validation accuracy: 0.8685, f1: 0.8686\n",
      "07-11 23:01 root         INFO     Epoch 19. Global step 13300. T=15.52min\n",
      "07-11 23:01 root         INFO     In-batch loss      : 0.2012\n",
      "07-11 23:01 root         INFO     Training accuracy  : 0.9093, f1: 0.9097\n",
      "07-11 23:01 root         INFO     Validation accuracy: 0.8712, f1: 0.8710\n",
      "07-11 23:01 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 23:01 root         INFO     YES!, f1: 0.8684280757939685, parameters: {'hidden_dim': 256, 'dropout': 0.6666031503956319, 'input_dim': 300, 'lr': 0.0003466656937507074}\n",
      "07-11 23:01 root         INFO     {'hidden_dim': 256, 'dropout': 0.6666031503956319, 'input_dim': 300, 'lr': 0.0003466656937507074}\n",
      "07-11 23:01 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.9170509859122935, 'input_dim': 300, 'lr': 0.0004572139201337275}\n",
      "07-11 23:01 root         INFO     Writer: runs/Jul11_23-01-10_lyalin_RNNBinaryClassifier_lr3_dropout0.9170509859122935_noise_level0.0000hyperparameters_search_random\n",
      "07-11 23:01 root         INFO     Epoch 0. Global step 665. T=0.80min\n",
      "07-11 23:01 root         INFO     In-batch loss      : 0.6313\n",
      "07-11 23:01 root         INFO     Training accuracy  : 0.5265, f1: 0.3818\n",
      "07-11 23:01 root         INFO     Validation accuracy: 0.5301, f1: 0.3912\n",
      "07-11 23:03 root         INFO     Epoch 2. Global step 1995. T=2.39min\n",
      "07-11 23:03 root         INFO     In-batch loss      : 0.6084\n",
      "07-11 23:03 root         INFO     Training accuracy  : 0.7351, f1: 0.7362\n",
      "07-11 23:03 root         INFO     Validation accuracy: 0.7299, f1: 0.7294\n",
      "07-11 23:05 root         INFO     Epoch 4. Global step 3325. T=3.97min\n",
      "07-11 23:05 root         INFO     In-batch loss      : 0.1884\n",
      "07-11 23:05 root         INFO     Training accuracy  : 0.7920, f1: 0.7934\n",
      "07-11 23:05 root         INFO     Validation accuracy: 0.7944, f1: 0.7941\n",
      "07-11 23:06 root         INFO     Epoch 6. Global step 4655. T=5.57min\n",
      "07-11 23:06 root         INFO     In-batch loss      : 0.1013\n",
      "07-11 23:06 root         INFO     Training accuracy  : 0.8429, f1: 0.8423\n",
      "07-11 23:06 root         INFO     Validation accuracy: 0.8403, f1: 0.8387\n",
      "07-11 23:08 root         INFO     Epoch 8. Global step 5985. T=7.23min\n",
      "07-11 23:08 root         INFO     In-batch loss      : 0.0265\n",
      "07-11 23:08 root         INFO     Training accuracy  : 0.8644, f1: 0.8642\n",
      "07-11 23:08 root         INFO     Validation accuracy: 0.8592, f1: 0.8584\n",
      "07-11 23:09 root         INFO     Epoch 10. Global step 7315. T=8.82min\n",
      "07-11 23:09 root         INFO     In-batch loss      : 0.0216\n",
      "07-11 23:09 root         INFO     Training accuracy  : 0.8780, f1: 0.8773\n",
      "07-11 23:09 root         INFO     Validation accuracy: 0.8643, f1: 0.8624\n",
      "07-11 23:11 root         INFO     Epoch 12. Global step 8645. T=10.43min\n",
      "07-11 23:11 root         INFO     In-batch loss      : 0.4435\n",
      "07-11 23:11 root         INFO     Training accuracy  : 0.8891, f1: 0.8884\n",
      "07-11 23:11 root         INFO     Validation accuracy: 0.8648, f1: 0.8632\n",
      "07-11 23:13 root         INFO     Epoch 14. Global step 9975. T=12.03min\n",
      "07-11 23:13 root         INFO     In-batch loss      : 0.0840\n",
      "07-11 23:13 root         INFO     Training accuracy  : 0.9061, f1: 0.9058\n",
      "07-11 23:13 root         INFO     Validation accuracy: 0.8656, f1: 0.8648\n",
      "07-11 23:14 root         INFO     Epoch 16. Global step 11305. T=13.65min\n",
      "07-11 23:14 root         INFO     In-batch loss      : 0.0347\n",
      "07-11 23:14 root         INFO     Training accuracy  : 0.9198, f1: 0.9195\n",
      "07-11 23:14 root         INFO     Validation accuracy: 0.8659, f1: 0.8648\n",
      "07-11 23:16 root         INFO     Epoch 18. Global step 12635. T=15.24min\n",
      "07-11 23:16 root         INFO     In-batch loss      : 0.0504\n",
      "07-11 23:16 root         INFO     Training accuracy  : 0.9329, f1: 0.9326\n",
      "07-11 23:16 root         INFO     Validation accuracy: 0.8667, f1: 0.8652\n",
      "07-11 23:17 root         INFO     Epoch 19. Global step 13300. T=16.04min\n",
      "07-11 23:17 root         INFO     In-batch loss      : 0.0814\n",
      "07-11 23:17 root         INFO     Training accuracy  : 0.9437, f1: 0.9437\n",
      "07-11 23:17 root         INFO     Validation accuracy: 0.8635, f1: 0.8628\n",
      "07-11 23:17 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 23:17 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.38703314388870047, 'input_dim': 300, 'lr': 0.00020196054687092091}\n",
      "07-11 23:17 root         INFO     Writer: runs/Jul11_23-17-17_lyalin_RNNBinaryClassifier_lr3_dropout0.38703314388870047_noise_level0.0000hyperparameters_search_random\n",
      "07-11 23:18 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-11 23:18 root         INFO     In-batch loss      : 0.6643\n",
      "07-11 23:18 root         INFO     Training accuracy  : 0.6865, f1: 0.6756\n",
      "07-11 23:18 root         INFO     Validation accuracy: 0.6840, f1: 0.6727\n",
      "07-11 23:20 root         INFO     Epoch 2. Global step 1995. T=2.88min\n",
      "07-11 23:20 root         INFO     In-batch loss      : 0.2600\n",
      "07-11 23:20 root         INFO     Training accuracy  : 0.7622, f1: 0.7580\n",
      "07-11 23:20 root         INFO     Validation accuracy: 0.7603, f1: 0.7556\n",
      "07-11 23:22 root         INFO     Epoch 4. Global step 3325. T=4.82min\n",
      "07-11 23:22 root         INFO     In-batch loss      : 0.2393\n",
      "07-11 23:22 root         INFO     Training accuracy  : 0.7855, f1: 0.7705\n",
      "07-11 23:22 root         INFO     Validation accuracy: 0.7872, f1: 0.7712\n",
      "07-11 23:24 root         INFO     Epoch 6. Global step 4655. T=6.76min\n",
      "07-11 23:24 root         INFO     In-batch loss      : 0.7590\n",
      "07-11 23:24 root         INFO     Training accuracy  : 0.8344, f1: 0.8336\n",
      "07-11 23:24 root         INFO     Validation accuracy: 0.8344, f1: 0.8328\n",
      "07-11 23:25 root         INFO     Epoch 8. Global step 5985. T=8.69min\n",
      "07-11 23:25 root         INFO     In-batch loss      : 1.2112\n",
      "07-11 23:25 root         INFO     Training accuracy  : 0.8607, f1: 0.8600\n",
      "07-11 23:25 root         INFO     Validation accuracy: 0.8589, f1: 0.8566\n",
      "07-11 23:27 root         INFO     Epoch 10. Global step 7315. T=10.68min\n",
      "07-11 23:27 root         INFO     In-batch loss      : 1.2354\n",
      "07-11 23:27 root         INFO     Training accuracy  : 0.8782, f1: 0.8779\n",
      "07-11 23:27 root         INFO     Validation accuracy: 0.8629, f1: 0.8623\n",
      "07-11 23:29 root         INFO     Epoch 12. Global step 8645. T=12.62min\n",
      "07-11 23:29 root         INFO     In-batch loss      : 0.0155\n",
      "07-11 23:29 root         INFO     Training accuracy  : 0.8928, f1: 0.8929\n",
      "07-11 23:29 root         INFO     Validation accuracy: 0.8651, f1: 0.8642\n",
      "07-11 23:31 root         INFO     Epoch 14. Global step 9975. T=14.56min\n",
      "07-11 23:31 root         INFO     In-batch loss      : 0.0784\n",
      "07-11 23:31 root         INFO     Training accuracy  : 0.9034, f1: 0.9028\n",
      "07-11 23:31 root         INFO     Validation accuracy: 0.8643, f1: 0.8625\n",
      "07-11 23:33 root         INFO     Epoch 16. Global step 11305. T=16.50min\n",
      "07-11 23:33 root         INFO     In-batch loss      : 0.1283\n",
      "07-11 23:33 root         INFO     Training accuracy  : 0.9144, f1: 0.9143\n",
      "07-11 23:33 root         INFO     Validation accuracy: 0.8616, f1: 0.8600\n",
      "07-11 23:35 root         INFO     Epoch 18. Global step 12635. T=18.44min\n",
      "07-11 23:35 root         INFO     In-batch loss      : 0.0089\n",
      "07-11 23:35 root         INFO     Training accuracy  : 0.9266, f1: 0.9263\n",
      "07-11 23:35 root         INFO     Validation accuracy: 0.8629, f1: 0.8615\n",
      "07-11 23:36 root         INFO     Epoch 19. Global step 13300. T=19.41min\n",
      "07-11 23:36 root         INFO     In-batch loss      : 0.0356\n",
      "07-11 23:36 root         INFO     Training accuracy  : 0.9298, f1: 0.9295\n",
      "07-11 23:36 root         INFO     Validation accuracy: 0.8627, f1: 0.8615\n",
      "07-11 23:36 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 23:36 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.11180991300547016, 'input_dim': 300, 'lr': 0.0002704999911128115}\n",
      "07-11 23:36 root         INFO     Writer: runs/Jul11_23-36-46_lyalin_RNNBinaryClassifier_lr3_dropout0.11180991300547016_noise_level0.0000hyperparameters_search_random\n",
      "07-11 23:37 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 23:37 root         INFO     In-batch loss      : 0.6837\n",
      "07-11 23:37 root         INFO     Training accuracy  : 0.5182, f1: 0.3214\n",
      "07-11 23:37 root         INFO     Validation accuracy: 0.5200, f1: 0.3309\n",
      "07-11 23:39 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-11 23:39 root         INFO     In-batch loss      : 0.6888\n",
      "07-11 23:39 root         INFO     Training accuracy  : 0.5337, f1: 0.3291\n",
      "07-11 23:39 root         INFO     Validation accuracy: 0.5373, f1: 0.3396\n",
      "07-11 23:40 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-11 23:40 root         INFO     In-batch loss      : 0.7278\n",
      "07-11 23:40 root         INFO     Training accuracy  : 0.6154, f1: 0.6891\n",
      "07-11 23:40 root         INFO     Validation accuracy: 0.6115, f1: 0.6839\n",
      "07-11 23:42 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-11 23:42 root         INFO     In-batch loss      : 0.8486\n",
      "07-11 23:42 root         INFO     Training accuracy  : 0.7486, f1: 0.7389\n",
      "07-11 23:42 root         INFO     Validation accuracy: 0.7445, f1: 0.7314\n",
      "07-11 23:43 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-11 23:43 root         INFO     In-batch loss      : 1.5065\n",
      "07-11 23:43 root         INFO     Training accuracy  : 0.7803, f1: 0.7779\n",
      "07-11 23:43 root         INFO     Validation accuracy: 0.7784, f1: 0.7740\n",
      "07-11 23:45 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-11 23:45 root         INFO     In-batch loss      : 0.8884\n",
      "07-11 23:45 root         INFO     Training accuracy  : 0.7959, f1: 0.7904\n",
      "07-11 23:45 root         INFO     Validation accuracy: 0.7933, f1: 0.7867\n",
      "07-11 23:46 root         INFO     Epoch 12. Global step 8645. T=10.03min\n",
      "07-11 23:46 root         INFO     In-batch loss      : 1.0086\n",
      "07-11 23:46 root         INFO     Training accuracy  : 0.8109, f1: 0.8116\n",
      "07-11 23:46 root         INFO     Validation accuracy: 0.8099, f1: 0.8084\n",
      "07-11 23:48 root         INFO     Epoch 14. Global step 9975. T=11.57min\n",
      "07-11 23:48 root         INFO     In-batch loss      : 0.1916\n",
      "07-11 23:48 root         INFO     Training accuracy  : 0.8247, f1: 0.8248\n",
      "07-11 23:48 root         INFO     Validation accuracy: 0.8248, f1: 0.8231\n",
      "07-11 23:49 root         INFO     Epoch 16. Global step 11305. T=13.11min\n",
      "07-11 23:49 root         INFO     In-batch loss      : 0.0894\n",
      "07-11 23:49 root         INFO     Training accuracy  : 0.8349, f1: 0.8354\n",
      "07-11 23:49 root         INFO     Validation accuracy: 0.8397, f1: 0.8389\n",
      "07-11 23:51 root         INFO     Epoch 18. Global step 12635. T=14.65min\n",
      "07-11 23:51 root         INFO     In-batch loss      : 0.0780\n",
      "07-11 23:51 root         INFO     Training accuracy  : 0.8440, f1: 0.8445\n",
      "07-11 23:51 root         INFO     Validation accuracy: 0.8467, f1: 0.8468\n",
      "07-11 23:52 root         INFO     Epoch 19. Global step 13300. T=15.42min\n",
      "07-11 23:52 root         INFO     In-batch loss      : 0.0482\n",
      "07-11 23:52 root         INFO     Training accuracy  : 0.8474, f1: 0.8477\n",
      "07-11 23:52 root         INFO     Validation accuracy: 0.8477, f1: 0.8477\n",
      "07-11 23:52 root         WARNING  Model is evaluating in training mode!\n",
      "07-11 23:52 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.4798617743236715, 'input_dim': 300, 'lr': 0.0002069118593783483}\n",
      "07-11 23:52 root         INFO     Writer: runs/Jul11_23-52-16_lyalin_RNNBinaryClassifier_lr3_dropout0.4798617743236715_noise_level0.0000hyperparameters_search_random\n",
      "07-11 23:53 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-11 23:53 root         INFO     In-batch loss      : 0.7095\n",
      "07-11 23:53 root         INFO     Training accuracy  : 0.5316, f1: 0.3310\n",
      "07-11 23:53 root         INFO     Validation accuracy: 0.5405, f1: 0.3416\n",
      "07-11 23:54 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-11 23:54 root         INFO     In-batch loss      : 0.3415\n",
      "07-11 23:54 root         INFO     Training accuracy  : 0.6957, f1: 0.6529\n",
      "07-11 23:54 root         INFO     Validation accuracy: 0.6971, f1: 0.6549\n",
      "07-11 23:56 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-11 23:56 root         INFO     In-batch loss      : 0.2279\n",
      "07-11 23:56 root         INFO     Training accuracy  : 0.7615, f1: 0.7516\n",
      "07-11 23:56 root         INFO     Validation accuracy: 0.7597, f1: 0.7488\n",
      "07-11 23:57 root         INFO     Epoch 6. Global step 4655. T=5.44min\n",
      "07-11 23:57 root         INFO     In-batch loss      : 0.7412\n",
      "07-11 23:57 root         INFO     Training accuracy  : 0.7916, f1: 0.7905\n",
      "07-11 23:57 root         INFO     Validation accuracy: 0.7952, f1: 0.7935\n",
      "07-11 23:59 root         INFO     Epoch 8. Global step 5985. T=6.99min\n",
      "07-11 23:59 root         INFO     In-batch loss      : 0.3302\n",
      "07-11 23:59 root         INFO     Training accuracy  : 0.8146, f1: 0.8131\n",
      "07-11 23:59 root         INFO     Validation accuracy: 0.8171, f1: 0.8146\n",
      "07-12 00:00 root         INFO     Epoch 10. Global step 7315. T=8.56min\n",
      "07-12 00:00 root         INFO     In-batch loss      : 0.0681\n",
      "07-12 00:00 root         INFO     Training accuracy  : 0.8340, f1: 0.8314\n",
      "07-12 00:00 root         INFO     Validation accuracy: 0.8408, f1: 0.8384\n",
      "07-12 00:02 root         INFO     Epoch 12. Global step 8645. T=10.12min\n",
      "07-12 00:02 root         INFO     In-batch loss      : 0.5018\n",
      "07-12 00:02 root         INFO     Training accuracy  : 0.8492, f1: 0.8479\n",
      "07-12 00:02 root         INFO     Validation accuracy: 0.8461, f1: 0.8450\n",
      "07-12 00:03 root         INFO     Epoch 14. Global step 9975. T=11.70min\n",
      "07-12 00:03 root         INFO     In-batch loss      : 0.1514\n",
      "07-12 00:03 root         INFO     Training accuracy  : 0.8568, f1: 0.8550\n",
      "07-12 00:03 root         INFO     Validation accuracy: 0.8536, f1: 0.8520\n",
      "07-12 00:05 root         INFO     Epoch 16. Global step 11305. T=13.25min\n",
      "07-12 00:05 root         INFO     In-batch loss      : 0.1203\n",
      "07-12 00:05 root         INFO     Training accuracy  : 0.8638, f1: 0.8606\n",
      "07-12 00:05 root         INFO     Validation accuracy: 0.8552, f1: 0.8514\n",
      "07-12 00:07 root         INFO     Epoch 18. Global step 12635. T=14.81min\n",
      "07-12 00:07 root         INFO     In-batch loss      : 1.2362\n",
      "07-12 00:07 root         INFO     Training accuracy  : 0.8740, f1: 0.8734\n",
      "07-12 00:07 root         INFO     Validation accuracy: 0.8621, f1: 0.8605\n",
      "07-12 00:07 root         INFO     Epoch 19. Global step 13300. T=15.59min\n",
      "07-12 00:07 root         INFO     In-batch loss      : 0.0778\n",
      "07-12 00:07 root         INFO     Training accuracy  : 0.8768, f1: 0.8762\n",
      "07-12 00:07 root         INFO     Validation accuracy: 0.8645, f1: 0.8631\n",
      "07-12 00:07 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 00:07 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.8306296924952753, 'input_dim': 300, 'lr': 0.0005653845974601245}\n",
      "07-12 00:07 root         INFO     Writer: runs/Jul12_00-07-55_lyalin_RNNBinaryClassifier_lr3_dropout0.8306296924952753_noise_level0.0000hyperparameters_search_random\n",
      "07-12 00:08 root         INFO     Epoch 0. Global step 665. T=0.81min\n",
      "07-12 00:08 root         INFO     In-batch loss      : 0.6940\n",
      "07-12 00:08 root         INFO     Training accuracy  : 0.5343, f1: 0.3860\n",
      "07-12 00:08 root         INFO     Validation accuracy: 0.5395, f1: 0.3968\n",
      "07-12 00:10 root         INFO     Epoch 2. Global step 1995. T=2.48min\n",
      "07-12 00:10 root         INFO     In-batch loss      : 0.2568\n",
      "07-12 00:10 root         INFO     Training accuracy  : 0.6717, f1: 0.6306\n",
      "07-12 00:10 root         INFO     Validation accuracy: 0.6707, f1: 0.6299\n",
      "07-12 00:12 root         INFO     Epoch 4. Global step 3325. T=4.09min\n",
      "07-12 00:12 root         INFO     In-batch loss      : 0.8421\n",
      "07-12 00:12 root         INFO     Training accuracy  : 0.7597, f1: 0.7337\n",
      "07-12 00:12 root         INFO     Validation accuracy: 0.7653, f1: 0.7413\n",
      "07-12 00:13 root         INFO     Epoch 6. Global step 4655. T=5.71min\n",
      "07-12 00:13 root         INFO     In-batch loss      : 0.1942\n",
      "07-12 00:13 root         INFO     Training accuracy  : 0.8527, f1: 0.8535\n",
      "07-12 00:13 root         INFO     Validation accuracy: 0.8531, f1: 0.8530\n",
      "07-12 00:15 root         INFO     Epoch 8. Global step 5985. T=7.31min\n",
      "07-12 00:15 root         INFO     In-batch loss      : 0.4087\n",
      "07-12 00:15 root         INFO     Training accuracy  : 0.8743, f1: 0.8737\n",
      "07-12 00:15 root         INFO     Validation accuracy: 0.8643, f1: 0.8631\n",
      "07-12 00:16 root         INFO     Epoch 10. Global step 7315. T=8.92min\n",
      "07-12 00:16 root         INFO     In-batch loss      : 0.0557\n",
      "07-12 00:16 root         INFO     Training accuracy  : 0.8927, f1: 0.8931\n",
      "07-12 00:16 root         INFO     Validation accuracy: 0.8704, f1: 0.8702\n",
      "07-12 00:18 root         INFO     Epoch 12. Global step 8645. T=10.52min\n",
      "07-12 00:18 root         INFO     In-batch loss      : 0.0444\n",
      "07-12 00:18 root         INFO     Training accuracy  : 0.9119, f1: 0.9120\n",
      "07-12 00:18 root         INFO     Validation accuracy: 0.8728, f1: 0.8726\n",
      "07-12 00:20 root         INFO     Epoch 14. Global step 9975. T=12.16min\n",
      "07-12 00:20 root         INFO     In-batch loss      : 0.0291\n",
      "07-12 00:20 root         INFO     Training accuracy  : 0.9285, f1: 0.9281\n",
      "07-12 00:20 root         INFO     Validation accuracy: 0.8725, f1: 0.8708\n",
      "07-12 00:21 root         INFO     Epoch 16. Global step 11305. T=13.78min\n",
      "07-12 00:21 root         INFO     In-batch loss      : 0.0026\n",
      "07-12 00:21 root         INFO     Training accuracy  : 0.9488, f1: 0.9489\n",
      "07-12 00:21 root         INFO     Validation accuracy: 0.8720, f1: 0.8720\n",
      "07-12 00:23 root         INFO     Epoch 18. Global step 12635. T=15.37min\n",
      "07-12 00:23 root         INFO     In-batch loss      : 0.0109\n",
      "07-12 00:23 root         INFO     Training accuracy  : 0.9677, f1: 0.9677\n",
      "07-12 00:23 root         INFO     Validation accuracy: 0.8624, f1: 0.8628\n",
      "07-12 00:24 root         INFO     Epoch 19. Global step 13300. T=16.17min\n",
      "07-12 00:24 root         INFO     In-batch loss      : 0.0062\n",
      "07-12 00:24 root         INFO     Training accuracy  : 0.9736, f1: 0.9737\n",
      "07-12 00:24 root         INFO     Validation accuracy: 0.8576, f1: 0.8583\n",
      "07-12 00:24 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 00:24 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.6767851397074414, 'input_dim': 300, 'lr': 0.0006070657328679954}\n",
      "07-12 00:24 root         INFO     Writer: runs/Jul12_00-24-10_lyalin_RNNBinaryClassifier_lr3_dropout0.6767851397074414_noise_level0.0000hyperparameters_search_random\n",
      "07-12 00:24 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 00:24 root         INFO     In-batch loss      : 0.6825\n",
      "07-12 00:24 root         INFO     Training accuracy  : 0.5280, f1: 0.3383\n",
      "07-12 00:24 root         INFO     Validation accuracy: 0.5291, f1: 0.3474\n",
      "07-12 00:26 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 00:26 root         INFO     In-batch loss      : 0.6976\n",
      "07-12 00:26 root         INFO     Training accuracy  : 0.7164, f1: 0.6830\n",
      "07-12 00:26 root         INFO     Validation accuracy: 0.7171, f1: 0.6839\n",
      "07-12 00:28 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 00:28 root         INFO     In-batch loss      : 0.7376\n",
      "07-12 00:28 root         INFO     Training accuracy  : 0.7897, f1: 0.7772\n",
      "07-12 00:28 root         INFO     Validation accuracy: 0.7928, f1: 0.7799\n",
      "07-12 00:29 root         INFO     Epoch 6. Global step 4655. T=5.41min\n",
      "07-12 00:29 root         INFO     In-batch loss      : 0.1580\n",
      "07-12 00:29 root         INFO     Training accuracy  : 0.8309, f1: 0.8309\n",
      "07-12 00:29 root         INFO     Validation accuracy: 0.8376, f1: 0.8368\n",
      "07-12 00:31 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 00:31 root         INFO     In-batch loss      : 1.5848\n",
      "07-12 00:31 root         INFO     Training accuracy  : 0.8520, f1: 0.8519\n",
      "07-12 00:31 root         INFO     Validation accuracy: 0.8565, f1: 0.8565\n",
      "07-12 00:32 root         INFO     Epoch 10. Global step 7315. T=8.53min\n",
      "07-12 00:32 root         INFO     In-batch loss      : 0.1191\n",
      "07-12 00:32 root         INFO     Training accuracy  : 0.8657, f1: 0.8668\n",
      "07-12 00:32 root         INFO     Validation accuracy: 0.8603, f1: 0.8613\n",
      "07-12 00:34 root         INFO     Epoch 12. Global step 8645. T=10.07min\n",
      "07-12 00:34 root         INFO     In-batch loss      : 0.2775\n",
      "07-12 00:34 root         INFO     Training accuracy  : 0.8771, f1: 0.8766\n",
      "07-12 00:34 root         INFO     Validation accuracy: 0.8688, f1: 0.8684\n",
      "07-12 00:35 root         INFO     Epoch 14. Global step 9975. T=11.62min\n",
      "07-12 00:35 root         INFO     In-batch loss      : 1.6418\n",
      "07-12 00:35 root         INFO     Training accuracy  : 0.8857, f1: 0.8865\n",
      "07-12 00:35 root         INFO     Validation accuracy: 0.8683, f1: 0.8690\n",
      "07-12 00:37 root         INFO     Epoch 16. Global step 11305. T=13.18min\n",
      "07-12 00:37 root         INFO     In-batch loss      : 0.0725\n",
      "07-12 00:37 root         INFO     Training accuracy  : 0.8942, f1: 0.8936\n",
      "07-12 00:37 root         INFO     Validation accuracy: 0.8709, f1: 0.8705\n",
      "07-12 00:38 root         INFO     Epoch 18. Global step 12635. T=14.74min\n",
      "07-12 00:38 root         INFO     In-batch loss      : 1.0669\n",
      "07-12 00:38 root         INFO     Training accuracy  : 0.9025, f1: 0.9024\n",
      "07-12 00:38 root         INFO     Validation accuracy: 0.8707, f1: 0.8706\n",
      "07-12 00:39 root         INFO     Epoch 19. Global step 13300. T=15.52min\n",
      "07-12 00:39 root         INFO     In-batch loss      : 0.0201\n",
      "07-12 00:39 root         INFO     Training accuracy  : 0.9048, f1: 0.9059\n",
      "07-12 00:39 root         INFO     Validation accuracy: 0.8683, f1: 0.8697\n",
      "07-12 00:39 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 00:39 root         INFO     YES!, f1: 0.8704389212057112, parameters: {'hidden_dim': 64, 'dropout': 0.6767851397074414, 'input_dim': 300, 'lr': 0.0006070657328679954}\n",
      "07-12 00:39 root         INFO     {'hidden_dim': 64, 'dropout': 0.6767851397074414, 'input_dim': 300, 'lr': 0.0006070657328679954}\n",
      "07-12 00:39 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.6121658760310663, 'input_dim': 300, 'lr': 0.0009199815895084046}\n",
      "07-12 00:39 root         INFO     Writer: runs/Jul12_00-39-45_lyalin_RNNBinaryClassifier_lr3_dropout0.6121658760310663_noise_level0.0000hyperparameters_search_random\n",
      "07-12 00:40 root         INFO     Epoch 0. Global step 665. T=0.81min\n",
      "07-12 00:40 root         INFO     In-batch loss      : 0.6922\n",
      "07-12 00:40 root         INFO     Training accuracy  : 0.5432, f1: 0.3212\n",
      "07-12 00:40 root         INFO     Validation accuracy: 0.5453, f1: 0.3215\n",
      "07-12 00:42 root         INFO     Epoch 2. Global step 1995. T=2.41min\n",
      "07-12 00:42 root         INFO     In-batch loss      : 0.8931\n",
      "07-12 00:42 root         INFO     Training accuracy  : 0.8197, f1: 0.8259\n",
      "07-12 00:42 root         INFO     Validation accuracy: 0.8227, f1: 0.8277\n",
      "07-12 00:43 root         INFO     Epoch 4. Global step 3325. T=4.02min\n",
      "07-12 00:43 root         INFO     In-batch loss      : 0.0533\n",
      "07-12 00:43 root         INFO     Training accuracy  : 0.8729, f1: 0.8699\n",
      "07-12 00:43 root         INFO     Validation accuracy: 0.8597, f1: 0.8554\n",
      "07-12 00:45 root         INFO     Epoch 6. Global step 4655. T=5.64min\n",
      "07-12 00:45 root         INFO     In-batch loss      : 1.1107\n",
      "07-12 00:45 root         INFO     Training accuracy  : 0.9035, f1: 0.9036\n",
      "07-12 00:45 root         INFO     Validation accuracy: 0.8683, f1: 0.8676\n",
      "07-12 00:47 root         INFO     Epoch 8. Global step 5985. T=7.28min\n",
      "07-12 00:47 root         INFO     In-batch loss      : 1.6066\n",
      "07-12 00:47 root         INFO     Training accuracy  : 0.9330, f1: 0.9325\n",
      "07-12 00:47 root         INFO     Validation accuracy: 0.8736, f1: 0.8721\n",
      "07-12 00:48 root         INFO     Epoch 10. Global step 7315. T=8.90min\n",
      "07-12 00:48 root         INFO     In-batch loss      : 0.0058\n",
      "07-12 00:48 root         INFO     Training accuracy  : 0.9646, f1: 0.9645\n",
      "07-12 00:48 root         INFO     Validation accuracy: 0.8693, f1: 0.8688\n",
      "07-12 00:50 root         INFO     Epoch 12. Global step 8645. T=10.53min\n",
      "07-12 00:50 root         INFO     In-batch loss      : 0.0235\n",
      "07-12 00:50 root         INFO     Training accuracy  : 0.9825, f1: 0.9826\n",
      "07-12 00:50 root         INFO     Validation accuracy: 0.8648, f1: 0.8649\n",
      "07-12 00:51 root         INFO     Epoch 14. Global step 9975. T=12.14min\n",
      "07-12 00:51 root         INFO     In-batch loss      : 0.0040\n",
      "07-12 00:51 root         INFO     Training accuracy  : 0.9921, f1: 0.9921\n",
      "07-12 00:51 root         INFO     Validation accuracy: 0.8709, f1: 0.8706\n",
      "07-12 00:53 root         INFO     Epoch 16. Global step 11305. T=13.78min\n",
      "07-12 00:53 root         INFO     In-batch loss      : 0.0003\n",
      "07-12 00:53 root         INFO     Training accuracy  : 0.9953, f1: 0.9953\n",
      "07-12 00:53 root         INFO     Validation accuracy: 0.8667, f1: 0.8663\n",
      "07-12 00:55 root         INFO     Epoch 18. Global step 12635. T=15.38min\n",
      "07-12 00:55 root         INFO     In-batch loss      : 0.0000\n",
      "07-12 00:55 root         INFO     Training accuracy  : 0.9972, f1: 0.9972\n",
      "07-12 00:55 root         INFO     Validation accuracy: 0.8683, f1: 0.8681\n",
      "07-12 00:55 root         INFO     Epoch 19. Global step 13300. T=16.18min\n",
      "07-12 00:55 root         INFO     In-batch loss      : 0.0008\n",
      "07-12 00:55 root         INFO     Training accuracy  : 0.9978, f1: 0.9978\n",
      "07-12 00:55 root         INFO     Validation accuracy: 0.8683, f1: 0.8681\n",
      "07-12 00:55 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 00:56 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.7242062103734229, 'input_dim': 300, 'lr': 0.00015950312983127168}\n",
      "07-12 00:56 root         INFO     Writer: runs/Jul12_00-56-00_lyalin_RNNBinaryClassifier_lr3_dropout0.7242062103734229_noise_level0.0000hyperparameters_search_random\n",
      "07-12 00:56 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-12 00:56 root         INFO     In-batch loss      : 0.6765\n",
      "07-12 00:56 root         INFO     Training accuracy  : 0.5261, f1: 0.2738\n",
      "07-12 00:56 root         INFO     Validation accuracy: 0.5352, f1: 0.2854\n",
      "07-12 00:58 root         INFO     Epoch 2. Global step 1995. T=2.34min\n",
      "07-12 00:58 root         INFO     In-batch loss      : 0.9281\n",
      "07-12 00:58 root         INFO     Training accuracy  : 0.7595, f1: 0.7587\n",
      "07-12 00:58 root         INFO     Validation accuracy: 0.7579, f1: 0.7575\n",
      "07-12 00:59 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-12 00:59 root         INFO     In-batch loss      : 0.6968\n",
      "07-12 00:59 root         INFO     Training accuracy  : 0.7980, f1: 0.7970\n",
      "07-12 00:59 root         INFO     Validation accuracy: 0.7992, f1: 0.7967\n",
      "07-12 01:01 root         INFO     Epoch 6. Global step 4655. T=5.43min\n",
      "07-12 01:01 root         INFO     In-batch loss      : 0.1404\n",
      "07-12 01:01 root         INFO     Training accuracy  : 0.8118, f1: 0.8113\n",
      "07-12 01:01 root         INFO     Validation accuracy: 0.8163, f1: 0.8136\n",
      "07-12 01:02 root         INFO     Epoch 8. Global step 5985. T=6.98min\n",
      "07-12 01:02 root         INFO     In-batch loss      : 0.1736\n",
      "07-12 01:02 root         INFO     Training accuracy  : 0.8200, f1: 0.8176\n",
      "07-12 01:02 root         INFO     Validation accuracy: 0.8264, f1: 0.8238\n",
      "07-12 01:04 root         INFO     Epoch 10. Global step 7315. T=8.55min\n",
      "07-12 01:04 root         INFO     In-batch loss      : 0.0676\n",
      "07-12 01:04 root         INFO     Training accuracy  : 0.8306, f1: 0.8289\n",
      "07-12 01:04 root         INFO     Validation accuracy: 0.8373, f1: 0.8353\n",
      "07-12 01:06 root         INFO     Epoch 12. Global step 8645. T=10.12min\n",
      "07-12 01:06 root         INFO     In-batch loss      : 0.0405\n",
      "07-12 01:06 root         INFO     Training accuracy  : 0.8418, f1: 0.8410\n",
      "07-12 01:06 root         INFO     Validation accuracy: 0.8475, f1: 0.8461\n",
      "07-12 01:07 root         INFO     Epoch 14. Global step 9975. T=11.68min\n",
      "07-12 01:07 root         INFO     In-batch loss      : 0.7596\n",
      "07-12 01:07 root         INFO     Training accuracy  : 0.8509, f1: 0.8517\n",
      "07-12 01:07 root         INFO     Validation accuracy: 0.8523, f1: 0.8524\n",
      "07-12 01:09 root         INFO     Epoch 16. Global step 11305. T=13.25min\n",
      "07-12 01:09 root         INFO     In-batch loss      : 0.1441\n",
      "07-12 01:09 root         INFO     Training accuracy  : 0.8568, f1: 0.8598\n",
      "07-12 01:09 root         INFO     Validation accuracy: 0.8581, f1: 0.8608\n",
      "07-12 01:10 root         INFO     Epoch 18. Global step 12635. T=14.81min\n",
      "07-12 01:10 root         INFO     In-batch loss      : 0.1618\n",
      "07-12 01:10 root         INFO     Training accuracy  : 0.8635, f1: 0.8640\n",
      "07-12 01:10 root         INFO     Validation accuracy: 0.8605, f1: 0.8607\n",
      "07-12 01:11 root         INFO     Epoch 19. Global step 13300. T=15.59min\n",
      "07-12 01:11 root         INFO     In-batch loss      : 0.0734\n",
      "07-12 01:11 root         INFO     Training accuracy  : 0.8680, f1: 0.8670\n",
      "07-12 01:11 root         INFO     Validation accuracy: 0.8613, f1: 0.8603\n",
      "07-12 01:11 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 01:11 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.7208938097515094, 'input_dim': 300, 'lr': 0.0008408907307089076}\n",
      "07-12 01:11 root         INFO     Writer: runs/Jul12_01-11-39_lyalin_RNNBinaryClassifier_lr3_dropout0.7208938097515094_noise_level0.0000hyperparameters_search_random\n",
      "07-12 01:12 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-12 01:12 root         INFO     In-batch loss      : 0.5751\n",
      "07-12 01:12 root         INFO     Training accuracy  : 0.5324, f1: 0.6495\n",
      "07-12 01:12 root         INFO     Validation accuracy: 0.5371, f1: 0.6496\n",
      "07-12 01:14 root         INFO     Epoch 2. Global step 1995. T=2.34min\n",
      "07-12 01:14 root         INFO     In-batch loss      : 0.2633\n",
      "07-12 01:14 root         INFO     Training accuracy  : 0.7859, f1: 0.7910\n",
      "07-12 01:14 root         INFO     Validation accuracy: 0.7872, f1: 0.7914\n",
      "07-12 01:15 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-12 01:15 root         INFO     In-batch loss      : 1.9024\n",
      "07-12 01:15 root         INFO     Training accuracy  : 0.8505, f1: 0.8506\n",
      "07-12 01:15 root         INFO     Validation accuracy: 0.8491, f1: 0.8469\n",
      "07-12 01:17 root         INFO     Epoch 6. Global step 4655. T=5.45min\n",
      "07-12 01:17 root         INFO     In-batch loss      : 0.0166\n",
      "07-12 01:17 root         INFO     Training accuracy  : 0.8777, f1: 0.8777\n",
      "07-12 01:17 root         INFO     Validation accuracy: 0.8611, f1: 0.8602\n",
      "07-12 01:18 root         INFO     Epoch 8. Global step 5985. T=7.01min\n",
      "07-12 01:18 root         INFO     In-batch loss      : 0.2197\n",
      "07-12 01:18 root         INFO     Training accuracy  : 0.8959, f1: 0.8967\n",
      "07-12 01:18 root         INFO     Validation accuracy: 0.8720, f1: 0.8723\n",
      "07-12 01:20 root         INFO     Epoch 10. Global step 7315. T=8.55min\n",
      "07-12 01:20 root         INFO     In-batch loss      : 0.1962\n",
      "07-12 01:20 root         INFO     Training accuracy  : 0.9154, f1: 0.9158\n",
      "07-12 01:20 root         INFO     Validation accuracy: 0.8704, f1: 0.8706\n",
      "07-12 01:21 root         INFO     Epoch 12. Global step 8645. T=10.09min\n",
      "07-12 01:21 root         INFO     In-batch loss      : 0.0473\n",
      "07-12 01:21 root         INFO     Training accuracy  : 0.9353, f1: 0.9353\n",
      "07-12 01:21 root         INFO     Validation accuracy: 0.8728, f1: 0.8723\n",
      "07-12 01:23 root         INFO     Epoch 14. Global step 9975. T=11.64min\n",
      "07-12 01:23 root         INFO     In-batch loss      : 0.0945\n",
      "07-12 01:23 root         INFO     Training accuracy  : 0.9520, f1: 0.9517\n",
      "07-12 01:23 root         INFO     Validation accuracy: 0.8725, f1: 0.8709\n",
      "07-12 01:24 root         INFO     Epoch 16. Global step 11305. T=13.19min\n",
      "07-12 01:24 root         INFO     In-batch loss      : 0.0007\n",
      "07-12 01:24 root         INFO     Training accuracy  : 0.9719, f1: 0.9719\n",
      "07-12 01:24 root         INFO     Validation accuracy: 0.8672, f1: 0.8661\n",
      "07-12 01:26 root         INFO     Epoch 18. Global step 12635. T=14.73min\n",
      "07-12 01:26 root         INFO     In-batch loss      : 0.0012\n",
      "07-12 01:26 root         INFO     Training accuracy  : 0.9826, f1: 0.9826\n",
      "07-12 01:26 root         INFO     Validation accuracy: 0.8629, f1: 0.8620\n",
      "07-12 01:27 root         INFO     Epoch 19. Global step 13300. T=15.49min\n",
      "07-12 01:27 root         INFO     In-batch loss      : 0.0001\n",
      "07-12 01:27 root         INFO     Training accuracy  : 0.9867, f1: 0.9867\n",
      "07-12 01:27 root         INFO     Validation accuracy: 0.8608, f1: 0.8602\n",
      "07-12 01:27 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 01:27 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.9237501810215509, 'input_dim': 300, 'lr': 0.00036962481681380874}\n",
      "07-12 01:27 root         INFO     Writer: runs/Jul12_01-27-13_lyalin_RNNBinaryClassifier_lr3_dropout0.9237501810215509_noise_level0.0000hyperparameters_search_random\n",
      "07-12 01:28 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 01:28 root         INFO     In-batch loss      : 0.6666\n",
      "07-12 01:28 root         INFO     Training accuracy  : 0.5288, f1: 0.2937\n",
      "07-12 01:28 root         INFO     Validation accuracy: 0.5328, f1: 0.2970\n",
      "07-12 01:29 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 01:29 root         INFO     In-batch loss      : 0.4131\n",
      "07-12 01:29 root         INFO     Training accuracy  : 0.6915, f1: 0.6590\n",
      "07-12 01:29 root         INFO     Validation accuracy: 0.6947, f1: 0.6649\n",
      "07-12 01:31 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 01:31 root         INFO     In-batch loss      : 0.3418\n",
      "07-12 01:31 root         INFO     Training accuracy  : 0.7496, f1: 0.7329\n",
      "07-12 01:31 root         INFO     Validation accuracy: 0.7509, f1: 0.7357\n",
      "07-12 01:32 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 01:32 root         INFO     In-batch loss      : 0.7447\n",
      "07-12 01:32 root         INFO     Training accuracy  : 0.7740, f1: 0.7558\n",
      "07-12 01:32 root         INFO     Validation accuracy: 0.7765, f1: 0.7582\n",
      "07-12 01:34 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-12 01:34 root         INFO     In-batch loss      : 0.3343\n",
      "07-12 01:34 root         INFO     Training accuracy  : 0.8208, f1: 0.8158\n",
      "07-12 01:34 root         INFO     Validation accuracy: 0.8288, f1: 0.8241\n",
      "07-12 01:35 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-12 01:35 root         INFO     In-batch loss      : 0.3483\n",
      "07-12 01:35 root         INFO     Training accuracy  : 0.8470, f1: 0.8450\n",
      "07-12 01:35 root         INFO     Validation accuracy: 0.8475, f1: 0.8446\n",
      "07-12 01:37 root         INFO     Epoch 12. Global step 8645. T=10.02min\n",
      "07-12 01:37 root         INFO     In-batch loss      : 1.0361\n",
      "07-12 01:37 root         INFO     Training accuracy  : 0.8604, f1: 0.8587\n",
      "07-12 01:37 root         INFO     Validation accuracy: 0.8627, f1: 0.8603\n",
      "07-12 01:38 root         INFO     Epoch 14. Global step 9975. T=11.56min\n",
      "07-12 01:38 root         INFO     In-batch loss      : 0.7787\n",
      "07-12 01:38 root         INFO     Training accuracy  : 0.8712, f1: 0.8705\n",
      "07-12 01:38 root         INFO     Validation accuracy: 0.8659, f1: 0.8644\n",
      "07-12 01:40 root         INFO     Epoch 16. Global step 11305. T=13.10min\n",
      "07-12 01:40 root         INFO     In-batch loss      : 0.0761\n",
      "07-12 01:40 root         INFO     Training accuracy  : 0.8811, f1: 0.8798\n",
      "07-12 01:40 root         INFO     Validation accuracy: 0.8643, f1: 0.8621\n",
      "07-12 01:41 root         INFO     Epoch 18. Global step 12635. T=14.63min\n",
      "07-12 01:41 root         INFO     In-batch loss      : 0.0088\n",
      "07-12 01:41 root         INFO     Training accuracy  : 0.8886, f1: 0.8887\n",
      "07-12 01:41 root         INFO     Validation accuracy: 0.8699, f1: 0.8697\n",
      "07-12 01:42 root         INFO     Epoch 19. Global step 13300. T=15.40min\n",
      "07-12 01:42 root         INFO     In-batch loss      : 0.3692\n",
      "07-12 01:42 root         INFO     Training accuracy  : 0.8923, f1: 0.8920\n",
      "07-12 01:42 root         INFO     Validation accuracy: 0.8680, f1: 0.8671\n",
      "07-12 01:42 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 01:42 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.16932902333838498, 'input_dim': 300, 'lr': 0.00018896411825326646}\n",
      "07-12 01:42 root         INFO     Writer: runs/Jul12_01-42-42_lyalin_RNNBinaryClassifier_lr3_dropout0.16932902333838498_noise_level0.0000hyperparameters_search_random\n",
      "07-12 01:43 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-12 01:43 root         INFO     In-batch loss      : 1.0617\n",
      "07-12 01:43 root         INFO     Training accuracy  : 0.6430, f1: 0.6783\n",
      "07-12 01:43 root         INFO     Validation accuracy: 0.6408, f1: 0.6761\n",
      "07-12 01:45 root         INFO     Epoch 2. Global step 1995. T=2.88min\n",
      "07-12 01:45 root         INFO     In-batch loss      : 0.4494\n",
      "07-12 01:45 root         INFO     Training accuracy  : 0.7343, f1: 0.7195\n",
      "07-12 01:45 root         INFO     Validation accuracy: 0.7341, f1: 0.7200\n",
      "07-12 01:47 root         INFO     Epoch 4. Global step 3325. T=4.81min\n",
      "07-12 01:47 root         INFO     In-batch loss      : 0.2509\n",
      "07-12 01:47 root         INFO     Training accuracy  : 0.7805, f1: 0.7863\n",
      "07-12 01:47 root         INFO     Validation accuracy: 0.7789, f1: 0.7828\n",
      "07-12 01:49 root         INFO     Epoch 6. Global step 4655. T=6.75min\n",
      "07-12 01:49 root         INFO     In-batch loss      : 0.1499\n",
      "07-12 01:49 root         INFO     Training accuracy  : 0.8232, f1: 0.8267\n",
      "07-12 01:49 root         INFO     Validation accuracy: 0.8229, f1: 0.8256\n",
      "07-12 01:51 root         INFO     Epoch 8. Global step 5985. T=8.68min\n",
      "07-12 01:51 root         INFO     In-batch loss      : 1.2878\n",
      "07-12 01:51 root         INFO     Training accuracy  : 0.8530, f1: 0.8528\n",
      "07-12 01:51 root         INFO     Validation accuracy: 0.8475, f1: 0.8462\n",
      "07-12 01:53 root         INFO     Epoch 10. Global step 7315. T=10.62min\n",
      "07-12 01:53 root         INFO     In-batch loss      : 0.0323\n",
      "07-12 01:53 root         INFO     Training accuracy  : 0.8685, f1: 0.8686\n",
      "07-12 01:53 root         INFO     Validation accuracy: 0.8539, f1: 0.8528\n",
      "07-12 01:55 root         INFO     Epoch 12. Global step 8645. T=12.55min\n",
      "07-12 01:55 root         INFO     In-batch loss      : 0.2788\n",
      "07-12 01:55 root         INFO     Training accuracy  : 0.8831, f1: 0.8831\n",
      "07-12 01:55 root         INFO     Validation accuracy: 0.8640, f1: 0.8627\n",
      "07-12 01:57 root         INFO     Epoch 14. Global step 9975. T=14.53min\n",
      "07-12 01:57 root         INFO     In-batch loss      : 0.4100\n",
      "07-12 01:57 root         INFO     Training accuracy  : 0.8976, f1: 0.8965\n",
      "07-12 01:57 root         INFO     Validation accuracy: 0.8677, f1: 0.8657\n",
      "07-12 01:59 root         INFO     Epoch 16. Global step 11305. T=16.45min\n",
      "07-12 01:59 root         INFO     In-batch loss      : 1.7214\n",
      "07-12 01:59 root         INFO     Training accuracy  : 0.9062, f1: 0.9066\n",
      "07-12 01:59 root         INFO     Validation accuracy: 0.8627, f1: 0.8627\n",
      "07-12 02:01 root         INFO     Epoch 18. Global step 12635. T=18.41min\n",
      "07-12 02:01 root         INFO     In-batch loss      : 0.7845\n",
      "07-12 02:01 root         INFO     Training accuracy  : 0.9187, f1: 0.9177\n",
      "07-12 02:01 root         INFO     Validation accuracy: 0.8624, f1: 0.8597\n",
      "07-12 02:02 root         INFO     Epoch 19. Global step 13300. T=19.38min\n",
      "07-12 02:02 root         INFO     In-batch loss      : 0.1759\n",
      "07-12 02:02 root         INFO     Training accuracy  : 0.9263, f1: 0.9263\n",
      "07-12 02:02 root         INFO     Validation accuracy: 0.8613, f1: 0.8607\n",
      "07-12 02:02 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 02:02 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.19682083244247645, 'input_dim': 300, 'lr': 0.0006258490940383969}\n",
      "07-12 02:02 root         INFO     Writer: runs/Jul12_02-02-09_lyalin_RNNBinaryClassifier_lr3_dropout0.19682083244247645_noise_level0.0000hyperparameters_search_random\n",
      "07-12 02:02 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 02:02 root         INFO     In-batch loss      : 0.6393\n",
      "07-12 02:02 root         INFO     Training accuracy  : 0.5943, f1: 0.4662\n",
      "07-12 02:02 root         INFO     Validation accuracy: 0.6061, f1: 0.4859\n",
      "07-12 02:04 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 02:04 root         INFO     In-batch loss      : 0.3460\n",
      "07-12 02:04 root         INFO     Training accuracy  : 0.7447, f1: 0.7185\n",
      "07-12 02:04 root         INFO     Validation accuracy: 0.7488, f1: 0.7249\n",
      "07-12 02:06 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 02:06 root         INFO     In-batch loss      : 0.1324\n",
      "07-12 02:06 root         INFO     Training accuracy  : 0.8297, f1: 0.8283\n",
      "07-12 02:06 root         INFO     Validation accuracy: 0.8328, f1: 0.8318\n",
      "07-12 02:07 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-12 02:07 root         INFO     In-batch loss      : 0.0798\n",
      "07-12 02:07 root         INFO     Training accuracy  : 0.8707, f1: 0.8723\n",
      "07-12 02:07 root         INFO     Validation accuracy: 0.8605, f1: 0.8615\n",
      "07-12 02:09 root         INFO     Epoch 8. Global step 5985. T=6.98min\n",
      "07-12 02:09 root         INFO     In-batch loss      : 0.0185\n",
      "07-12 02:09 root         INFO     Training accuracy  : 0.8888, f1: 0.8884\n",
      "07-12 02:09 root         INFO     Validation accuracy: 0.8704, f1: 0.8688\n",
      "07-12 02:10 root         INFO     Epoch 10. Global step 7315. T=8.53min\n",
      "07-12 02:10 root         INFO     In-batch loss      : 0.0082\n",
      "07-12 02:10 root         INFO     Training accuracy  : 0.9051, f1: 0.9042\n",
      "07-12 02:10 root         INFO     Validation accuracy: 0.8752, f1: 0.8728\n",
      "07-12 02:12 root         INFO     Epoch 12. Global step 8645. T=10.08min\n",
      "07-12 02:12 root         INFO     In-batch loss      : 0.4124\n",
      "07-12 02:12 root         INFO     Training accuracy  : 0.9192, f1: 0.9197\n",
      "07-12 02:12 root         INFO     Validation accuracy: 0.8741, f1: 0.8742\n",
      "07-12 02:13 root         INFO     Epoch 14. Global step 9975. T=11.62min\n",
      "07-12 02:13 root         INFO     In-batch loss      : 0.1894\n",
      "07-12 02:13 root         INFO     Training accuracy  : 0.9383, f1: 0.9384\n",
      "07-12 02:13 root         INFO     Validation accuracy: 0.8789, f1: 0.8787\n",
      "07-12 02:15 root         INFO     Epoch 16. Global step 11305. T=13.17min\n",
      "07-12 02:15 root         INFO     In-batch loss      : 0.0248\n",
      "07-12 02:15 root         INFO     Training accuracy  : 0.9537, f1: 0.9538\n",
      "07-12 02:15 root         INFO     Validation accuracy: 0.8771, f1: 0.8776\n",
      "07-12 02:16 root         INFO     Epoch 18. Global step 12635. T=14.72min\n",
      "07-12 02:16 root         INFO     In-batch loss      : 0.0223\n",
      "07-12 02:16 root         INFO     Training accuracy  : 0.9706, f1: 0.9705\n",
      "07-12 02:16 root         INFO     Validation accuracy: 0.8709, f1: 0.8704\n",
      "07-12 02:17 root         INFO     Epoch 19. Global step 13300. T=15.49min\n",
      "07-12 02:17 root         INFO     In-batch loss      : 0.0196\n",
      "07-12 02:17 root         INFO     Training accuracy  : 0.9781, f1: 0.9781\n",
      "07-12 02:17 root         INFO     Validation accuracy: 0.8744, f1: 0.8741\n",
      "07-12 02:17 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 02:17 root         INFO     YES!, f1: 0.8744982606368745, parameters: {'hidden_dim': 256, 'dropout': 0.19682083244247645, 'input_dim': 300, 'lr': 0.0006258490940383969}\n",
      "07-12 02:17 root         INFO     {'hidden_dim': 256, 'dropout': 0.19682083244247645, 'input_dim': 300, 'lr': 0.0006258490940383969}\n",
      "07-12 02:17 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.9895199407449289, 'input_dim': 300, 'lr': 0.00010913956562494761}\n",
      "07-12 02:17 root         INFO     Writer: runs/Jul12_02-17-42_lyalin_RNNBinaryClassifier_lr3_dropout0.9895199407449289_noise_level0.0000hyperparameters_search_random\n",
      "07-12 02:18 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 02:18 root         INFO     In-batch loss      : 0.7657\n",
      "07-12 02:18 root         INFO     Training accuracy  : 0.5000, f1: 0.0379\n",
      "07-12 02:18 root         INFO     Validation accuracy: 0.5077, f1: 0.0385\n",
      "07-12 02:20 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 02:20 root         INFO     In-batch loss      : 0.8374\n",
      "07-12 02:20 root         INFO     Training accuracy  : 0.5004, f1: 0.0757\n",
      "07-12 02:20 root         INFO     Validation accuracy: 0.5096, f1: 0.0791\n",
      "07-12 02:21 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 02:21 root         INFO     In-batch loss      : 0.4800\n",
      "07-12 02:21 root         INFO     Training accuracy  : 0.5024, f1: 0.0911\n",
      "07-12 02:21 root         INFO     Validation accuracy: 0.5093, f1: 0.0882\n",
      "07-12 02:23 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 02:23 root         INFO     In-batch loss      : 0.4498\n",
      "07-12 02:23 root         INFO     Training accuracy  : 0.5036, f1: 0.1012\n",
      "07-12 02:23 root         INFO     Validation accuracy: 0.5125, f1: 0.1022\n",
      "07-12 02:24 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-12 02:24 root         INFO     In-batch loss      : 1.0587\n",
      "07-12 02:24 root         INFO     Training accuracy  : 0.5071, f1: 0.1751\n",
      "07-12 02:24 root         INFO     Validation accuracy: 0.5120, f1: 0.1697\n",
      "07-12 02:26 root         INFO     Epoch 10. Global step 7315. T=8.47min\n",
      "07-12 02:26 root         INFO     In-batch loss      : 0.6934\n",
      "07-12 02:26 root         INFO     Training accuracy  : 0.5074, f1: 0.2128\n",
      "07-12 02:26 root         INFO     Validation accuracy: 0.5149, f1: 0.2129\n",
      "07-12 02:27 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-12 02:27 root         INFO     In-batch loss      : 0.6989\n",
      "07-12 02:27 root         INFO     Training accuracy  : 0.5107, f1: 0.2014\n",
      "07-12 02:27 root         INFO     Validation accuracy: 0.5163, f1: 0.1959\n",
      "07-12 02:29 root         INFO     Epoch 14. Global step 9975. T=11.55min\n",
      "07-12 02:29 root         INFO     In-batch loss      : 0.7067\n",
      "07-12 02:29 root         INFO     Training accuracy  : 0.5154, f1: 0.2824\n",
      "07-12 02:29 root         INFO     Validation accuracy: 0.5227, f1: 0.2823\n",
      "07-12 02:30 root         INFO     Epoch 16. Global step 11305. T=13.08min\n",
      "07-12 02:30 root         INFO     In-batch loss      : 0.6932\n",
      "07-12 02:30 root         INFO     Training accuracy  : 0.5163, f1: 0.3163\n",
      "07-12 02:30 root         INFO     Validation accuracy: 0.5227, f1: 0.3147\n",
      "07-12 02:32 root         INFO     Epoch 18. Global step 12635. T=14.61min\n",
      "07-12 02:32 root         INFO     In-batch loss      : 0.6932\n",
      "07-12 02:32 root         INFO     Training accuracy  : 0.5185, f1: 0.3326\n",
      "07-12 02:32 root         INFO     Validation accuracy: 0.5261, f1: 0.3362\n",
      "07-12 02:33 root         INFO     Epoch 19. Global step 13300. T=15.38min\n",
      "07-12 02:33 root         INFO     In-batch loss      : 0.6932\n",
      "07-12 02:33 root         INFO     Training accuracy  : 0.5196, f1: 0.2968\n",
      "07-12 02:33 root         INFO     Validation accuracy: 0.5245, f1: 0.2994\n",
      "07-12 02:33 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 02:33 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.15912138640658208, 'input_dim': 300, 'lr': 0.000397410061708101}\n",
      "07-12 02:33 root         INFO     Writer: runs/Jul12_02-33-09_lyalin_RNNBinaryClassifier_lr3_dropout0.15912138640658208_noise_level0.0000hyperparameters_search_random\n",
      "07-12 02:33 root         INFO     Epoch 0. Global step 665. T=0.80min\n",
      "07-12 02:33 root         INFO     In-batch loss      : 0.7742\n",
      "07-12 02:33 root         INFO     Training accuracy  : 0.6695, f1: 0.6654\n",
      "07-12 02:33 root         INFO     Validation accuracy: 0.6675, f1: 0.6622\n",
      "07-12 02:35 root         INFO     Epoch 2. Global step 1995. T=2.43min\n",
      "07-12 02:35 root         INFO     In-batch loss      : 0.2810\n",
      "07-12 02:35 root         INFO     Training accuracy  : 0.7487, f1: 0.7454\n",
      "07-12 02:35 root         INFO     Validation accuracy: 0.7493, f1: 0.7447\n",
      "07-12 02:37 root         INFO     Epoch 4. Global step 3325. T=4.04min\n",
      "07-12 02:37 root         INFO     In-batch loss      : 0.2475\n",
      "07-12 02:37 root         INFO     Training accuracy  : 0.8195, f1: 0.8147\n",
      "07-12 02:37 root         INFO     Validation accuracy: 0.8235, f1: 0.8181\n",
      "07-12 02:38 root         INFO     Epoch 6. Global step 4655. T=5.64min\n",
      "07-12 02:38 root         INFO     In-batch loss      : 0.3120\n",
      "07-12 02:38 root         INFO     Training accuracy  : 0.8581, f1: 0.8583\n",
      "07-12 02:38 root         INFO     Validation accuracy: 0.8600, f1: 0.8599\n",
      "07-12 02:40 root         INFO     Epoch 8. Global step 5985. T=7.31min\n",
      "07-12 02:40 root         INFO     In-batch loss      : 0.2178\n",
      "07-12 02:40 root         INFO     Training accuracy  : 0.8784, f1: 0.8785\n",
      "07-12 02:40 root         INFO     Validation accuracy: 0.8672, f1: 0.8670\n",
      "07-12 02:42 root         INFO     Epoch 10. Global step 7315. T=8.90min\n",
      "07-12 02:42 root         INFO     In-batch loss      : 0.0089\n",
      "07-12 02:42 root         INFO     Training accuracy  : 0.8960, f1: 0.8970\n",
      "07-12 02:42 root         INFO     Validation accuracy: 0.8669, f1: 0.8675\n",
      "07-12 02:43 root         INFO     Epoch 12. Global step 8645. T=10.49min\n",
      "07-12 02:43 root         INFO     In-batch loss      : 0.0637\n",
      "07-12 02:43 root         INFO     Training accuracy  : 0.9102, f1: 0.9100\n",
      "07-12 02:43 root         INFO     Validation accuracy: 0.8683, f1: 0.8668\n",
      "07-12 02:45 root         INFO     Epoch 14. Global step 9975. T=12.08min\n",
      "07-12 02:45 root         INFO     In-batch loss      : 0.0151\n",
      "07-12 02:45 root         INFO     Training accuracy  : 0.9254, f1: 0.9255\n",
      "07-12 02:45 root         INFO     Validation accuracy: 0.8741, f1: 0.8735\n",
      "07-12 02:46 root         INFO     Epoch 16. Global step 11305. T=13.69min\n",
      "07-12 02:46 root         INFO     In-batch loss      : 0.0231\n",
      "07-12 02:46 root         INFO     Training accuracy  : 0.9409, f1: 0.9413\n",
      "07-12 02:46 root         INFO     Validation accuracy: 0.8699, f1: 0.8696\n",
      "07-12 02:48 root         INFO     Epoch 18. Global step 12635. T=15.28min\n",
      "07-12 02:48 root         INFO     In-batch loss      : 0.0006\n",
      "07-12 02:48 root         INFO     Training accuracy  : 0.9560, f1: 0.9560\n",
      "07-12 02:48 root         INFO     Validation accuracy: 0.8667, f1: 0.8658\n",
      "07-12 02:49 root         INFO     Epoch 19. Global step 13300. T=16.08min\n",
      "07-12 02:49 root         INFO     In-batch loss      : 0.0017\n",
      "07-12 02:49 root         INFO     Training accuracy  : 0.9665, f1: 0.9666\n",
      "07-12 02:49 root         INFO     Validation accuracy: 0.8592, f1: 0.8593\n",
      "07-12 02:49 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 02:49 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.49513893442250767, 'input_dim': 300, 'lr': 0.0005696494907926694}\n",
      "07-12 02:49 root         INFO     Writer: runs/Jul12_02-49-18_lyalin_RNNBinaryClassifier_lr3_dropout0.49513893442250767_noise_level0.0000hyperparameters_search_random\n",
      "07-12 02:50 root         INFO     Epoch 0. Global step 665. T=0.80min\n",
      "07-12 02:50 root         INFO     In-batch loss      : 0.4542\n",
      "07-12 02:50 root         INFO     Training accuracy  : 0.6846, f1: 0.6991\n",
      "07-12 02:50 root         INFO     Validation accuracy: 0.6784, f1: 0.6939\n",
      "07-12 02:51 root         INFO     Epoch 2. Global step 1995. T=2.35min\n",
      "07-12 02:51 root         INFO     In-batch loss      : 0.9645\n",
      "07-12 02:51 root         INFO     Training accuracy  : 0.7447, f1: 0.7356\n",
      "07-12 02:51 root         INFO     Validation accuracy: 0.7355, f1: 0.7279\n",
      "07-12 02:53 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-12 02:53 root         INFO     In-batch loss      : 0.3508\n",
      "07-12 02:53 root         INFO     Training accuracy  : 0.8324, f1: 0.8278\n",
      "07-12 02:53 root         INFO     Validation accuracy: 0.8344, f1: 0.8289\n",
      "07-12 02:54 root         INFO     Epoch 6. Global step 4655. T=5.44min\n",
      "07-12 02:54 root         INFO     In-batch loss      : 0.1052\n",
      "07-12 02:54 root         INFO     Training accuracy  : 0.8617, f1: 0.8586\n",
      "07-12 02:54 root         INFO     Validation accuracy: 0.8589, f1: 0.8553\n",
      "07-12 02:56 root         INFO     Epoch 8. Global step 5985. T=6.98min\n",
      "07-12 02:56 root         INFO     In-batch loss      : 0.0399\n",
      "07-12 02:56 root         INFO     Training accuracy  : 0.8787, f1: 0.8781\n",
      "07-12 02:56 root         INFO     Validation accuracy: 0.8648, f1: 0.8635\n",
      "07-12 02:57 root         INFO     Epoch 10. Global step 7315. T=8.53min\n",
      "07-12 02:57 root         INFO     In-batch loss      : 0.0119\n",
      "07-12 02:57 root         INFO     Training accuracy  : 0.8932, f1: 0.8915\n",
      "07-12 02:57 root         INFO     Validation accuracy: 0.8656, f1: 0.8625\n",
      "07-12 02:59 root         INFO     Epoch 12. Global step 8645. T=10.07min\n",
      "07-12 02:59 root         INFO     In-batch loss      : 0.9954\n",
      "07-12 02:59 root         INFO     Training accuracy  : 0.9068, f1: 0.9066\n",
      "07-12 02:59 root         INFO     Validation accuracy: 0.8677, f1: 0.8672\n",
      "07-12 03:00 root         INFO     Epoch 14. Global step 9975. T=11.63min\n",
      "07-12 03:00 root         INFO     In-batch loss      : 0.0731\n",
      "07-12 03:00 root         INFO     Training accuracy  : 0.9221, f1: 0.9219\n",
      "07-12 03:00 root         INFO     Validation accuracy: 0.8720, f1: 0.8713\n",
      "07-12 03:02 root         INFO     Epoch 16. Global step 11305. T=13.18min\n",
      "07-12 03:02 root         INFO     In-batch loss      : 0.0065\n",
      "07-12 03:02 root         INFO     Training accuracy  : 0.9383, f1: 0.9379\n",
      "07-12 03:02 root         INFO     Validation accuracy: 0.8696, f1: 0.8682\n",
      "07-12 03:04 root         INFO     Epoch 18. Global step 12635. T=14.72min\n",
      "07-12 03:04 root         INFO     In-batch loss      : 0.0267\n",
      "07-12 03:04 root         INFO     Training accuracy  : 0.9550, f1: 0.9547\n",
      "07-12 03:04 root         INFO     Validation accuracy: 0.8675, f1: 0.8660\n",
      "07-12 03:04 root         INFO     Epoch 19. Global step 13300. T=15.50min\n",
      "07-12 03:04 root         INFO     In-batch loss      : 0.0530\n",
      "07-12 03:04 root         INFO     Training accuracy  : 0.9641, f1: 0.9642\n",
      "07-12 03:04 root         INFO     Validation accuracy: 0.8683, f1: 0.8683\n",
      "07-12 03:04 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 03:04 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.7035452287492109, 'input_dim': 300, 'lr': 0.00013410440869872123}\n",
      "07-12 03:04 root         INFO     Writer: runs/Jul12_03-04-53_lyalin_RNNBinaryClassifier_lr3_dropout0.7035452287492109_noise_level0.0000hyperparameters_search_random\n",
      "07-12 03:05 root         INFO     Epoch 0. Global step 665. T=0.76min\n",
      "07-12 03:05 root         INFO     In-batch loss      : 0.7156\n",
      "07-12 03:05 root         INFO     Training accuracy  : 0.5198, f1: 0.6409\n",
      "07-12 03:05 root         INFO     Validation accuracy: 0.5219, f1: 0.6393\n",
      "07-12 03:07 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 03:07 root         INFO     In-batch loss      : 0.7193\n",
      "07-12 03:07 root         INFO     Training accuracy  : 0.6997, f1: 0.7026\n",
      "07-12 03:07 root         INFO     Validation accuracy: 0.6899, f1: 0.6940\n",
      "07-12 03:08 root         INFO     Epoch 4. Global step 3325. T=3.88min\n",
      "07-12 03:08 root         INFO     In-batch loss      : 0.1809\n",
      "07-12 03:08 root         INFO     Training accuracy  : 0.7913, f1: 0.7965\n",
      "07-12 03:08 root         INFO     Validation accuracy: 0.7923, f1: 0.7979\n",
      "07-12 03:10 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 03:10 root         INFO     In-batch loss      : 0.0997\n",
      "07-12 03:10 root         INFO     Training accuracy  : 0.8059, f1: 0.7994\n",
      "07-12 03:10 root         INFO     Validation accuracy: 0.8115, f1: 0.8053\n",
      "07-12 03:11 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 03:11 root         INFO     In-batch loss      : 0.1282\n",
      "07-12 03:11 root         INFO     Training accuracy  : 0.8144, f1: 0.8171\n",
      "07-12 03:11 root         INFO     Validation accuracy: 0.8237, f1: 0.8260\n",
      "07-12 03:13 root         INFO     Epoch 10. Global step 7315. T=8.52min\n",
      "07-12 03:13 root         INFO     In-batch loss      : 0.6402\n",
      "07-12 03:13 root         INFO     Training accuracy  : 0.8217, f1: 0.8221\n",
      "07-12 03:13 root         INFO     Validation accuracy: 0.8299, f1: 0.8301\n",
      "07-12 03:14 root         INFO     Epoch 12. Global step 8645. T=10.07min\n",
      "07-12 03:14 root         INFO     In-batch loss      : 0.6317\n",
      "07-12 03:14 root         INFO     Training accuracy  : 0.8291, f1: 0.8269\n",
      "07-12 03:14 root         INFO     Validation accuracy: 0.8371, f1: 0.8354\n",
      "07-12 03:16 root         INFO     Epoch 14. Global step 9975. T=11.63min\n",
      "07-12 03:16 root         INFO     In-batch loss      : 0.1849\n",
      "07-12 03:16 root         INFO     Training accuracy  : 0.8363, f1: 0.8369\n",
      "07-12 03:16 root         INFO     Validation accuracy: 0.8445, f1: 0.8448\n",
      "07-12 03:18 root         INFO     Epoch 16. Global step 11305. T=13.18min\n",
      "07-12 03:18 root         INFO     In-batch loss      : 0.0697\n",
      "07-12 03:18 root         INFO     Training accuracy  : 0.8448, f1: 0.8427\n",
      "07-12 03:18 root         INFO     Validation accuracy: 0.8507, f1: 0.8485\n",
      "07-12 03:19 root         INFO     Epoch 18. Global step 12635. T=14.73min\n",
      "07-12 03:19 root         INFO     In-batch loss      : 0.0830\n",
      "07-12 03:19 root         INFO     Training accuracy  : 0.8534, f1: 0.8543\n",
      "07-12 03:19 root         INFO     Validation accuracy: 0.8539, f1: 0.8546\n",
      "07-12 03:20 root         INFO     Epoch 19. Global step 13300. T=15.51min\n",
      "07-12 03:20 root         INFO     In-batch loss      : 0.1790\n",
      "07-12 03:20 root         INFO     Training accuracy  : 0.8565, f1: 0.8571\n",
      "07-12 03:20 root         INFO     Validation accuracy: 0.8555, f1: 0.8560\n",
      "07-12 03:20 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 03:20 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.6045786326313876, 'input_dim': 300, 'lr': 0.00016803591484314468}\n",
      "07-12 03:20 root         INFO     Writer: runs/Jul12_03-20-28_lyalin_RNNBinaryClassifier_lr3_dropout0.6045786326313876_noise_level0.0000hyperparameters_search_random\n",
      "07-12 03:21 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-12 03:21 root         INFO     In-batch loss      : 0.6860\n",
      "07-12 03:21 root         INFO     Training accuracy  : 0.5133, f1: 0.6553\n",
      "07-12 03:21 root         INFO     Validation accuracy: 0.5125, f1: 0.6535\n",
      "07-12 03:22 root         INFO     Epoch 2. Global step 1995. T=2.34min\n",
      "07-12 03:22 root         INFO     In-batch loss      : 0.6571\n",
      "07-12 03:22 root         INFO     Training accuracy  : 0.5483, f1: 0.3413\n",
      "07-12 03:22 root         INFO     Validation accuracy: 0.5528, f1: 0.3528\n",
      "07-12 03:24 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-12 03:24 root         INFO     In-batch loss      : 0.2796\n",
      "07-12 03:24 root         INFO     Training accuracy  : 0.7506, f1: 0.7548\n",
      "07-12 03:24 root         INFO     Validation accuracy: 0.7499, f1: 0.7541\n",
      "07-12 03:25 root         INFO     Epoch 6. Global step 4655. T=5.44min\n",
      "07-12 03:25 root         INFO     In-batch loss      : 0.6659\n",
      "07-12 03:25 root         INFO     Training accuracy  : 0.7878, f1: 0.7856\n",
      "07-12 03:25 root         INFO     Validation accuracy: 0.7912, f1: 0.7898\n",
      "07-12 03:27 root         INFO     Epoch 8. Global step 5985. T=7.02min\n",
      "07-12 03:27 root         INFO     In-batch loss      : 0.3530\n",
      "07-12 03:27 root         INFO     Training accuracy  : 0.8050, f1: 0.8043\n",
      "07-12 03:27 root         INFO     Validation accuracy: 0.8123, f1: 0.8116\n",
      "07-12 03:29 root         INFO     Epoch 10. Global step 7315. T=8.58min\n",
      "07-12 03:29 root         INFO     In-batch loss      : 0.9324\n",
      "07-12 03:29 root         INFO     Training accuracy  : 0.8162, f1: 0.8128\n",
      "07-12 03:29 root         INFO     Validation accuracy: 0.8200, f1: 0.8167\n",
      "07-12 03:30 root         INFO     Epoch 12. Global step 8645. T=10.15min\n",
      "07-12 03:30 root         INFO     In-batch loss      : 0.0530\n",
      "07-12 03:30 root         INFO     Training accuracy  : 0.8245, f1: 0.8257\n",
      "07-12 03:30 root         INFO     Validation accuracy: 0.8304, f1: 0.8317\n",
      "07-12 03:32 root         INFO     Epoch 14. Global step 9975. T=11.69min\n",
      "07-12 03:32 root         INFO     In-batch loss      : 0.1407\n",
      "07-12 03:32 root         INFO     Training accuracy  : 0.8320, f1: 0.8303\n",
      "07-12 03:32 root         INFO     Validation accuracy: 0.8384, f1: 0.8366\n",
      "07-12 03:33 root         INFO     Epoch 16. Global step 11305. T=13.24min\n",
      "07-12 03:33 root         INFO     In-batch loss      : 0.8712\n",
      "07-12 03:33 root         INFO     Training accuracy  : 0.8392, f1: 0.8378\n",
      "07-12 03:33 root         INFO     Validation accuracy: 0.8437, f1: 0.8420\n",
      "07-12 03:35 root         INFO     Epoch 18. Global step 12635. T=14.79min\n",
      "07-12 03:35 root         INFO     In-batch loss      : 0.0190\n",
      "07-12 03:35 root         INFO     Training accuracy  : 0.8473, f1: 0.8489\n",
      "07-12 03:35 root         INFO     Validation accuracy: 0.8475, f1: 0.8486\n",
      "07-12 03:36 root         INFO     Epoch 19. Global step 13300. T=15.56min\n",
      "07-12 03:36 root         INFO     In-batch loss      : 1.2242\n",
      "07-12 03:36 root         INFO     Training accuracy  : 0.8495, f1: 0.8479\n",
      "07-12 03:36 root         INFO     Validation accuracy: 0.8507, f1: 0.8486\n",
      "07-12 03:36 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 03:36 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.22460846829130482, 'input_dim': 300, 'lr': 0.0005871231814479305}\n",
      "07-12 03:36 root         INFO     Writer: runs/Jul12_03-36-05_lyalin_RNNBinaryClassifier_lr3_dropout0.22460846829130482_noise_level0.0000hyperparameters_search_random\n",
      "07-12 03:36 root         INFO     Epoch 0. Global step 665. T=0.81min\n",
      "07-12 03:36 root         INFO     In-batch loss      : 0.7256\n",
      "07-12 03:36 root         INFO     Training accuracy  : 0.6513, f1: 0.6268\n",
      "07-12 03:36 root         INFO     Validation accuracy: 0.6416, f1: 0.6186\n",
      "07-12 03:38 root         INFO     Epoch 2. Global step 1995. T=2.41min\n",
      "07-12 03:38 root         INFO     In-batch loss      : 0.9642\n",
      "07-12 03:38 root         INFO     Training accuracy  : 0.6939, f1: 0.6517\n",
      "07-12 03:38 root         INFO     Validation accuracy: 0.6917, f1: 0.6497\n",
      "07-12 03:40 root         INFO     Epoch 4. Global step 3325. T=4.00min\n",
      "07-12 03:40 root         INFO     In-batch loss      : 0.7086\n",
      "07-12 03:40 root         INFO     Training accuracy  : 0.8254, f1: 0.8239\n",
      "07-12 03:40 root         INFO     Validation accuracy: 0.8227, f1: 0.8206\n",
      "07-12 03:41 root         INFO     Epoch 6. Global step 4655. T=5.60min\n",
      "07-12 03:41 root         INFO     In-batch loss      : 0.5474\n",
      "07-12 03:41 root         INFO     Training accuracy  : 0.8752, f1: 0.8762\n",
      "07-12 03:41 root         INFO     Validation accuracy: 0.8683, f1: 0.8683\n",
      "07-12 03:43 root         INFO     Epoch 8. Global step 5985. T=7.25min\n",
      "07-12 03:43 root         INFO     In-batch loss      : 0.1561\n",
      "07-12 03:43 root         INFO     Training accuracy  : 0.8980, f1: 0.8975\n",
      "07-12 03:43 root         INFO     Validation accuracy: 0.8741, f1: 0.8722\n",
      "07-12 03:44 root         INFO     Epoch 10. Global step 7315. T=8.88min\n",
      "07-12 03:44 root         INFO     In-batch loss      : 1.6695\n",
      "07-12 03:44 root         INFO     Training accuracy  : 0.9207, f1: 0.9201\n",
      "07-12 03:44 root         INFO     Validation accuracy: 0.8693, f1: 0.8670\n",
      "07-12 03:46 root         INFO     Epoch 12. Global step 8645. T=10.47min\n",
      "07-12 03:46 root         INFO     In-batch loss      : 0.3142\n",
      "07-12 03:46 root         INFO     Training accuracy  : 0.9442, f1: 0.9441\n",
      "07-12 03:46 root         INFO     Validation accuracy: 0.8699, f1: 0.8685\n",
      "07-12 03:48 root         INFO     Epoch 14. Global step 9975. T=12.12min\n",
      "07-12 03:48 root         INFO     In-batch loss      : 0.0182\n",
      "07-12 03:48 root         INFO     Training accuracy  : 0.9659, f1: 0.9659\n",
      "07-12 03:48 root         INFO     Validation accuracy: 0.8645, f1: 0.8640\n",
      "07-12 03:49 root         INFO     Epoch 16. Global step 11305. T=13.73min\n",
      "07-12 03:49 root         INFO     In-batch loss      : 0.0008\n",
      "07-12 03:49 root         INFO     Training accuracy  : 0.9823, f1: 0.9823\n",
      "07-12 03:49 root         INFO     Validation accuracy: 0.8637, f1: 0.8635\n",
      "07-12 03:51 root         INFO     Epoch 18. Global step 12635. T=15.34min\n",
      "07-12 03:51 root         INFO     In-batch loss      : 0.0021\n",
      "07-12 03:51 root         INFO     Training accuracy  : 0.9911, f1: 0.9911\n",
      "07-12 03:51 root         INFO     Validation accuracy: 0.8600, f1: 0.8582\n",
      "07-12 03:52 root         INFO     Epoch 19. Global step 13300. T=16.14min\n",
      "07-12 03:52 root         INFO     In-batch loss      : 0.0001\n",
      "07-12 03:52 root         INFO     Training accuracy  : 0.9937, f1: 0.9937\n",
      "07-12 03:52 root         INFO     Validation accuracy: 0.8603, f1: 0.8588\n",
      "07-12 03:52 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 03:52 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.9015763476525555, 'input_dim': 300, 'lr': 0.0009344483176521484}\n",
      "07-12 03:52 root         INFO     Writer: runs/Jul12_03-52-18_lyalin_RNNBinaryClassifier_lr3_dropout0.9015763476525555_noise_level0.0000hyperparameters_search_random\n",
      "07-12 03:53 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 03:53 root         INFO     In-batch loss      : 0.7341\n",
      "07-12 03:53 root         INFO     Training accuracy  : 0.5165, f1: 0.6557\n",
      "07-12 03:53 root         INFO     Validation accuracy: 0.5168, f1: 0.6559\n",
      "07-12 03:54 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 03:54 root         INFO     In-batch loss      : 0.7509\n",
      "07-12 03:54 root         INFO     Training accuracy  : 0.6426, f1: 0.5598\n",
      "07-12 03:54 root         INFO     Validation accuracy: 0.6349, f1: 0.5456\n",
      "07-12 03:56 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 03:56 root         INFO     In-batch loss      : 0.7889\n",
      "07-12 03:56 root         INFO     Training accuracy  : 0.6975, f1: 0.6627\n",
      "07-12 03:56 root         INFO     Validation accuracy: 0.7032, f1: 0.6706\n",
      "07-12 03:57 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 03:57 root         INFO     In-batch loss      : 0.1352\n",
      "07-12 03:57 root         INFO     Training accuracy  : 0.7744, f1: 0.7741\n",
      "07-12 03:57 root         INFO     Validation accuracy: 0.7744, f1: 0.7752\n",
      "07-12 03:59 root         INFO     Epoch 8. Global step 5985. T=6.94min\n",
      "07-12 03:59 root         INFO     In-batch loss      : 0.1545\n",
      "07-12 03:59 root         INFO     Training accuracy  : 0.8270, f1: 0.8274\n",
      "07-12 03:59 root         INFO     Validation accuracy: 0.8320, f1: 0.8320\n",
      "07-12 04:00 root         INFO     Epoch 10. Global step 7315. T=8.49min\n",
      "07-12 04:00 root         INFO     In-batch loss      : 0.4919\n",
      "07-12 04:00 root         INFO     Training accuracy  : 0.8555, f1: 0.8552\n",
      "07-12 04:00 root         INFO     Validation accuracy: 0.8555, f1: 0.8550\n",
      "07-12 04:02 root         INFO     Epoch 12. Global step 8645. T=10.03min\n",
      "07-12 04:02 root         INFO     In-batch loss      : 0.2074\n",
      "07-12 04:02 root         INFO     Training accuracy  : 0.8746, f1: 0.8755\n",
      "07-12 04:02 root         INFO     Validation accuracy: 0.8648, f1: 0.8656\n",
      "07-12 04:03 root         INFO     Epoch 14. Global step 9975. T=11.56min\n",
      "07-12 04:03 root         INFO     In-batch loss      : 2.2756\n",
      "07-12 04:03 root         INFO     Training accuracy  : 0.8841, f1: 0.8837\n",
      "07-12 04:03 root         INFO     Validation accuracy: 0.8677, f1: 0.8673\n",
      "07-12 04:05 root         INFO     Epoch 16. Global step 11305. T=13.11min\n",
      "07-12 04:05 root         INFO     In-batch loss      : 0.1405\n",
      "07-12 04:05 root         INFO     Training accuracy  : 0.8937, f1: 0.8929\n",
      "07-12 04:05 root         INFO     Validation accuracy: 0.8664, f1: 0.8656\n",
      "07-12 04:06 root         INFO     Epoch 18. Global step 12635. T=14.66min\n",
      "07-12 04:06 root         INFO     In-batch loss      : 0.1584\n",
      "07-12 04:06 root         INFO     Training accuracy  : 0.9032, f1: 0.9036\n",
      "07-12 04:06 root         INFO     Validation accuracy: 0.8672, f1: 0.8677\n",
      "07-12 04:07 root         INFO     Epoch 19. Global step 13300. T=15.42min\n",
      "07-12 04:07 root         INFO     In-batch loss      : 0.1154\n",
      "07-12 04:07 root         INFO     Training accuracy  : 0.9068, f1: 0.9067\n",
      "07-12 04:07 root         INFO     Validation accuracy: 0.8688, f1: 0.8685\n",
      "07-12 04:07 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 04:07 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.6929985391902389, 'input_dim': 300, 'lr': 0.00041935177945678014}\n",
      "07-12 04:07 root         INFO     Writer: runs/Jul12_04-07-47_lyalin_RNNBinaryClassifier_lr3_dropout0.6929985391902389_noise_level0.0000hyperparameters_search_random\n",
      "07-12 04:08 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 04:08 root         INFO     In-batch loss      : 0.7800\n",
      "07-12 04:08 root         INFO     Training accuracy  : 0.5156, f1: 0.6538\n",
      "07-12 04:08 root         INFO     Validation accuracy: 0.5163, f1: 0.6533\n",
      "07-12 04:10 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 04:10 root         INFO     In-batch loss      : 0.3774\n",
      "07-12 04:10 root         INFO     Training accuracy  : 0.6677, f1: 0.6536\n",
      "07-12 04:10 root         INFO     Validation accuracy: 0.6568, f1: 0.6420\n",
      "07-12 04:11 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 04:11 root         INFO     In-batch loss      : 0.3559\n",
      "07-12 04:11 root         INFO     Training accuracy  : 0.7572, f1: 0.7441\n",
      "07-12 04:11 root         INFO     Validation accuracy: 0.7565, f1: 0.7422\n",
      "07-12 04:13 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-12 04:13 root         INFO     In-batch loss      : 0.1915\n",
      "07-12 04:13 root         INFO     Training accuracy  : 0.7948, f1: 0.8017\n",
      "07-12 04:13 root         INFO     Validation accuracy: 0.7973, f1: 0.8036\n",
      "07-12 04:14 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 04:14 root         INFO     In-batch loss      : 0.4261\n",
      "07-12 04:14 root         INFO     Training accuracy  : 0.8191, f1: 0.8140\n",
      "07-12 04:14 root         INFO     Validation accuracy: 0.8235, f1: 0.8171\n",
      "07-12 04:16 root         INFO     Epoch 10. Global step 7315. T=8.49min\n",
      "07-12 04:16 root         INFO     In-batch loss      : 0.0933\n",
      "07-12 04:16 root         INFO     Training accuracy  : 0.8378, f1: 0.8391\n",
      "07-12 04:16 root         INFO     Validation accuracy: 0.8501, f1: 0.8507\n",
      "07-12 04:17 root         INFO     Epoch 12. Global step 8645. T=10.03min\n",
      "07-12 04:17 root         INFO     In-batch loss      : 0.0891\n",
      "07-12 04:17 root         INFO     Training accuracy  : 0.8505, f1: 0.8488\n",
      "07-12 04:17 root         INFO     Validation accuracy: 0.8603, f1: 0.8578\n",
      "07-12 04:19 root         INFO     Epoch 14. Global step 9975. T=11.57min\n",
      "07-12 04:19 root         INFO     In-batch loss      : 0.0515\n",
      "07-12 04:19 root         INFO     Training accuracy  : 0.8624, f1: 0.8614\n",
      "07-12 04:19 root         INFO     Validation accuracy: 0.8677, f1: 0.8665\n",
      "07-12 04:20 root         INFO     Epoch 16. Global step 11305. T=13.12min\n",
      "07-12 04:20 root         INFO     In-batch loss      : 0.4770\n",
      "07-12 04:20 root         INFO     Training accuracy  : 0.8711, f1: 0.8691\n",
      "07-12 04:20 root         INFO     Validation accuracy: 0.8667, f1: 0.8644\n",
      "07-12 04:22 root         INFO     Epoch 18. Global step 12635. T=14.66min\n",
      "07-12 04:22 root         INFO     In-batch loss      : 0.1469\n",
      "07-12 04:22 root         INFO     Training accuracy  : 0.8769, f1: 0.8761\n",
      "07-12 04:22 root         INFO     Validation accuracy: 0.8704, f1: 0.8694\n",
      "07-12 04:23 root         INFO     Epoch 19. Global step 13300. T=15.43min\n",
      "07-12 04:23 root         INFO     In-batch loss      : 0.2944\n",
      "07-12 04:23 root         INFO     Training accuracy  : 0.8815, f1: 0.8815\n",
      "07-12 04:23 root         INFO     Validation accuracy: 0.8715, f1: 0.8709\n",
      "07-12 04:23 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 04:23 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.388534516372286, 'input_dim': 300, 'lr': 0.00022642442366441299}\n",
      "07-12 04:23 root         INFO     Writer: runs/Jul12_04-23-17_lyalin_RNNBinaryClassifier_lr3_dropout0.388534516372286_noise_level0.0000hyperparameters_search_random\n",
      "07-12 04:24 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 04:24 root         INFO     In-batch loss      : 0.6825\n",
      "07-12 04:24 root         INFO     Training accuracy  : 0.5082, f1: 0.6271\n",
      "07-12 04:24 root         INFO     Validation accuracy: 0.5077, f1: 0.6206\n",
      "07-12 04:25 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 04:25 root         INFO     In-batch loss      : 0.6563\n",
      "07-12 04:25 root         INFO     Training accuracy  : 0.5248, f1: 0.3386\n",
      "07-12 04:25 root         INFO     Validation accuracy: 0.5280, f1: 0.3469\n",
      "07-12 04:27 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 04:27 root         INFO     In-batch loss      : 0.5523\n",
      "07-12 04:27 root         INFO     Training accuracy  : 0.5335, f1: 0.3418\n",
      "07-12 04:27 root         INFO     Validation accuracy: 0.5389, f1: 0.3527\n",
      "07-12 04:28 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-12 04:28 root         INFO     In-batch loss      : 0.4984\n",
      "07-12 04:28 root         INFO     Training accuracy  : 0.6288, f1: 0.5314\n",
      "07-12 04:28 root         INFO     Validation accuracy: 0.6349, f1: 0.5383\n",
      "07-12 04:30 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 04:30 root         INFO     In-batch loss      : 0.4083\n",
      "07-12 04:30 root         INFO     Training accuracy  : 0.7411, f1: 0.7556\n",
      "07-12 04:30 root         INFO     Validation accuracy: 0.7427, f1: 0.7546\n",
      "07-12 04:31 root         INFO     Epoch 10. Global step 7315. T=8.50min\n",
      "07-12 04:31 root         INFO     In-batch loss      : 0.3313\n",
      "07-12 04:31 root         INFO     Training accuracy  : 0.7728, f1: 0.7806\n",
      "07-12 04:31 root         INFO     Validation accuracy: 0.7731, f1: 0.7796\n",
      "07-12 04:33 root         INFO     Epoch 12. Global step 8645. T=10.04min\n",
      "07-12 04:33 root         INFO     In-batch loss      : 0.2116\n",
      "07-12 04:33 root         INFO     Training accuracy  : 0.7892, f1: 0.7867\n",
      "07-12 04:33 root         INFO     Validation accuracy: 0.7915, f1: 0.7876\n",
      "07-12 04:34 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 04:34 root         INFO     In-batch loss      : 0.2128\n",
      "07-12 04:34 root         INFO     Training accuracy  : 0.8051, f1: 0.8062\n",
      "07-12 04:34 root         INFO     Validation accuracy: 0.8083, f1: 0.8092\n",
      "07-12 04:36 root         INFO     Epoch 16. Global step 11305. T=13.13min\n",
      "07-12 04:36 root         INFO     In-batch loss      : 0.1697\n",
      "07-12 04:36 root         INFO     Training accuracy  : 0.8183, f1: 0.8177\n",
      "07-12 04:36 root         INFO     Validation accuracy: 0.8213, f1: 0.8209\n",
      "07-12 04:37 root         INFO     Epoch 18. Global step 12635. T=14.67min\n",
      "07-12 04:37 root         INFO     In-batch loss      : 0.2835\n",
      "07-12 04:37 root         INFO     Training accuracy  : 0.8287, f1: 0.8312\n",
      "07-12 04:37 root         INFO     Validation accuracy: 0.8288, f1: 0.8313\n",
      "07-12 04:38 root         INFO     Epoch 19. Global step 13300. T=15.44min\n",
      "07-12 04:38 root         INFO     In-batch loss      : 0.1095\n",
      "07-12 04:38 root         INFO     Training accuracy  : 0.8344, f1: 0.8327\n",
      "07-12 04:38 root         INFO     Validation accuracy: 0.8360, f1: 0.8345\n",
      "07-12 04:38 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 04:38 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.2748888760455165, 'input_dim': 300, 'lr': 0.000373143358810775}\n",
      "07-12 04:38 root         INFO     Writer: runs/Jul12_04-38-48_lyalin_RNNBinaryClassifier_lr3_dropout0.2748888760455165_noise_level0.0000hyperparameters_search_random\n",
      "07-12 04:39 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 04:39 root         INFO     In-batch loss      : 0.6899\n",
      "07-12 04:39 root         INFO     Training accuracy  : 0.5630, f1: 0.6597\n",
      "07-12 04:39 root         INFO     Validation accuracy: 0.5600, f1: 0.6539\n",
      "07-12 04:41 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 04:41 root         INFO     In-batch loss      : 0.2743\n",
      "07-12 04:41 root         INFO     Training accuracy  : 0.7248, f1: 0.7165\n",
      "07-12 04:41 root         INFO     Validation accuracy: 0.7251, f1: 0.7161\n",
      "07-12 04:42 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 04:42 root         INFO     In-batch loss      : 0.3476\n",
      "07-12 04:42 root         INFO     Training accuracy  : 0.7921, f1: 0.7961\n",
      "07-12 04:42 root         INFO     Validation accuracy: 0.7987, f1: 0.8025\n",
      "07-12 04:44 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 04:44 root         INFO     In-batch loss      : 0.0675\n",
      "07-12 04:44 root         INFO     Training accuracy  : 0.8376, f1: 0.8384\n",
      "07-12 04:44 root         INFO     Validation accuracy: 0.8435, f1: 0.8439\n",
      "07-12 04:45 root         INFO     Epoch 8. Global step 5985. T=6.98min\n",
      "07-12 04:45 root         INFO     In-batch loss      : 0.0670\n",
      "07-12 04:45 root         INFO     Training accuracy  : 0.8576, f1: 0.8572\n",
      "07-12 04:45 root         INFO     Validation accuracy: 0.8560, f1: 0.8551\n",
      "07-12 04:47 root         INFO     Epoch 10. Global step 7315. T=8.52min\n",
      "07-12 04:47 root         INFO     In-batch loss      : 0.1562\n",
      "07-12 04:47 root         INFO     Training accuracy  : 0.8706, f1: 0.8685\n",
      "07-12 04:47 root         INFO     Validation accuracy: 0.8565, f1: 0.8535\n",
      "07-12 04:48 root         INFO     Epoch 12. Global step 8645. T=10.06min\n",
      "07-12 04:48 root         INFO     In-batch loss      : 0.5419\n",
      "07-12 04:48 root         INFO     Training accuracy  : 0.8840, f1: 0.8838\n",
      "07-12 04:48 root         INFO     Validation accuracy: 0.8672, f1: 0.8665\n",
      "07-12 04:50 root         INFO     Epoch 14. Global step 9975. T=11.61min\n",
      "07-12 04:50 root         INFO     In-batch loss      : 0.2608\n",
      "07-12 04:50 root         INFO     Training accuracy  : 0.8932, f1: 0.8929\n",
      "07-12 04:50 root         INFO     Validation accuracy: 0.8637, f1: 0.8623\n",
      "07-12 04:51 root         INFO     Epoch 16. Global step 11305. T=13.16min\n",
      "07-12 04:51 root         INFO     In-batch loss      : 0.0471\n",
      "07-12 04:51 root         INFO     Training accuracy  : 0.9046, f1: 0.9048\n",
      "07-12 04:51 root         INFO     Validation accuracy: 0.8691, f1: 0.8683\n",
      "07-12 04:53 root         INFO     Epoch 18. Global step 12635. T=14.71min\n",
      "07-12 04:53 root         INFO     In-batch loss      : 0.0530\n",
      "07-12 04:53 root         INFO     Training accuracy  : 0.9170, f1: 0.9165\n",
      "07-12 04:53 root         INFO     Validation accuracy: 0.8640, f1: 0.8623\n",
      "07-12 04:54 root         INFO     Epoch 19. Global step 13300. T=15.49min\n",
      "07-12 04:54 root         INFO     In-batch loss      : 0.0064\n",
      "07-12 04:54 root         INFO     Training accuracy  : 0.9225, f1: 0.9224\n",
      "07-12 04:54 root         INFO     Validation accuracy: 0.8664, f1: 0.8656\n",
      "07-12 04:54 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 04:54 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.35439008748161016, 'input_dim': 300, 'lr': 0.00023178476004676193}\n",
      "07-12 04:54 root         INFO     Writer: runs/Jul12_04-54-21_lyalin_RNNBinaryClassifier_lr3_dropout0.35439008748161016_noise_level0.0000hyperparameters_search_random\n",
      "07-12 04:55 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 04:55 root         INFO     In-batch loss      : 0.6580\n",
      "07-12 04:55 root         INFO     Training accuracy  : 0.5329, f1: 0.3312\n",
      "07-12 04:55 root         INFO     Validation accuracy: 0.5408, f1: 0.3427\n",
      "07-12 04:56 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 04:56 root         INFO     In-batch loss      : 0.3856\n",
      "07-12 04:56 root         INFO     Training accuracy  : 0.6860, f1: 0.6526\n",
      "07-12 04:56 root         INFO     Validation accuracy: 0.6808, f1: 0.6495\n",
      "07-12 04:58 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 04:58 root         INFO     In-batch loss      : 0.3388\n",
      "07-12 04:58 root         INFO     Training accuracy  : 0.7341, f1: 0.7087\n",
      "07-12 04:58 root         INFO     Validation accuracy: 0.7309, f1: 0.7052\n",
      "07-12 04:59 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 04:59 root         INFO     In-batch loss      : 1.1346\n",
      "07-12 04:59 root         INFO     Training accuracy  : 0.7856, f1: 0.7829\n",
      "07-12 04:59 root         INFO     Validation accuracy: 0.7824, f1: 0.7798\n",
      "07-12 05:01 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 05:01 root         INFO     In-batch loss      : 0.1474\n",
      "07-12 05:01 root         INFO     Training accuracy  : 0.8120, f1: 0.8094\n",
      "07-12 05:01 root         INFO     Validation accuracy: 0.8045, f1: 0.8018\n",
      "07-12 05:02 root         INFO     Epoch 10. Global step 7315. T=8.53min\n",
      "07-12 05:02 root         INFO     In-batch loss      : 0.4708\n",
      "07-12 05:02 root         INFO     Training accuracy  : 0.8383, f1: 0.8399\n",
      "07-12 05:02 root         INFO     Validation accuracy: 0.8429, f1: 0.8437\n",
      "07-12 05:04 root         INFO     Epoch 12. Global step 8645. T=10.07min\n",
      "07-12 05:04 root         INFO     In-batch loss      : 0.0398\n",
      "07-12 05:04 root         INFO     Training accuracy  : 0.8536, f1: 0.8527\n",
      "07-12 05:04 root         INFO     Validation accuracy: 0.8547, f1: 0.8531\n",
      "07-12 05:05 root         INFO     Epoch 14. Global step 9975. T=11.63min\n",
      "07-12 05:05 root         INFO     In-batch loss      : 0.9220\n",
      "07-12 05:05 root         INFO     Training accuracy  : 0.8643, f1: 0.8633\n",
      "07-12 05:05 root         INFO     Validation accuracy: 0.8592, f1: 0.8575\n",
      "07-12 05:07 root         INFO     Epoch 16. Global step 11305. T=13.18min\n",
      "07-12 05:07 root         INFO     In-batch loss      : 0.2904\n",
      "07-12 05:07 root         INFO     Training accuracy  : 0.8743, f1: 0.8741\n",
      "07-12 05:07 root         INFO     Validation accuracy: 0.8629, f1: 0.8624\n",
      "07-12 05:09 root         INFO     Epoch 18. Global step 12635. T=14.72min\n",
      "07-12 05:09 root         INFO     In-batch loss      : 0.0637\n",
      "07-12 05:09 root         INFO     Training accuracy  : 0.8794, f1: 0.8793\n",
      "07-12 05:09 root         INFO     Validation accuracy: 0.8672, f1: 0.8658\n",
      "07-12 05:09 root         INFO     Epoch 19. Global step 13300. T=15.50min\n",
      "07-12 05:09 root         INFO     In-batch loss      : 0.0380\n",
      "07-12 05:09 root         INFO     Training accuracy  : 0.8841, f1: 0.8849\n",
      "07-12 05:09 root         INFO     Validation accuracy: 0.8691, f1: 0.8699\n",
      "07-12 05:09 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 05:09 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.8196016394792673, 'input_dim': 300, 'lr': 0.00015272567428891855}\n",
      "07-12 05:09 root         INFO     Writer: runs/Jul12_05-09-55_lyalin_RNNBinaryClassifier_lr3_dropout0.8196016394792673_noise_level0.0000hyperparameters_search_random\n",
      "07-12 05:10 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-12 05:10 root         INFO     In-batch loss      : 0.6276\n",
      "07-12 05:10 root         INFO     Training accuracy  : 0.5047, f1: 0.6433\n",
      "07-12 05:10 root         INFO     Validation accuracy: 0.4907, f1: 0.6323\n",
      "07-12 05:12 root         INFO     Epoch 2. Global step 1995. T=2.34min\n",
      "07-12 05:12 root         INFO     In-batch loss      : 0.6130\n",
      "07-12 05:12 root         INFO     Training accuracy  : 0.5163, f1: 0.6319\n",
      "07-12 05:12 root         INFO     Validation accuracy: 0.5048, f1: 0.6197\n",
      "07-12 05:13 root         INFO     Epoch 4. Global step 3325. T=3.88min\n",
      "07-12 05:13 root         INFO     In-batch loss      : 0.7298\n",
      "07-12 05:13 root         INFO     Training accuracy  : 0.5278, f1: 0.3550\n",
      "07-12 05:13 root         INFO     Validation accuracy: 0.5251, f1: 0.3591\n",
      "07-12 05:15 root         INFO     Epoch 6. Global step 4655. T=5.43min\n",
      "07-12 05:15 root         INFO     In-batch loss      : 0.7139\n",
      "07-12 05:15 root         INFO     Training accuracy  : 0.5360, f1: 0.3295\n",
      "07-12 05:15 root         INFO     Validation accuracy: 0.5384, f1: 0.3370\n",
      "07-12 05:16 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 05:16 root         INFO     In-batch loss      : 0.4644\n",
      "07-12 05:16 root         INFO     Training accuracy  : 0.6109, f1: 0.4902\n",
      "07-12 05:16 root         INFO     Validation accuracy: 0.6149, f1: 0.4979\n",
      "07-12 05:18 root         INFO     Epoch 10. Global step 7315. T=8.51min\n",
      "07-12 05:18 root         INFO     In-batch loss      : 1.0571\n",
      "07-12 05:18 root         INFO     Training accuracy  : 0.7575, f1: 0.7694\n",
      "07-12 05:18 root         INFO     Validation accuracy: 0.7555, f1: 0.7648\n",
      "07-12 05:19 root         INFO     Epoch 12. Global step 8645. T=10.06min\n",
      "07-12 05:19 root         INFO     In-batch loss      : 0.4489\n",
      "07-12 05:19 root         INFO     Training accuracy  : 0.7868, f1: 0.7868\n",
      "07-12 05:19 root         INFO     Validation accuracy: 0.7960, f1: 0.7949\n",
      "07-12 05:21 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 05:21 root         INFO     In-batch loss      : 0.7284\n",
      "07-12 05:21 root         INFO     Training accuracy  : 0.7992, f1: 0.8023\n",
      "07-12 05:21 root         INFO     Validation accuracy: 0.8064, f1: 0.8075\n",
      "07-12 05:23 root         INFO     Epoch 16. Global step 11305. T=13.13min\n",
      "07-12 05:23 root         INFO     In-batch loss      : 0.9794\n",
      "07-12 05:23 root         INFO     Training accuracy  : 0.8102, f1: 0.8075\n",
      "07-12 05:23 root         INFO     Validation accuracy: 0.8181, f1: 0.8150\n",
      "07-12 05:24 root         INFO     Epoch 18. Global step 12635. T=14.67min\n",
      "07-12 05:24 root         INFO     In-batch loss      : 0.3842\n",
      "07-12 05:24 root         INFO     Training accuracy  : 0.8190, f1: 0.8164\n",
      "07-12 05:24 root         INFO     Validation accuracy: 0.8259, f1: 0.8231\n",
      "07-12 05:25 root         INFO     Epoch 19. Global step 13300. T=15.44min\n",
      "07-12 05:25 root         INFO     In-batch loss      : 0.3364\n",
      "07-12 05:25 root         INFO     Training accuracy  : 0.8229, f1: 0.8214\n",
      "07-12 05:25 root         INFO     Validation accuracy: 0.8283, f1: 0.8264\n",
      "07-12 05:25 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 05:25 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.3935347454074254, 'input_dim': 300, 'lr': 0.0001688737044725898}\n",
      "07-12 05:25 root         INFO     Writer: runs/Jul12_05-25-26_lyalin_RNNBinaryClassifier_lr3_dropout0.3935347454074254_noise_level0.0000hyperparameters_search_random\n",
      "07-12 05:26 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 05:26 root         INFO     In-batch loss      : 0.7118\n",
      "07-12 05:26 root         INFO     Training accuracy  : 0.5260, f1: 0.3255\n",
      "07-12 05:26 root         INFO     Validation accuracy: 0.5405, f1: 0.3456\n",
      "07-12 05:27 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 05:27 root         INFO     In-batch loss      : 0.6535\n",
      "07-12 05:27 root         INFO     Training accuracy  : 0.6991, f1: 0.7055\n",
      "07-12 05:27 root         INFO     Validation accuracy: 0.7016, f1: 0.7073\n",
      "07-12 05:29 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 05:29 root         INFO     In-batch loss      : 1.0506\n",
      "07-12 05:29 root         INFO     Training accuracy  : 0.7839, f1: 0.7788\n",
      "07-12 05:29 root         INFO     Validation accuracy: 0.7912, f1: 0.7868\n",
      "07-12 05:30 root         INFO     Epoch 6. Global step 4655. T=5.41min\n",
      "07-12 05:30 root         INFO     In-batch loss      : 0.1661\n",
      "07-12 05:30 root         INFO     Training accuracy  : 0.8056, f1: 0.8060\n",
      "07-12 05:30 root         INFO     Validation accuracy: 0.8163, f1: 0.8161\n",
      "07-12 05:32 root         INFO     Epoch 8. Global step 5985. T=6.96min\n",
      "07-12 05:32 root         INFO     In-batch loss      : 1.4140\n",
      "07-12 05:32 root         INFO     Training accuracy  : 0.8176, f1: 0.8185\n",
      "07-12 05:32 root         INFO     Validation accuracy: 0.8243, f1: 0.8245\n",
      "07-12 05:33 root         INFO     Epoch 10. Global step 7315. T=8.51min\n",
      "07-12 05:33 root         INFO     In-batch loss      : 0.2210\n",
      "07-12 05:33 root         INFO     Training accuracy  : 0.8258, f1: 0.8234\n",
      "07-12 05:33 root         INFO     Validation accuracy: 0.8304, f1: 0.8271\n",
      "07-12 05:35 root         INFO     Epoch 12. Global step 8645. T=10.04min\n",
      "07-12 05:35 root         INFO     In-batch loss      : 1.2061\n",
      "07-12 05:35 root         INFO     Training accuracy  : 0.8319, f1: 0.8279\n",
      "07-12 05:35 root         INFO     Validation accuracy: 0.8413, f1: 0.8368\n",
      "07-12 05:37 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 05:37 root         INFO     In-batch loss      : 0.2113\n",
      "07-12 05:37 root         INFO     Training accuracy  : 0.8409, f1: 0.8405\n",
      "07-12 05:37 root         INFO     Validation accuracy: 0.8477, f1: 0.8469\n",
      "07-12 05:38 root         INFO     Epoch 16. Global step 11305. T=13.14min\n",
      "07-12 05:38 root         INFO     In-batch loss      : 0.1153\n",
      "07-12 05:38 root         INFO     Training accuracy  : 0.8466, f1: 0.8477\n",
      "07-12 05:38 root         INFO     Validation accuracy: 0.8523, f1: 0.8530\n",
      "07-12 05:40 root         INFO     Epoch 18. Global step 12635. T=14.69min\n",
      "07-12 05:40 root         INFO     In-batch loss      : 0.0187\n",
      "07-12 05:40 root         INFO     Training accuracy  : 0.8526, f1: 0.8512\n",
      "07-12 05:40 root         INFO     Validation accuracy: 0.8563, f1: 0.8548\n",
      "07-12 05:40 root         INFO     Epoch 19. Global step 13300. T=15.46min\n",
      "07-12 05:40 root         INFO     In-batch loss      : 0.2576\n",
      "07-12 05:40 root         INFO     Training accuracy  : 0.8569, f1: 0.8583\n",
      "07-12 05:40 root         INFO     Validation accuracy: 0.8571, f1: 0.8582\n",
      "07-12 05:40 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 05:40 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.12151481724801662, 'input_dim': 300, 'lr': 0.00041075625429829875}\n",
      "07-12 05:40 root         INFO     Writer: runs/Jul12_05-40-57_lyalin_RNNBinaryClassifier_lr3_dropout0.12151481724801662_noise_level0.0000hyperparameters_search_random\n",
      "07-12 05:41 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-12 05:41 root         INFO     In-batch loss      : 0.7955\n",
      "07-12 05:41 root         INFO     Training accuracy  : 0.6782, f1: 0.6694\n",
      "07-12 05:41 root         INFO     Validation accuracy: 0.6811, f1: 0.6705\n",
      "07-12 05:43 root         INFO     Epoch 2. Global step 1995. T=2.91min\n",
      "07-12 05:43 root         INFO     In-batch loss      : 1.0794\n",
      "07-12 05:43 root         INFO     Training accuracy  : 0.7019, f1: 0.6510\n",
      "07-12 05:43 root         INFO     Validation accuracy: 0.7061, f1: 0.6580\n",
      "07-12 05:45 root         INFO     Epoch 4. Global step 3325. T=4.85min\n",
      "07-12 05:45 root         INFO     In-batch loss      : 1.0046\n",
      "07-12 05:45 root         INFO     Training accuracy  : 0.8531, f1: 0.8531\n",
      "07-12 05:45 root         INFO     Validation accuracy: 0.8616, f1: 0.8605\n",
      "07-12 05:47 root         INFO     Epoch 6. Global step 4655. T=6.78min\n",
      "07-12 05:47 root         INFO     In-batch loss      : 0.0986\n",
      "07-12 05:47 root         INFO     Training accuracy  : 0.8825, f1: 0.8839\n",
      "07-12 05:47 root         INFO     Validation accuracy: 0.8696, f1: 0.8699\n",
      "07-12 05:49 root         INFO     Epoch 8. Global step 5985. T=8.71min\n",
      "07-12 05:49 root         INFO     In-batch loss      : 0.0317\n",
      "07-12 05:49 root         INFO     Training accuracy  : 0.9014, f1: 0.9006\n",
      "07-12 05:49 root         INFO     Validation accuracy: 0.8669, f1: 0.8638\n",
      "07-12 05:51 root         INFO     Epoch 10. Global step 7315. T=10.65min\n",
      "07-12 05:51 root         INFO     In-batch loss      : 0.4963\n",
      "07-12 05:51 root         INFO     Training accuracy  : 0.9225, f1: 0.9224\n",
      "07-12 05:51 root         INFO     Validation accuracy: 0.8680, f1: 0.8660\n",
      "07-12 05:53 root         INFO     Epoch 12. Global step 8645. T=12.59min\n",
      "07-12 05:53 root         INFO     In-batch loss      : 0.0223\n",
      "07-12 05:53 root         INFO     Training accuracy  : 0.9468, f1: 0.9468\n",
      "07-12 05:53 root         INFO     Validation accuracy: 0.8675, f1: 0.8661\n",
      "07-12 05:55 root         INFO     Epoch 14. Global step 9975. T=14.54min\n",
      "07-12 05:55 root         INFO     In-batch loss      : 0.0005\n",
      "07-12 05:55 root         INFO     Training accuracy  : 0.9667, f1: 0.9669\n",
      "07-12 05:55 root         INFO     Validation accuracy: 0.8563, f1: 0.8553\n",
      "07-12 05:57 root         INFO     Epoch 16. Global step 11305. T=16.47min\n",
      "07-12 05:57 root         INFO     In-batch loss      : 0.0007\n",
      "07-12 05:57 root         INFO     Training accuracy  : 0.9840, f1: 0.9840\n",
      "07-12 05:57 root         INFO     Validation accuracy: 0.8589, f1: 0.8575\n",
      "07-12 05:59 root         INFO     Epoch 18. Global step 12635. T=18.42min\n",
      "07-12 05:59 root         INFO     In-batch loss      : 0.0041\n",
      "07-12 05:59 root         INFO     Training accuracy  : 0.9914, f1: 0.9915\n",
      "07-12 05:59 root         INFO     Validation accuracy: 0.8536, f1: 0.8529\n",
      "07-12 06:00 root         INFO     Epoch 19. Global step 13300. T=19.39min\n",
      "07-12 06:00 root         INFO     In-batch loss      : 0.0001\n",
      "07-12 06:00 root         INFO     Training accuracy  : 0.9932, f1: 0.9932\n",
      "07-12 06:00 root         INFO     Validation accuracy: 0.8579, f1: 0.8583\n",
      "07-12 06:00 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 06:00 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.43126273469556886, 'input_dim': 300, 'lr': 0.00022155124949479053}\n",
      "07-12 06:00 root         INFO     Writer: runs/Jul12_06-00-25_lyalin_RNNBinaryClassifier_lr3_dropout0.43126273469556886_noise_level0.0000hyperparameters_search_random\n",
      "07-12 06:01 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 06:01 root         INFO     In-batch loss      : 0.6770\n",
      "07-12 06:01 root         INFO     Training accuracy  : 0.5221, f1: 0.6444\n",
      "07-12 06:01 root         INFO     Validation accuracy: 0.5245, f1: 0.6447\n",
      "07-12 06:02 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 06:02 root         INFO     In-batch loss      : 0.3761\n",
      "07-12 06:02 root         INFO     Training accuracy  : 0.7320, f1: 0.7345\n",
      "07-12 06:02 root         INFO     Validation accuracy: 0.7341, f1: 0.7365\n",
      "07-12 06:04 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 06:04 root         INFO     In-batch loss      : 0.5549\n",
      "07-12 06:04 root         INFO     Training accuracy  : 0.7877, f1: 0.7859\n",
      "07-12 06:04 root         INFO     Validation accuracy: 0.7912, f1: 0.7885\n",
      "07-12 06:05 root         INFO     Epoch 6. Global step 4655. T=5.41min\n",
      "07-12 06:05 root         INFO     In-batch loss      : 1.1915\n",
      "07-12 06:05 root         INFO     Training accuracy  : 0.8059, f1: 0.8088\n",
      "07-12 06:05 root         INFO     Validation accuracy: 0.8133, f1: 0.8161\n",
      "07-12 06:07 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 06:07 root         INFO     In-batch loss      : 0.0945\n",
      "07-12 06:07 root         INFO     Training accuracy  : 0.8191, f1: 0.8217\n",
      "07-12 06:07 root         INFO     Validation accuracy: 0.8251, f1: 0.8281\n",
      "07-12 06:08 root         INFO     Epoch 10. Global step 7315. T=8.50min\n",
      "07-12 06:08 root         INFO     In-batch loss      : 0.6286\n",
      "07-12 06:08 root         INFO     Training accuracy  : 0.8330, f1: 0.8323\n",
      "07-12 06:08 root         INFO     Validation accuracy: 0.8437, f1: 0.8434\n",
      "07-12 06:10 root         INFO     Epoch 12. Global step 8645. T=10.04min\n",
      "07-12 06:10 root         INFO     In-batch loss      : 0.6197\n",
      "07-12 06:10 root         INFO     Training accuracy  : 0.8413, f1: 0.8438\n",
      "07-12 06:10 root         INFO     Validation accuracy: 0.8475, f1: 0.8494\n",
      "07-12 06:12 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 06:12 root         INFO     In-batch loss      : 0.2554\n",
      "07-12 06:12 root         INFO     Training accuracy  : 0.8530, f1: 0.8525\n",
      "07-12 06:12 root         INFO     Validation accuracy: 0.8547, f1: 0.8538\n",
      "07-12 06:13 root         INFO     Epoch 16. Global step 11305. T=13.13min\n",
      "07-12 06:13 root         INFO     In-batch loss      : 0.1226\n",
      "07-12 06:13 root         INFO     Training accuracy  : 0.8609, f1: 0.8615\n",
      "07-12 06:13 root         INFO     Validation accuracy: 0.8629, f1: 0.8634\n",
      "07-12 06:15 root         INFO     Epoch 18. Global step 12635. T=14.67min\n",
      "07-12 06:15 root         INFO     In-batch loss      : 0.1536\n",
      "07-12 06:15 root         INFO     Training accuracy  : 0.8677, f1: 0.8679\n",
      "07-12 06:15 root         INFO     Validation accuracy: 0.8645, f1: 0.8649\n",
      "07-12 06:15 root         INFO     Epoch 19. Global step 13300. T=15.45min\n",
      "07-12 06:15 root         INFO     In-batch loss      : 0.0651\n",
      "07-12 06:15 root         INFO     Training accuracy  : 0.8690, f1: 0.8697\n",
      "07-12 06:15 root         INFO     Validation accuracy: 0.8629, f1: 0.8633\n",
      "07-12 06:15 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 06:15 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.1842268069636836, 'input_dim': 300, 'lr': 0.0004691741016471544}\n",
      "07-12 06:15 root         INFO     Writer: runs/Jul12_06-15-56_lyalin_RNNBinaryClassifier_lr3_dropout0.1842268069636836_noise_level0.0000hyperparameters_search_random\n",
      "07-12 06:16 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 06:16 root         INFO     In-batch loss      : 0.7627\n",
      "07-12 06:16 root         INFO     Training accuracy  : 0.5233, f1: 0.3229\n",
      "07-12 06:16 root         INFO     Validation accuracy: 0.5259, f1: 0.3301\n",
      "07-12 06:18 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 06:18 root         INFO     In-batch loss      : 0.6939\n",
      "07-12 06:18 root         INFO     Training accuracy  : 0.5480, f1: 0.3580\n",
      "07-12 06:18 root         INFO     Validation accuracy: 0.5453, f1: 0.3578\n",
      "07-12 06:19 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 06:19 root         INFO     In-batch loss      : 0.3233\n",
      "07-12 06:19 root         INFO     Training accuracy  : 0.7351, f1: 0.7283\n",
      "07-12 06:19 root         INFO     Validation accuracy: 0.7376, f1: 0.7322\n",
      "07-12 06:21 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 06:21 root         INFO     In-batch loss      : 0.3052\n",
      "07-12 06:21 root         INFO     Training accuracy  : 0.7722, f1: 0.7546\n",
      "07-12 06:21 root         INFO     Validation accuracy: 0.7747, f1: 0.7575\n",
      "07-12 06:22 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-12 06:22 root         INFO     In-batch loss      : 0.1703\n",
      "07-12 06:22 root         INFO     Training accuracy  : 0.8093, f1: 0.8051\n",
      "07-12 06:22 root         INFO     Validation accuracy: 0.8104, f1: 0.8065\n",
      "07-12 06:24 root         INFO     Epoch 10. Global step 7315. T=8.46min\n",
      "07-12 06:24 root         INFO     In-batch loss      : 0.9113\n",
      "07-12 06:24 root         INFO     Training accuracy  : 0.8306, f1: 0.8306\n",
      "07-12 06:24 root         INFO     Validation accuracy: 0.8325, f1: 0.8322\n",
      "07-12 06:25 root         INFO     Epoch 12. Global step 8645. T=10.00min\n",
      "07-12 06:25 root         INFO     In-batch loss      : 0.0701\n",
      "07-12 06:25 root         INFO     Training accuracy  : 0.8437, f1: 0.8450\n",
      "07-12 06:25 root         INFO     Validation accuracy: 0.8424, f1: 0.8431\n",
      "07-12 06:27 root         INFO     Epoch 14. Global step 9975. T=11.54min\n",
      "07-12 06:27 root         INFO     In-batch loss      : 0.4043\n",
      "07-12 06:27 root         INFO     Training accuracy  : 0.8550, f1: 0.8523\n",
      "07-12 06:27 root         INFO     Validation accuracy: 0.8579, f1: 0.8554\n",
      "07-12 06:29 root         INFO     Epoch 16. Global step 11305. T=13.08min\n",
      "07-12 06:29 root         INFO     In-batch loss      : 0.0918\n",
      "07-12 06:29 root         INFO     Training accuracy  : 0.8641, f1: 0.8635\n",
      "07-12 06:29 root         INFO     Validation accuracy: 0.8584, f1: 0.8574\n",
      "07-12 06:30 root         INFO     Epoch 18. Global step 12635. T=14.62min\n",
      "07-12 06:30 root         INFO     In-batch loss      : 0.1952\n",
      "07-12 06:30 root         INFO     Training accuracy  : 0.8712, f1: 0.8704\n",
      "07-12 06:30 root         INFO     Validation accuracy: 0.8640, f1: 0.8633\n",
      "07-12 06:31 root         INFO     Epoch 19. Global step 13300. T=15.40min\n",
      "07-12 06:31 root         INFO     In-batch loss      : 0.1568\n",
      "07-12 06:31 root         INFO     Training accuracy  : 0.8736, f1: 0.8733\n",
      "07-12 06:31 root         INFO     Validation accuracy: 0.8669, f1: 0.8670\n",
      "07-12 06:31 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 06:31 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.5376570151162119, 'input_dim': 300, 'lr': 0.0002511114194843569}\n",
      "07-12 06:31 root         INFO     Writer: runs/Jul12_06-31-23_lyalin_RNNBinaryClassifier_lr3_dropout0.5376570151162119_noise_level0.0000hyperparameters_search_random\n",
      "07-12 06:32 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-12 06:32 root         INFO     In-batch loss      : 0.6887\n",
      "07-12 06:32 root         INFO     Training accuracy  : 0.5261, f1: 0.2975\n",
      "07-12 06:32 root         INFO     Validation accuracy: 0.5272, f1: 0.3039\n",
      "07-12 06:33 root         INFO     Epoch 2. Global step 1995. T=2.49min\n",
      "07-12 06:33 root         INFO     In-batch loss      : 0.4424\n",
      "07-12 06:33 root         INFO     Training accuracy  : 0.6785, f1: 0.6519\n",
      "07-12 06:33 root         INFO     Validation accuracy: 0.6813, f1: 0.6573\n",
      "07-12 06:35 root         INFO     Epoch 4. Global step 3325. T=4.03min\n",
      "07-12 06:35 root         INFO     In-batch loss      : 0.2918\n",
      "07-12 06:35 root         INFO     Training accuracy  : 0.7727, f1: 0.7716\n",
      "07-12 06:35 root         INFO     Validation accuracy: 0.7755, f1: 0.7737\n",
      "07-12 06:36 root         INFO     Epoch 6. Global step 4655. T=5.58min\n",
      "07-12 06:36 root         INFO     In-batch loss      : 0.1735\n",
      "07-12 06:36 root         INFO     Training accuracy  : 0.8032, f1: 0.7990\n",
      "07-12 06:36 root         INFO     Validation accuracy: 0.8048, f1: 0.7995\n",
      "07-12 06:38 root         INFO     Epoch 8. Global step 5985. T=7.12min\n",
      "07-12 06:38 root         INFO     In-batch loss      : 0.3192\n",
      "07-12 06:38 root         INFO     Training accuracy  : 0.8223, f1: 0.8207\n",
      "07-12 06:38 root         INFO     Validation accuracy: 0.8245, f1: 0.8228\n",
      "07-12 06:40 root         INFO     Epoch 10. Global step 7315. T=8.67min\n",
      "07-12 06:40 root         INFO     In-batch loss      : 0.0625\n",
      "07-12 06:40 root         INFO     Training accuracy  : 0.8373, f1: 0.8374\n",
      "07-12 06:40 root         INFO     Validation accuracy: 0.8395, f1: 0.8393\n",
      "07-12 06:41 root         INFO     Epoch 12. Global step 8645. T=10.21min\n",
      "07-12 06:41 root         INFO     In-batch loss      : 0.1094\n",
      "07-12 06:41 root         INFO     Training accuracy  : 0.8487, f1: 0.8474\n",
      "07-12 06:41 root         INFO     Validation accuracy: 0.8483, f1: 0.8472\n",
      "07-12 06:43 root         INFO     Epoch 14. Global step 9975. T=11.76min\n",
      "07-12 06:43 root         INFO     In-batch loss      : 0.0725\n",
      "07-12 06:43 root         INFO     Training accuracy  : 0.8577, f1: 0.8567\n",
      "07-12 06:43 root         INFO     Validation accuracy: 0.8576, f1: 0.8569\n",
      "07-12 06:44 root         INFO     Epoch 16. Global step 11305. T=13.29min\n",
      "07-12 06:44 root         INFO     In-batch loss      : 0.0337\n",
      "07-12 06:44 root         INFO     Training accuracy  : 0.8630, f1: 0.8638\n",
      "07-12 06:44 root         INFO     Validation accuracy: 0.8624, f1: 0.8631\n",
      "07-12 06:46 root         INFO     Epoch 18. Global step 12635. T=14.83min\n",
      "07-12 06:46 root         INFO     In-batch loss      : 0.0906\n",
      "07-12 06:46 root         INFO     Training accuracy  : 0.8703, f1: 0.8707\n",
      "07-12 06:46 root         INFO     Validation accuracy: 0.8619, f1: 0.8619\n",
      "07-12 06:47 root         INFO     Epoch 19. Global step 13300. T=15.61min\n",
      "07-12 06:47 root         INFO     In-batch loss      : 0.1752\n",
      "07-12 06:47 root         INFO     Training accuracy  : 0.8723, f1: 0.8721\n",
      "07-12 06:47 root         INFO     Validation accuracy: 0.8616, f1: 0.8614\n",
      "07-12 06:47 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 06:47 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.8062083826559898, 'input_dim': 300, 'lr': 0.0005419094489770825}\n",
      "07-12 06:47 root         INFO     Writer: runs/Jul12_06-47-04_lyalin_RNNBinaryClassifier_lr3_dropout0.8062083826559898_noise_level0.0000hyperparameters_search_random\n",
      "07-12 06:47 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 06:47 root         INFO     In-batch loss      : 0.7771\n",
      "07-12 06:47 root         INFO     Training accuracy  : 0.5122, f1: 0.6377\n",
      "07-12 06:47 root         INFO     Validation accuracy: 0.5027, f1: 0.6287\n",
      "07-12 06:49 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 06:49 root         INFO     In-batch loss      : 0.7231\n",
      "07-12 06:49 root         INFO     Training accuracy  : 0.5375, f1: 0.3326\n",
      "07-12 06:49 root         INFO     Validation accuracy: 0.5347, f1: 0.3291\n",
      "07-12 06:50 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 06:50 root         INFO     In-batch loss      : 0.4444\n",
      "07-12 06:50 root         INFO     Training accuracy  : 0.6946, f1: 0.6710\n",
      "07-12 06:50 root         INFO     Validation accuracy: 0.6861, f1: 0.6599\n",
      "07-12 06:52 root         INFO     Epoch 6. Global step 4655. T=5.38min\n",
      "07-12 06:52 root         INFO     In-batch loss      : 0.5976\n",
      "07-12 06:52 root         INFO     Training accuracy  : 0.7544, f1: 0.7435\n",
      "07-12 06:52 root         INFO     Validation accuracy: 0.7475, f1: 0.7358\n",
      "07-12 06:54 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-12 06:54 root         INFO     In-batch loss      : 0.2641\n",
      "07-12 06:54 root         INFO     Training accuracy  : 0.7957, f1: 0.7958\n",
      "07-12 06:54 root         INFO     Validation accuracy: 0.7955, f1: 0.7951\n",
      "07-12 06:55 root         INFO     Epoch 10. Global step 7315. T=8.47min\n",
      "07-12 06:55 root         INFO     In-batch loss      : 0.7150\n",
      "07-12 06:55 root         INFO     Training accuracy  : 0.8204, f1: 0.8231\n",
      "07-12 06:55 root         INFO     Validation accuracy: 0.8208, f1: 0.8228\n",
      "07-12 06:57 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-12 06:57 root         INFO     In-batch loss      : 0.1936\n",
      "07-12 06:57 root         INFO     Training accuracy  : 0.8384, f1: 0.8367\n",
      "07-12 06:57 root         INFO     Validation accuracy: 0.8397, f1: 0.8370\n",
      "07-12 06:58 root         INFO     Epoch 14. Global step 9975. T=11.55min\n",
      "07-12 06:58 root         INFO     In-batch loss      : 0.1942\n",
      "07-12 06:58 root         INFO     Training accuracy  : 0.8491, f1: 0.8489\n",
      "07-12 06:58 root         INFO     Validation accuracy: 0.8499, f1: 0.8489\n",
      "07-12 07:00 root         INFO     Epoch 16. Global step 11305. T=13.10min\n",
      "07-12 07:00 root         INFO     In-batch loss      : 0.1160\n",
      "07-12 07:00 root         INFO     Training accuracy  : 0.8576, f1: 0.8570\n",
      "07-12 07:00 root         INFO     Validation accuracy: 0.8571, f1: 0.8558\n",
      "07-12 07:01 root         INFO     Epoch 18. Global step 12635. T=14.64min\n",
      "07-12 07:01 root         INFO     In-batch loss      : 0.4146\n",
      "07-12 07:01 root         INFO     Training accuracy  : 0.8645, f1: 0.8650\n",
      "07-12 07:01 root         INFO     Validation accuracy: 0.8621, f1: 0.8619\n",
      "07-12 07:02 root         INFO     Epoch 19. Global step 13300. T=15.41min\n",
      "07-12 07:02 root         INFO     In-batch loss      : 0.2209\n",
      "07-12 07:02 root         INFO     Training accuracy  : 0.8680, f1: 0.8673\n",
      "07-12 07:02 root         INFO     Validation accuracy: 0.8600, f1: 0.8588\n",
      "07-12 07:02 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 07:02 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.9850308043284507, 'input_dim': 300, 'lr': 0.0001691092386819244}\n",
      "07-12 07:02 root         INFO     Writer: runs/Jul12_07-02-33_lyalin_RNNBinaryClassifier_lr3_dropout0.9850308043284507_noise_level0.0000hyperparameters_search_random\n",
      "07-12 07:03 root         INFO     Epoch 0. Global step 665. T=0.95min\n",
      "07-12 07:03 root         INFO     In-batch loss      : 0.6910\n",
      "07-12 07:03 root         INFO     Training accuracy  : 0.5265, f1: 0.3608\n",
      "07-12 07:03 root         INFO     Validation accuracy: 0.5323, f1: 0.3709\n",
      "07-12 07:05 root         INFO     Epoch 2. Global step 1995. T=2.88min\n",
      "07-12 07:05 root         INFO     In-batch loss      : 0.4624\n",
      "07-12 07:05 root         INFO     Training accuracy  : 0.6994, f1: 0.6773\n",
      "07-12 07:05 root         INFO     Validation accuracy: 0.7035, f1: 0.6828\n",
      "07-12 07:07 root         INFO     Epoch 4. Global step 3325. T=4.83min\n",
      "07-12 07:07 root         INFO     In-batch loss      : 0.3312\n",
      "07-12 07:07 root         INFO     Training accuracy  : 0.7739, f1: 0.7687\n",
      "07-12 07:07 root         INFO     Validation accuracy: 0.7728, f1: 0.7662\n",
      "07-12 07:09 root         INFO     Epoch 6. Global step 4655. T=6.76min\n",
      "07-12 07:09 root         INFO     In-batch loss      : 0.8642\n",
      "07-12 07:09 root         INFO     Training accuracy  : 0.7868, f1: 0.7839\n",
      "07-12 07:09 root         INFO     Validation accuracy: 0.7853, f1: 0.7805\n",
      "07-12 07:11 root         INFO     Epoch 8. Global step 5985. T=8.69min\n",
      "07-12 07:11 root         INFO     In-batch loss      : 0.3614\n",
      "07-12 07:11 root         INFO     Training accuracy  : 0.8006, f1: 0.8052\n",
      "07-12 07:11 root         INFO     Validation accuracy: 0.8117, f1: 0.8148\n",
      "07-12 07:13 root         INFO     Epoch 10. Global step 7315. T=10.62min\n",
      "07-12 07:13 root         INFO     In-batch loss      : 0.0645\n",
      "07-12 07:13 root         INFO     Training accuracy  : 0.8204, f1: 0.8198\n",
      "07-12 07:13 root         INFO     Validation accuracy: 0.8307, f1: 0.8289\n",
      "07-12 07:15 root         INFO     Epoch 12. Global step 8645. T=12.59min\n",
      "07-12 07:15 root         INFO     In-batch loss      : 0.5573\n",
      "07-12 07:15 root         INFO     Training accuracy  : 0.8399, f1: 0.8371\n",
      "07-12 07:15 root         INFO     Validation accuracy: 0.8395, f1: 0.8361\n",
      "07-12 07:17 root         INFO     Epoch 14. Global step 9975. T=14.52min\n",
      "07-12 07:17 root         INFO     In-batch loss      : 0.3064\n",
      "07-12 07:17 root         INFO     Training accuracy  : 0.8508, f1: 0.8506\n",
      "07-12 07:17 root         INFO     Validation accuracy: 0.8520, f1: 0.8508\n",
      "07-12 07:19 root         INFO     Epoch 16. Global step 11305. T=16.47min\n",
      "07-12 07:19 root         INFO     In-batch loss      : 0.3256\n",
      "07-12 07:19 root         INFO     Training accuracy  : 0.8616, f1: 0.8612\n",
      "07-12 07:19 root         INFO     Validation accuracy: 0.8496, f1: 0.8485\n",
      "07-12 07:20 root         INFO     Epoch 18. Global step 12635. T=18.39min\n",
      "07-12 07:20 root         INFO     In-batch loss      : 0.0926\n",
      "07-12 07:20 root         INFO     Training accuracy  : 0.8695, f1: 0.8680\n",
      "07-12 07:20 root         INFO     Validation accuracy: 0.8523, f1: 0.8500\n",
      "07-12 07:21 root         INFO     Epoch 19. Global step 13300. T=19.36min\n",
      "07-12 07:21 root         INFO     In-batch loss      : 0.0979\n",
      "07-12 07:21 root         INFO     Training accuracy  : 0.8721, f1: 0.8732\n",
      "07-12 07:21 root         INFO     Validation accuracy: 0.8589, f1: 0.8588\n",
      "07-12 07:21 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 07:21 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.1942346411761794, 'input_dim': 300, 'lr': 0.00010604529120425783}\n",
      "07-12 07:21 root         INFO     Writer: runs/Jul12_07-21-58_lyalin_RNNBinaryClassifier_lr3_dropout0.1942346411761794_noise_level0.0000hyperparameters_search_random\n",
      "07-12 07:22 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 07:22 root         INFO     In-batch loss      : 0.6772\n",
      "07-12 07:22 root         INFO     Training accuracy  : 0.4973, f1: 0.6273\n",
      "07-12 07:22 root         INFO     Validation accuracy: 0.4968, f1: 0.6249\n",
      "07-12 07:24 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 07:24 root         INFO     In-batch loss      : 0.6787\n",
      "07-12 07:24 root         INFO     Training accuracy  : 0.5084, f1: 0.6402\n",
      "07-12 07:24 root         INFO     Validation accuracy: 0.5048, f1: 0.6367\n",
      "07-12 07:25 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 07:25 root         INFO     In-batch loss      : 0.6745\n",
      "07-12 07:25 root         INFO     Training accuracy  : 0.5207, f1: 0.3406\n",
      "07-12 07:25 root         INFO     Validation accuracy: 0.5232, f1: 0.3503\n",
      "07-12 07:27 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-12 07:27 root         INFO     In-batch loss      : 0.6741\n",
      "07-12 07:27 root         INFO     Training accuracy  : 0.5281, f1: 0.3214\n",
      "07-12 07:27 root         INFO     Validation accuracy: 0.5323, f1: 0.3341\n",
      "07-12 07:28 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 07:28 root         INFO     In-batch loss      : 0.7216\n",
      "07-12 07:28 root         INFO     Training accuracy  : 0.5330, f1: 0.3234\n",
      "07-12 07:28 root         INFO     Validation accuracy: 0.5376, f1: 0.3326\n",
      "07-12 07:30 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-12 07:30 root         INFO     In-batch loss      : 0.6087\n",
      "07-12 07:30 root         INFO     Training accuracy  : 0.5356, f1: 0.3447\n",
      "07-12 07:30 root         INFO     Validation accuracy: 0.5421, f1: 0.3562\n",
      "07-12 07:31 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-12 07:31 root         INFO     In-batch loss      : 0.7327\n",
      "07-12 07:31 root         INFO     Training accuracy  : 0.5555, f1: 0.3631\n",
      "07-12 07:31 root         INFO     Validation accuracy: 0.5621, f1: 0.3733\n",
      "07-12 07:33 root         INFO     Epoch 14. Global step 9975. T=11.57min\n",
      "07-12 07:33 root         INFO     In-batch loss      : 0.6303\n",
      "07-12 07:33 root         INFO     Training accuracy  : 0.6040, f1: 0.4832\n",
      "07-12 07:33 root         INFO     Validation accuracy: 0.6109, f1: 0.4964\n",
      "07-12 07:35 root         INFO     Epoch 16. Global step 11305. T=13.11min\n",
      "07-12 07:35 root         INFO     In-batch loss      : 0.5113\n",
      "07-12 07:35 root         INFO     Training accuracy  : 0.6175, f1: 0.5096\n",
      "07-12 07:35 root         INFO     Validation accuracy: 0.6317, f1: 0.5330\n",
      "07-12 07:36 root         INFO     Epoch 18. Global step 12635. T=14.65min\n",
      "07-12 07:36 root         INFO     In-batch loss      : 0.6711\n",
      "07-12 07:36 root         INFO     Training accuracy  : 0.7344, f1: 0.7361\n",
      "07-12 07:36 root         INFO     Validation accuracy: 0.7315, f1: 0.7335\n",
      "07-12 07:37 root         INFO     Epoch 19. Global step 13300. T=15.43min\n",
      "07-12 07:37 root         INFO     In-batch loss      : 1.2294\n",
      "07-12 07:37 root         INFO     Training accuracy  : 0.7501, f1: 0.7574\n",
      "07-12 07:37 root         INFO     Validation accuracy: 0.7483, f1: 0.7562\n",
      "07-12 07:37 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 07:37 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.24972645188054965, 'input_dim': 300, 'lr': 0.0005208904353132065}\n",
      "07-12 07:37 root         INFO     Writer: runs/Jul12_07-37-28_lyalin_RNNBinaryClassifier_lr3_dropout0.24972645188054965_noise_level0.0000hyperparameters_search_random\n",
      "07-12 07:38 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-12 07:38 root         INFO     In-batch loss      : 0.7932\n",
      "07-12 07:38 root         INFO     Training accuracy  : 0.5291, f1: 0.2527\n",
      "07-12 07:38 root         INFO     Validation accuracy: 0.5381, f1: 0.2686\n",
      "07-12 07:39 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 07:39 root         INFO     In-batch loss      : 0.3158\n",
      "07-12 07:39 root         INFO     Training accuracy  : 0.7405, f1: 0.7333\n",
      "07-12 07:39 root         INFO     Validation accuracy: 0.7368, f1: 0.7291\n",
      "07-12 07:41 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 07:41 root         INFO     In-batch loss      : 1.2578\n",
      "07-12 07:41 root         INFO     Training accuracy  : 0.8256, f1: 0.8272\n",
      "07-12 07:41 root         INFO     Validation accuracy: 0.8331, f1: 0.8333\n",
      "07-12 07:42 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 07:42 root         INFO     In-batch loss      : 0.0554\n",
      "07-12 07:42 root         INFO     Training accuracy  : 0.8584, f1: 0.8561\n",
      "07-12 07:42 root         INFO     Validation accuracy: 0.8507, f1: 0.8471\n",
      "07-12 07:44 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 07:44 root         INFO     In-batch loss      : 0.4146\n",
      "07-12 07:44 root         INFO     Training accuracy  : 0.8768, f1: 0.8761\n",
      "07-12 07:44 root         INFO     Validation accuracy: 0.8579, f1: 0.8564\n",
      "07-12 07:45 root         INFO     Epoch 10. Global step 7315. T=8.52min\n",
      "07-12 07:45 root         INFO     In-batch loss      : 0.2390\n",
      "07-12 07:45 root         INFO     Training accuracy  : 0.8893, f1: 0.8903\n",
      "07-12 07:45 root         INFO     Validation accuracy: 0.8648, f1: 0.8653\n",
      "07-12 07:47 root         INFO     Epoch 12. Global step 8645. T=10.08min\n",
      "07-12 07:47 root         INFO     In-batch loss      : 0.2143\n",
      "07-12 07:47 root         INFO     Training accuracy  : 0.9036, f1: 0.9032\n",
      "07-12 07:47 root         INFO     Validation accuracy: 0.8675, f1: 0.8661\n",
      "07-12 07:49 root         INFO     Epoch 14. Global step 9975. T=11.62min\n",
      "07-12 07:49 root         INFO     In-batch loss      : 0.0389\n",
      "07-12 07:49 root         INFO     Training accuracy  : 0.9188, f1: 0.9186\n",
      "07-12 07:49 root         INFO     Validation accuracy: 0.8723, f1: 0.8713\n",
      "07-12 07:50 root         INFO     Epoch 16. Global step 11305. T=13.17min\n",
      "07-12 07:50 root         INFO     In-batch loss      : 0.0020\n",
      "07-12 07:50 root         INFO     Training accuracy  : 0.9334, f1: 0.9330\n",
      "07-12 07:50 root         INFO     Validation accuracy: 0.8640, f1: 0.8624\n",
      "07-12 07:52 root         INFO     Epoch 18. Global step 12635. T=14.72min\n",
      "07-12 07:52 root         INFO     In-batch loss      : 0.4938\n",
      "07-12 07:52 root         INFO     Training accuracy  : 0.9510, f1: 0.9507\n",
      "07-12 07:52 root         INFO     Validation accuracy: 0.8645, f1: 0.8637\n",
      "07-12 07:52 root         INFO     Epoch 19. Global step 13300. T=15.50min\n",
      "07-12 07:52 root         INFO     In-batch loss      : 0.2967\n",
      "07-12 07:52 root         INFO     Training accuracy  : 0.9577, f1: 0.9575\n",
      "07-12 07:52 root         INFO     Validation accuracy: 0.8653, f1: 0.8641\n",
      "07-12 07:52 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 07:53 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.9950895028815437, 'input_dim': 300, 'lr': 0.00014051527199778797}\n",
      "07-12 07:53 root         INFO     Writer: runs/Jul12_07-53-02_lyalin_RNNBinaryClassifier_lr3_dropout0.9950895028815437_noise_level0.0000hyperparameters_search_random\n",
      "07-12 07:53 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-12 07:53 root         INFO     In-batch loss      : 0.8466\n",
      "07-12 07:53 root         INFO     Training accuracy  : 0.5080, f1: 0.3926\n",
      "07-12 07:53 root         INFO     Validation accuracy: 0.5021, f1: 0.3921\n",
      "07-12 07:55 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 07:55 root         INFO     In-batch loss      : 0.6793\n",
      "07-12 07:55 root         INFO     Training accuracy  : 0.5052, f1: 0.6592\n",
      "07-12 07:55 root         INFO     Validation accuracy: 0.4992, f1: 0.6543\n",
      "07-12 07:56 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 07:56 root         INFO     In-batch loss      : 0.8199\n",
      "07-12 07:56 root         INFO     Training accuracy  : 0.5208, f1: 0.3205\n",
      "07-12 07:56 root         INFO     Validation accuracy: 0.5237, f1: 0.3306\n",
      "07-12 07:58 root         INFO     Epoch 6. Global step 4655. T=5.40min\n",
      "07-12 07:58 root         INFO     In-batch loss      : 0.6589\n",
      "07-12 07:58 root         INFO     Training accuracy  : 0.5235, f1: 0.3491\n",
      "07-12 07:58 root         INFO     Validation accuracy: 0.5248, f1: 0.3613\n",
      "07-12 07:59 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 07:59 root         INFO     In-batch loss      : 0.7093\n",
      "07-12 07:59 root         INFO     Training accuracy  : 0.5240, f1: 0.2940\n",
      "07-12 07:59 root         INFO     Validation accuracy: 0.5307, f1: 0.3076\n",
      "07-12 08:01 root         INFO     Epoch 10. Global step 7315. T=8.51min\n",
      "07-12 08:01 root         INFO     In-batch loss      : 0.6580\n",
      "07-12 08:01 root         INFO     Training accuracy  : 0.5228, f1: 0.6524\n",
      "07-12 08:01 root         INFO     Validation accuracy: 0.5240, f1: 0.6525\n",
      "07-12 08:03 root         INFO     Epoch 12. Global step 8645. T=10.05min\n",
      "07-12 08:03 root         INFO     In-batch loss      : 0.6966\n",
      "07-12 08:03 root         INFO     Training accuracy  : 0.5301, f1: 0.3445\n",
      "07-12 08:03 root         INFO     Validation accuracy: 0.5352, f1: 0.3585\n",
      "07-12 08:04 root         INFO     Epoch 14. Global step 9975. T=11.60min\n",
      "07-12 08:04 root         INFO     In-batch loss      : 0.6987\n",
      "07-12 08:04 root         INFO     Training accuracy  : 0.5298, f1: 0.6380\n",
      "07-12 08:04 root         INFO     Validation accuracy: 0.5291, f1: 0.6365\n",
      "07-12 08:06 root         INFO     Epoch 16. Global step 11305. T=13.15min\n",
      "07-12 08:06 root         INFO     In-batch loss      : 0.6466\n",
      "07-12 08:06 root         INFO     Training accuracy  : 0.6556, f1: 0.6605\n",
      "07-12 08:06 root         INFO     Validation accuracy: 0.6483, f1: 0.6539\n",
      "07-12 08:07 root         INFO     Epoch 18. Global step 12635. T=14.69min\n",
      "07-12 08:07 root         INFO     In-batch loss      : 0.6932\n",
      "07-12 08:07 root         INFO     Training accuracy  : 0.7077, f1: 0.7127\n",
      "07-12 08:07 root         INFO     Validation accuracy: 0.7016, f1: 0.7061\n",
      "07-12 08:08 root         INFO     Epoch 19. Global step 13300. T=15.46min\n",
      "07-12 08:08 root         INFO     In-batch loss      : 1.0858\n",
      "07-12 08:08 root         INFO     Training accuracy  : 0.7256, f1: 0.7018\n",
      "07-12 08:08 root         INFO     Validation accuracy: 0.7197, f1: 0.6937\n",
      "07-12 08:08 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 08:08 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.18721759121002995, 'input_dim': 300, 'lr': 0.00027693456688590416}\n",
      "07-12 08:08 root         INFO     Writer: runs/Jul12_08-08-34_lyalin_RNNBinaryClassifier_lr3_dropout0.18721759121002995_noise_level0.0000hyperparameters_search_random\n",
      "07-12 08:09 root         INFO     Epoch 0. Global step 665. T=0.80min\n",
      "07-12 08:09 root         INFO     In-batch loss      : 0.7388\n",
      "07-12 08:09 root         INFO     Training accuracy  : 0.7330, f1: 0.7372\n",
      "07-12 08:09 root         INFO     Validation accuracy: 0.7293, f1: 0.7313\n",
      "07-12 08:11 root         INFO     Epoch 2. Global step 1995. T=2.46min\n",
      "07-12 08:11 root         INFO     In-batch loss      : 0.4215\n",
      "07-12 08:11 root         INFO     Training accuracy  : 0.7814, f1: 0.7815\n",
      "07-12 08:11 root         INFO     Validation accuracy: 0.7832, f1: 0.7821\n",
      "07-12 08:12 root         INFO     Epoch 4. Global step 3325. T=4.06min\n",
      "07-12 08:12 root         INFO     In-batch loss      : 0.9931\n",
      "07-12 08:12 root         INFO     Training accuracy  : 0.8108, f1: 0.8119\n",
      "07-12 08:12 root         INFO     Validation accuracy: 0.8200, f1: 0.8206\n",
      "07-12 08:14 root         INFO     Epoch 6. Global step 4655. T=5.67min\n",
      "07-12 08:14 root         INFO     In-batch loss      : 0.3706\n",
      "07-12 08:14 root         INFO     Training accuracy  : 0.8443, f1: 0.8401\n",
      "07-12 08:14 root         INFO     Validation accuracy: 0.8427, f1: 0.8376\n",
      "07-12 08:15 root         INFO     Epoch 8. Global step 5985. T=7.29min\n",
      "07-12 08:15 root         INFO     In-batch loss      : 0.5228\n",
      "07-12 08:15 root         INFO     Training accuracy  : 0.8624, f1: 0.8628\n",
      "07-12 08:15 root         INFO     Validation accuracy: 0.8552, f1: 0.8544\n",
      "07-12 08:17 root         INFO     Epoch 10. Global step 7315. T=8.89min\n",
      "07-12 08:17 root         INFO     In-batch loss      : 0.1495\n",
      "07-12 08:17 root         INFO     Training accuracy  : 0.8762, f1: 0.8766\n",
      "07-12 08:17 root         INFO     Validation accuracy: 0.8611, f1: 0.8607\n",
      "07-12 08:19 root         INFO     Epoch 12. Global step 8645. T=10.50min\n",
      "07-12 08:19 root         INFO     In-batch loss      : 0.1061\n",
      "07-12 08:19 root         INFO     Training accuracy  : 0.8862, f1: 0.8858\n",
      "07-12 08:19 root         INFO     Validation accuracy: 0.8701, f1: 0.8688\n",
      "07-12 08:20 root         INFO     Epoch 14. Global step 9975. T=12.16min\n",
      "07-12 08:20 root         INFO     In-batch loss      : 0.0127\n",
      "07-12 08:20 root         INFO     Training accuracy  : 0.8977, f1: 0.8961\n",
      "07-12 08:20 root         INFO     Validation accuracy: 0.8683, f1: 0.8661\n",
      "07-12 08:22 root         INFO     Epoch 16. Global step 11305. T=13.79min\n",
      "07-12 08:22 root         INFO     In-batch loss      : 0.0057\n",
      "07-12 08:22 root         INFO     Training accuracy  : 0.9096, f1: 0.9090\n",
      "07-12 08:22 root         INFO     Validation accuracy: 0.8672, f1: 0.8656\n",
      "07-12 08:24 root         INFO     Epoch 18. Global step 12635. T=15.42min\n",
      "07-12 08:24 root         INFO     In-batch loss      : 0.0311\n",
      "07-12 08:24 root         INFO     Training accuracy  : 0.9226, f1: 0.9222\n",
      "07-12 08:24 root         INFO     Validation accuracy: 0.8683, f1: 0.8674\n",
      "07-12 08:24 root         INFO     Epoch 19. Global step 13300. T=16.22min\n",
      "07-12 08:24 root         INFO     In-batch loss      : 0.0265\n",
      "07-12 08:24 root         INFO     Training accuracy  : 0.9289, f1: 0.9286\n",
      "07-12 08:24 root         INFO     Validation accuracy: 0.8669, f1: 0.8665\n",
      "07-12 08:24 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 08:24 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.18866356612168045, 'input_dim': 300, 'lr': 0.00019521053297848992}\n",
      "07-12 08:24 root         INFO     Writer: runs/Jul12_08-24-52_lyalin_RNNBinaryClassifier_lr3_dropout0.18866356612168045_noise_level0.0000hyperparameters_search_random\n",
      "07-12 08:25 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 08:25 root         INFO     In-batch loss      : 0.7526\n",
      "07-12 08:25 root         INFO     Training accuracy  : 0.5191, f1: 0.3400\n",
      "07-12 08:25 root         INFO     Validation accuracy: 0.5221, f1: 0.3545\n",
      "07-12 08:27 root         INFO     Epoch 2. Global step 1995. T=2.30min\n",
      "07-12 08:27 root         INFO     In-batch loss      : 0.7171\n",
      "07-12 08:27 root         INFO     Training accuracy  : 0.5318, f1: 0.6507\n",
      "07-12 08:27 root         INFO     Validation accuracy: 0.5296, f1: 0.6485\n",
      "07-12 08:28 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 08:28 root         INFO     In-batch loss      : 0.3216\n",
      "07-12 08:28 root         INFO     Training accuracy  : 0.7176, f1: 0.6971\n",
      "07-12 08:28 root         INFO     Validation accuracy: 0.7229, f1: 0.7015\n",
      "07-12 08:30 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 08:30 root         INFO     In-batch loss      : 0.2069\n",
      "07-12 08:30 root         INFO     Training accuracy  : 0.7729, f1: 0.7667\n",
      "07-12 08:30 root         INFO     Validation accuracy: 0.7755, f1: 0.7680\n",
      "07-12 08:31 root         INFO     Epoch 8. Global step 5985. T=6.92min\n",
      "07-12 08:31 root         INFO     In-batch loss      : 0.9361\n",
      "07-12 08:31 root         INFO     Training accuracy  : 0.7959, f1: 0.7943\n",
      "07-12 08:31 root         INFO     Validation accuracy: 0.8021, f1: 0.7990\n",
      "07-12 08:33 root         INFO     Epoch 10. Global step 7315. T=8.47min\n",
      "07-12 08:33 root         INFO     In-batch loss      : 0.0844\n",
      "07-12 08:33 root         INFO     Training accuracy  : 0.8123, f1: 0.8090\n",
      "07-12 08:33 root         INFO     Validation accuracy: 0.8232, f1: 0.8183\n",
      "07-12 08:34 root         INFO     Epoch 12. Global step 8645. T=10.01min\n",
      "07-12 08:34 root         INFO     In-batch loss      : 0.2681\n",
      "07-12 08:34 root         INFO     Training accuracy  : 0.8218, f1: 0.8199\n",
      "07-12 08:34 root         INFO     Validation accuracy: 0.8355, f1: 0.8327\n",
      "07-12 08:36 root         INFO     Epoch 14. Global step 9975. T=11.58min\n",
      "07-12 08:36 root         INFO     In-batch loss      : 1.2720\n",
      "07-12 08:36 root         INFO     Training accuracy  : 0.8313, f1: 0.8322\n",
      "07-12 08:36 root         INFO     Validation accuracy: 0.8429, f1: 0.8428\n",
      "07-12 08:37 root         INFO     Epoch 16. Global step 11305. T=13.12min\n",
      "07-12 08:37 root         INFO     In-batch loss      : 1.5112\n",
      "07-12 08:37 root         INFO     Training accuracy  : 0.8389, f1: 0.8427\n",
      "07-12 08:37 root         INFO     Validation accuracy: 0.8448, f1: 0.8484\n",
      "07-12 08:39 root         INFO     Epoch 18. Global step 12635. T=14.66min\n",
      "07-12 08:39 root         INFO     In-batch loss      : 0.2578\n",
      "07-12 08:39 root         INFO     Training accuracy  : 0.8459, f1: 0.8407\n",
      "07-12 08:39 root         INFO     Validation accuracy: 0.8477, f1: 0.8425\n",
      "07-12 08:40 root         INFO     Epoch 19. Global step 13300. T=15.43min\n",
      "07-12 08:40 root         INFO     In-batch loss      : 0.8832\n",
      "07-12 08:40 root         INFO     Training accuracy  : 0.8517, f1: 0.8522\n",
      "07-12 08:40 root         INFO     Validation accuracy: 0.8512, f1: 0.8514\n",
      "07-12 08:40 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 08:40 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.28116941370408083, 'input_dim': 300, 'lr': 0.0003636276116835225}\n",
      "07-12 08:40 root         INFO     Writer: runs/Jul12_08-40-22_lyalin_RNNBinaryClassifier_lr3_dropout0.28116941370408083_noise_level0.0000hyperparameters_search_random\n",
      "07-12 08:41 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-12 08:41 root         INFO     In-batch loss      : 0.6868\n",
      "07-12 08:41 root         INFO     Training accuracy  : 0.5324, f1: 0.3406\n",
      "07-12 08:41 root         INFO     Validation accuracy: 0.5384, f1: 0.3500\n",
      "07-12 08:42 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 08:42 root         INFO     In-batch loss      : 0.9282\n",
      "07-12 08:42 root         INFO     Training accuracy  : 0.7458, f1: 0.7374\n",
      "07-12 08:42 root         INFO     Validation accuracy: 0.7451, f1: 0.7387\n",
      "07-12 08:44 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 08:44 root         INFO     In-batch loss      : 0.8982\n",
      "07-12 08:44 root         INFO     Training accuracy  : 0.7955, f1: 0.7956\n",
      "07-12 08:44 root         INFO     Validation accuracy: 0.8011, f1: 0.8012\n",
      "07-12 08:45 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 08:45 root         INFO     In-batch loss      : 0.8047\n",
      "07-12 08:45 root         INFO     Training accuracy  : 0.8245, f1: 0.8225\n",
      "07-12 08:45 root         INFO     Validation accuracy: 0.8301, f1: 0.8276\n",
      "07-12 08:47 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 08:47 root         INFO     In-batch loss      : 0.4772\n",
      "07-12 08:47 root         INFO     Training accuracy  : 0.8464, f1: 0.8444\n",
      "07-12 08:47 root         INFO     Validation accuracy: 0.8501, f1: 0.8479\n",
      "07-12 08:48 root         INFO     Epoch 10. Global step 7315. T=8.51min\n",
      "07-12 08:48 root         INFO     In-batch loss      : 1.2417\n",
      "07-12 08:48 root         INFO     Training accuracy  : 0.8616, f1: 0.8613\n",
      "07-12 08:48 root         INFO     Validation accuracy: 0.8608, f1: 0.8606\n",
      "07-12 08:50 root         INFO     Epoch 12. Global step 8645. T=10.04min\n",
      "07-12 08:50 root         INFO     In-batch loss      : 0.7372\n",
      "07-12 08:50 root         INFO     Training accuracy  : 0.8711, f1: 0.8703\n",
      "07-12 08:50 root         INFO     Validation accuracy: 0.8637, f1: 0.8630\n",
      "07-12 08:51 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 08:51 root         INFO     In-batch loss      : 0.0573\n",
      "07-12 08:51 root         INFO     Training accuracy  : 0.8784, f1: 0.8794\n",
      "07-12 08:51 root         INFO     Validation accuracy: 0.8643, f1: 0.8651\n",
      "07-12 08:53 root         INFO     Epoch 16. Global step 11305. T=13.13min\n",
      "07-12 08:53 root         INFO     In-batch loss      : 0.1197\n",
      "07-12 08:53 root         INFO     Training accuracy  : 0.8870, f1: 0.8871\n",
      "07-12 08:53 root         INFO     Validation accuracy: 0.8629, f1: 0.8628\n",
      "07-12 08:55 root         INFO     Epoch 18. Global step 12635. T=14.68min\n",
      "07-12 08:55 root         INFO     In-batch loss      : 0.3885\n",
      "07-12 08:55 root         INFO     Training accuracy  : 0.8961, f1: 0.8960\n",
      "07-12 08:55 root         INFO     Validation accuracy: 0.8683, f1: 0.8681\n",
      "07-12 08:55 root         INFO     Epoch 19. Global step 13300. T=15.45min\n",
      "07-12 08:55 root         INFO     In-batch loss      : 0.0087\n",
      "07-12 08:55 root         INFO     Training accuracy  : 0.8994, f1: 0.8996\n",
      "07-12 08:55 root         INFO     Validation accuracy: 0.8656, f1: 0.8657\n",
      "07-12 08:55 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 08:55 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.16050577201372945, 'input_dim': 300, 'lr': 0.00027977586957309117}\n",
      "07-12 08:55 root         INFO     Writer: runs/Jul12_08-55-53_lyalin_RNNBinaryClassifier_lr3_dropout0.16050577201372945_noise_level0.0000hyperparameters_search_random\n",
      "07-12 08:56 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 08:56 root         INFO     In-batch loss      : 0.9064\n",
      "07-12 08:56 root         INFO     Training accuracy  : 0.6123, f1: 0.6778\n",
      "07-12 08:56 root         INFO     Validation accuracy: 0.6069, f1: 0.6711\n",
      "07-12 08:58 root         INFO     Epoch 2. Global step 1995. T=2.33min\n",
      "07-12 08:58 root         INFO     In-batch loss      : 0.2267\n",
      "07-12 08:58 root         INFO     Training accuracy  : 0.7541, f1: 0.7531\n",
      "07-12 08:58 root         INFO     Validation accuracy: 0.7520, f1: 0.7500\n",
      "07-12 08:59 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 08:59 root         INFO     In-batch loss      : 0.1729\n",
      "07-12 08:59 root         INFO     Training accuracy  : 0.7842, f1: 0.7859\n",
      "07-12 08:59 root         INFO     Validation accuracy: 0.7909, f1: 0.7931\n",
      "07-12 09:01 root         INFO     Epoch 6. Global step 4655. T=5.43min\n",
      "07-12 09:01 root         INFO     In-batch loss      : 0.7079\n",
      "07-12 09:01 root         INFO     Training accuracy  : 0.8127, f1: 0.8129\n",
      "07-12 09:01 root         INFO     Validation accuracy: 0.8237, f1: 0.8227\n",
      "07-12 09:02 root         INFO     Epoch 8. Global step 5985. T=6.99min\n",
      "07-12 09:02 root         INFO     In-batch loss      : 0.0483\n",
      "07-12 09:02 root         INFO     Training accuracy  : 0.8410, f1: 0.8406\n",
      "07-12 09:02 root         INFO     Validation accuracy: 0.8451, f1: 0.8441\n",
      "07-12 09:04 root         INFO     Epoch 10. Global step 7315. T=8.54min\n",
      "07-12 09:04 root         INFO     In-batch loss      : 0.2421\n",
      "07-12 09:04 root         INFO     Training accuracy  : 0.8572, f1: 0.8573\n",
      "07-12 09:04 root         INFO     Validation accuracy: 0.8560, f1: 0.8557\n",
      "07-12 09:05 root         INFO     Epoch 12. Global step 8645. T=10.09min\n",
      "07-12 09:05 root         INFO     In-batch loss      : 0.0798\n",
      "07-12 09:05 root         INFO     Training accuracy  : 0.8705, f1: 0.8697\n",
      "07-12 09:05 root         INFO     Validation accuracy: 0.8608, f1: 0.8588\n",
      "07-12 09:07 root         INFO     Epoch 14. Global step 9975. T=11.64min\n",
      "07-12 09:07 root         INFO     In-batch loss      : 0.0546\n",
      "07-12 09:07 root         INFO     Training accuracy  : 0.8769, f1: 0.8751\n",
      "07-12 09:07 root         INFO     Validation accuracy: 0.8613, f1: 0.8585\n",
      "07-12 09:09 root         INFO     Epoch 16. Global step 11305. T=13.19min\n",
      "07-12 09:09 root         INFO     In-batch loss      : 0.4252\n",
      "07-12 09:09 root         INFO     Training accuracy  : 0.8862, f1: 0.8866\n",
      "07-12 09:09 root         INFO     Validation accuracy: 0.8645, f1: 0.8645\n",
      "07-12 09:10 root         INFO     Epoch 18. Global step 12635. T=14.73min\n",
      "07-12 09:10 root         INFO     In-batch loss      : 0.1041\n",
      "07-12 09:10 root         INFO     Training accuracy  : 0.8952, f1: 0.8949\n",
      "07-12 09:10 root         INFO     Validation accuracy: 0.8653, f1: 0.8639\n",
      "07-12 09:11 root         INFO     Epoch 19. Global step 13300. T=15.51min\n",
      "07-12 09:11 root         INFO     In-batch loss      : 0.0388\n",
      "07-12 09:11 root         INFO     Training accuracy  : 0.8985, f1: 0.8986\n",
      "07-12 09:11 root         INFO     Validation accuracy: 0.8643, f1: 0.8635\n",
      "07-12 09:11 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 09:11 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.34956450721582843, 'input_dim': 300, 'lr': 0.000469169549535384}\n",
      "07-12 09:11 root         INFO     Writer: runs/Jul12_09-11-27_lyalin_RNNBinaryClassifier_lr3_dropout0.34956450721582843_noise_level0.0000hyperparameters_search_random\n",
      "07-12 09:12 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 09:12 root         INFO     In-batch loss      : 0.7696\n",
      "07-12 09:12 root         INFO     Training accuracy  : 0.5330, f1: 0.3363\n",
      "07-12 09:12 root         INFO     Validation accuracy: 0.5435, f1: 0.3525\n",
      "07-12 09:13 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 09:13 root         INFO     In-batch loss      : 0.7958\n",
      "07-12 09:13 root         INFO     Training accuracy  : 0.7135, f1: 0.6851\n",
      "07-12 09:13 root         INFO     Validation accuracy: 0.7128, f1: 0.6828\n",
      "07-12 09:15 root         INFO     Epoch 4. Global step 3325. T=3.87min\n",
      "07-12 09:15 root         INFO     In-batch loss      : 0.6981\n",
      "07-12 09:15 root         INFO     Training accuracy  : 0.7881, f1: 0.7902\n",
      "07-12 09:15 root         INFO     Validation accuracy: 0.7955, f1: 0.7974\n",
      "07-12 09:16 root         INFO     Epoch 6. Global step 4655. T=5.42min\n",
      "07-12 09:16 root         INFO     In-batch loss      : 0.2217\n",
      "07-12 09:16 root         INFO     Training accuracy  : 0.8304, f1: 0.8297\n",
      "07-12 09:16 root         INFO     Validation accuracy: 0.8413, f1: 0.8395\n",
      "07-12 09:18 root         INFO     Epoch 8. Global step 5985. T=6.97min\n",
      "07-12 09:18 root         INFO     In-batch loss      : 0.2966\n",
      "07-12 09:18 root         INFO     Training accuracy  : 0.8540, f1: 0.8549\n",
      "07-12 09:18 root         INFO     Validation accuracy: 0.8539, f1: 0.8540\n",
      "07-12 09:19 root         INFO     Epoch 10. Global step 7315. T=8.51min\n",
      "07-12 09:19 root         INFO     In-batch loss      : 0.0407\n",
      "07-12 09:19 root         INFO     Training accuracy  : 0.8660, f1: 0.8651\n",
      "07-12 09:19 root         INFO     Validation accuracy: 0.8581, f1: 0.8561\n",
      "07-12 09:21 root         INFO     Epoch 12. Global step 8645. T=10.06min\n",
      "07-12 09:21 root         INFO     In-batch loss      : 0.2710\n",
      "07-12 09:21 root         INFO     Training accuracy  : 0.8804, f1: 0.8793\n",
      "07-12 09:21 root         INFO     Validation accuracy: 0.8608, f1: 0.8588\n",
      "07-12 09:23 root         INFO     Epoch 14. Global step 9975. T=11.62min\n",
      "07-12 09:23 root         INFO     In-batch loss      : 0.0328\n",
      "07-12 09:23 root         INFO     Training accuracy  : 0.8901, f1: 0.8902\n",
      "07-12 09:23 root         INFO     Validation accuracy: 0.8629, f1: 0.8620\n",
      "07-12 09:24 root         INFO     Epoch 16. Global step 11305. T=13.16min\n",
      "07-12 09:24 root         INFO     In-batch loss      : 0.0210\n",
      "07-12 09:24 root         INFO     Training accuracy  : 0.9000, f1: 0.9002\n",
      "07-12 09:24 root         INFO     Validation accuracy: 0.8672, f1: 0.8665\n",
      "07-12 09:26 root         INFO     Epoch 18. Global step 12635. T=14.71min\n",
      "07-12 09:26 root         INFO     In-batch loss      : 0.2704\n",
      "07-12 09:26 root         INFO     Training accuracy  : 0.9072, f1: 0.9079\n",
      "07-12 09:26 root         INFO     Validation accuracy: 0.8667, f1: 0.8672\n",
      "07-12 09:26 root         INFO     Epoch 19. Global step 13300. T=15.49min\n",
      "07-12 09:26 root         INFO     In-batch loss      : 1.5168\n",
      "07-12 09:26 root         INFO     Training accuracy  : 0.9123, f1: 0.9123\n",
      "07-12 09:26 root         INFO     Validation accuracy: 0.8707, f1: 0.8697\n",
      "07-12 09:26 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 09:27 root         INFO     Parameters: {'hidden_dim': 1024, 'dropout': 0.23025964000426502, 'input_dim': 300, 'lr': 0.0004828619984093707}\n",
      "07-12 09:27 root         INFO     Writer: runs/Jul12_09-27-01_lyalin_RNNBinaryClassifier_lr3_dropout0.23025964000426502_noise_level0.0000hyperparameters_search_random\n",
      "07-12 09:27 root         INFO     Epoch 0. Global step 665. T=0.96min\n",
      "07-12 09:27 root         INFO     In-batch loss      : 0.6895\n",
      "07-12 09:27 root         INFO     Training accuracy  : 0.5585, f1: 0.3601\n",
      "07-12 09:27 root         INFO     Validation accuracy: 0.5680, f1: 0.3798\n",
      "07-12 09:29 root         INFO     Epoch 2. Global step 1995. T=2.90min\n",
      "07-12 09:29 root         INFO     In-batch loss      : 0.6315\n",
      "07-12 09:29 root         INFO     Training accuracy  : 0.5989, f1: 0.5962\n",
      "07-12 09:29 root         INFO     Validation accuracy: 0.5907, f1: 0.5859\n",
      "07-12 09:31 root         INFO     Epoch 4. Global step 3325. T=4.82min\n",
      "07-12 09:31 root         INFO     In-batch loss      : 0.4365\n",
      "07-12 09:31 root         INFO     Training accuracy  : 0.5817, f1: 0.6322\n",
      "07-12 09:31 root         INFO     Validation accuracy: 0.5853, f1: 0.6347\n",
      "07-12 09:33 root         INFO     Epoch 6. Global step 4655. T=6.76min\n",
      "07-12 09:33 root         INFO     In-batch loss      : 0.0698\n",
      "07-12 09:33 root         INFO     Training accuracy  : 0.8393, f1: 0.8390\n",
      "07-12 09:33 root         INFO     Validation accuracy: 0.8453, f1: 0.8437\n",
      "07-12 09:35 root         INFO     Epoch 8. Global step 5985. T=8.78min\n",
      "07-12 09:35 root         INFO     In-batch loss      : 0.0506\n",
      "07-12 09:35 root         INFO     Training accuracy  : 0.8577, f1: 0.8562\n",
      "07-12 09:35 root         INFO     Validation accuracy: 0.8485, f1: 0.8462\n",
      "07-12 09:37 root         INFO     Epoch 10. Global step 7315. T=10.71min\n",
      "07-12 09:37 root         INFO     In-batch loss      : 0.0780\n",
      "07-12 09:37 root         INFO     Training accuracy  : 0.8717, f1: 0.8701\n",
      "07-12 09:37 root         INFO     Validation accuracy: 0.8597, f1: 0.8570\n",
      "07-12 09:39 root         INFO     Epoch 12. Global step 8645. T=12.72min\n",
      "07-12 09:39 root         INFO     In-batch loss      : 0.0569\n",
      "07-12 09:39 root         INFO     Training accuracy  : 0.8939, f1: 0.8939\n",
      "07-12 09:39 root         INFO     Validation accuracy: 0.8640, f1: 0.8627\n",
      "07-12 09:41 root         INFO     Epoch 14. Global step 9975. T=14.65min\n",
      "07-12 09:41 root         INFO     In-batch loss      : 0.0623\n",
      "07-12 09:41 root         INFO     Training accuracy  : 0.9154, f1: 0.9154\n",
      "07-12 09:41 root         INFO     Validation accuracy: 0.8683, f1: 0.8669\n",
      "07-12 09:43 root         INFO     Epoch 16. Global step 11305. T=16.58min\n",
      "07-12 09:43 root         INFO     In-batch loss      : 0.0101\n",
      "07-12 09:43 root         INFO     Training accuracy  : 0.9424, f1: 0.9427\n",
      "07-12 09:43 root         INFO     Validation accuracy: 0.8693, f1: 0.8687\n",
      "07-12 09:45 root         INFO     Epoch 18. Global step 12635. T=18.51min\n",
      "07-12 09:45 root         INFO     In-batch loss      : 0.0086\n",
      "07-12 09:45 root         INFO     Training accuracy  : 0.9664, f1: 0.9662\n",
      "07-12 09:45 root         INFO     Validation accuracy: 0.8648, f1: 0.8630\n",
      "07-12 09:46 root         INFO     Epoch 19. Global step 13300. T=19.48min\n",
      "07-12 09:46 root         INFO     In-batch loss      : 0.0603\n",
      "07-12 09:46 root         INFO     Training accuracy  : 0.9757, f1: 0.9757\n",
      "07-12 09:46 root         INFO     Validation accuracy: 0.8643, f1: 0.8640\n",
      "07-12 09:46 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 09:46 root         INFO     Parameters: {'hidden_dim': 32, 'dropout': 0.7474640620886008, 'input_dim': 300, 'lr': 0.00020251524948872935}\n",
      "07-12 09:46 root         INFO     Writer: runs/Jul12_09-46-34_lyalin_RNNBinaryClassifier_lr3_dropout0.7474640620886008_noise_level0.0000hyperparameters_search_random\n",
      "07-12 09:47 root         INFO     Epoch 0. Global step 665. T=0.85min\n",
      "07-12 09:47 root         INFO     In-batch loss      : 0.8493\n",
      "07-12 09:47 root         INFO     Training accuracy  : 0.5046, f1: 0.6384\n",
      "07-12 09:47 root         INFO     Validation accuracy: 0.5011, f1: 0.6318\n",
      "07-12 09:49 root         INFO     Epoch 2. Global step 1995. T=2.60min\n",
      "07-12 09:49 root         INFO     In-batch loss      : 0.6577\n",
      "07-12 09:49 root         INFO     Training accuracy  : 0.5156, f1: 0.6443\n",
      "07-12 09:49 root         INFO     Validation accuracy: 0.5179, f1: 0.6425\n",
      "07-12 09:50 root         INFO     Epoch 4. Global step 3325. T=4.31min\n",
      "07-12 09:50 root         INFO     In-batch loss      : 0.6695\n",
      "07-12 09:50 root         INFO     Training accuracy  : 0.5260, f1: 0.3551\n",
      "07-12 09:50 root         INFO     Validation accuracy: 0.5325, f1: 0.3632\n",
      "07-12 09:52 root         INFO     Epoch 6. Global step 4655. T=6.03min\n",
      "07-12 09:52 root         INFO     In-batch loss      : 0.6404\n",
      "07-12 09:52 root         INFO     Training accuracy  : 0.5318, f1: 0.3296\n",
      "07-12 09:52 root         INFO     Validation accuracy: 0.5376, f1: 0.3346\n",
      "07-12 09:54 root         INFO     Epoch 8. Global step 5985. T=7.76min\n",
      "07-12 09:54 root         INFO     In-batch loss      : 0.7343\n",
      "07-12 09:54 root         INFO     Training accuracy  : 0.5754, f1: 0.3952\n",
      "07-12 09:54 root         INFO     Validation accuracy: 0.5725, f1: 0.3898\n",
      "07-12 09:56 root         INFO     Epoch 10. Global step 7315. T=9.47min\n",
      "07-12 09:56 root         INFO     In-batch loss      : 0.7345\n",
      "07-12 09:56 root         INFO     Training accuracy  : 0.6257, f1: 0.6910\n",
      "07-12 09:56 root         INFO     Validation accuracy: 0.6155, f1: 0.6804\n",
      "07-12 09:57 root         INFO     Epoch 12. Global step 8645. T=11.20min\n",
      "07-12 09:57 root         INFO     In-batch loss      : 0.7945\n",
      "07-12 09:57 root         INFO     Training accuracy  : 0.7381, f1: 0.7420\n",
      "07-12 09:57 root         INFO     Validation accuracy: 0.7320, f1: 0.7346\n",
      "07-12 09:59 root         INFO     Epoch 14. Global step 9975. T=12.94min\n",
      "07-12 09:59 root         INFO     In-batch loss      : 0.4946\n",
      "07-12 09:59 root         INFO     Training accuracy  : 0.7609, f1: 0.7705\n",
      "07-12 09:59 root         INFO     Validation accuracy: 0.7533, f1: 0.7628\n",
      "07-12 10:01 root         INFO     Epoch 16. Global step 11305. T=14.65min\n",
      "07-12 10:01 root         INFO     In-batch loss      : 0.4124\n",
      "07-12 10:01 root         INFO     Training accuracy  : 0.7762, f1: 0.7770\n",
      "07-12 10:01 root         INFO     Validation accuracy: 0.7685, f1: 0.7695\n",
      "07-12 10:02 root         INFO     Epoch 18. Global step 12635. T=16.37min\n",
      "07-12 10:02 root         INFO     In-batch loss      : 0.8818\n",
      "07-12 10:02 root         INFO     Training accuracy  : 0.7882, f1: 0.7938\n",
      "07-12 10:02 root         INFO     Validation accuracy: 0.7757, f1: 0.7813\n",
      "07-12 10:03 root         INFO     Epoch 19. Global step 13300. T=17.24min\n",
      "07-12 10:03 root         INFO     In-batch loss      : 0.3183\n",
      "07-12 10:03 root         INFO     Training accuracy  : 0.7936, f1: 0.8024\n",
      "07-12 10:03 root         INFO     Validation accuracy: 0.7859, f1: 0.7951\n",
      "07-12 10:03 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 10:03 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.37144320966744815, 'input_dim': 300, 'lr': 0.0003630042303771198}\n",
      "07-12 10:03 root         INFO     Writer: runs/Jul12_10-03-53_lyalin_RNNBinaryClassifier_lr3_dropout0.37144320966744815_noise_level0.0000hyperparameters_search_random\n",
      "07-12 10:04 root         INFO     Epoch 0. Global step 665. T=0.84min\n",
      "07-12 10:04 root         INFO     In-batch loss      : 0.5634\n",
      "07-12 10:04 root         INFO     Training accuracy  : 0.5589, f1: 0.3041\n",
      "07-12 10:04 root         INFO     Validation accuracy: 0.5680, f1: 0.3210\n",
      "07-12 10:06 root         INFO     Epoch 2. Global step 1995. T=2.44min\n",
      "07-12 10:06 root         INFO     In-batch loss      : 0.1772\n",
      "07-12 10:06 root         INFO     Training accuracy  : 0.7483, f1: 0.7375\n",
      "07-12 10:06 root         INFO     Validation accuracy: 0.7517, f1: 0.7420\n",
      "07-12 10:07 root         INFO     Epoch 4. Global step 3325. T=4.09min\n",
      "07-12 10:07 root         INFO     In-batch loss      : 0.1958\n",
      "07-12 10:07 root         INFO     Training accuracy  : 0.8129, f1: 0.8150\n",
      "07-12 10:07 root         INFO     Validation accuracy: 0.8123, f1: 0.8140\n",
      "07-12 10:09 root         INFO     Epoch 6. Global step 4655. T=5.69min\n",
      "07-12 10:09 root         INFO     In-batch loss      : 0.3034\n",
      "07-12 10:09 root         INFO     Training accuracy  : 0.8594, f1: 0.8598\n",
      "07-12 10:09 root         INFO     Validation accuracy: 0.8563, f1: 0.8556\n",
      "07-12 10:11 root         INFO     Epoch 8. Global step 5985. T=7.33min\n",
      "07-12 10:11 root         INFO     In-batch loss      : 0.1107\n",
      "07-12 10:11 root         INFO     Training accuracy  : 0.8783, f1: 0.8777\n",
      "07-12 10:11 root         INFO     Validation accuracy: 0.8595, f1: 0.8577\n",
      "07-12 10:12 root         INFO     Epoch 10. Global step 7315. T=8.92min\n",
      "07-12 10:12 root         INFO     In-batch loss      : 1.8980\n",
      "07-12 10:12 root         INFO     Training accuracy  : 0.8936, f1: 0.8938\n",
      "07-12 10:12 root         INFO     Validation accuracy: 0.8664, f1: 0.8656\n",
      "07-12 10:14 root         INFO     Epoch 12. Global step 8645. T=10.53min\n",
      "07-12 10:14 root         INFO     In-batch loss      : 0.0038\n",
      "07-12 10:14 root         INFO     Training accuracy  : 0.9079, f1: 0.9078\n",
      "07-12 10:14 root         INFO     Validation accuracy: 0.8699, f1: 0.8692\n",
      "07-12 10:16 root         INFO     Epoch 14. Global step 9975. T=12.12min\n",
      "07-12 10:16 root         INFO     In-batch loss      : 0.1881\n",
      "07-12 10:16 root         INFO     Training accuracy  : 0.9209, f1: 0.9216\n",
      "07-12 10:16 root         INFO     Validation accuracy: 0.8707, f1: 0.8707\n",
      "07-12 10:17 root         INFO     Epoch 16. Global step 11305. T=13.71min\n",
      "07-12 10:17 root         INFO     In-batch loss      : 0.2850\n",
      "07-12 10:17 root         INFO     Training accuracy  : 0.9349, f1: 0.9354\n",
      "07-12 10:17 root         INFO     Validation accuracy: 0.8712, f1: 0.8711\n",
      "07-12 10:19 root         INFO     Epoch 18. Global step 12635. T=15.30min\n",
      "07-12 10:19 root         INFO     In-batch loss      : 0.0028\n",
      "07-12 10:19 root         INFO     Training accuracy  : 0.9499, f1: 0.9496\n",
      "07-12 10:19 root         INFO     Validation accuracy: 0.8653, f1: 0.8627\n",
      "07-12 10:20 root         INFO     Epoch 19. Global step 13300. T=16.17min\n",
      "07-12 10:20 root         INFO     In-batch loss      : 0.0651\n",
      "07-12 10:20 root         INFO     Training accuracy  : 0.9583, f1: 0.9584\n",
      "07-12 10:20 root         INFO     Validation accuracy: 0.8616, f1: 0.8613\n",
      "07-12 10:20 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 10:20 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.5247415475076816, 'input_dim': 300, 'lr': 0.00012028855055984249}\n",
      "07-12 10:20 root         INFO     Writer: runs/Jul12_10-20-07_lyalin_RNNBinaryClassifier_lr3_dropout0.5247415475076816_noise_level0.0000hyperparameters_search_random\n",
      "07-12 10:20 root         INFO     Epoch 0. Global step 665. T=0.80min\n",
      "07-12 10:20 root         INFO     In-batch loss      : 0.6858\n",
      "07-12 10:20 root         INFO     Training accuracy  : 0.5287, f1: 0.3766\n",
      "07-12 10:20 root         INFO     Validation accuracy: 0.5363, f1: 0.3956\n",
      "07-12 10:22 root         INFO     Epoch 2. Global step 1995. T=2.44min\n",
      "07-12 10:22 root         INFO     In-batch loss      : 0.5439\n",
      "07-12 10:22 root         INFO     Training accuracy  : 0.7851, f1: 0.7854\n",
      "07-12 10:22 root         INFO     Validation accuracy: 0.7864, f1: 0.7847\n",
      "07-12 10:24 root         INFO     Epoch 4. Global step 3325. T=4.06min\n",
      "07-12 10:24 root         INFO     In-batch loss      : 0.2468\n",
      "07-12 10:24 root         INFO     Training accuracy  : 0.7995, f1: 0.7966\n",
      "07-12 10:24 root         INFO     Validation accuracy: 0.8067, f1: 0.8025\n",
      "07-12 10:25 root         INFO     Epoch 6. Global step 4655. T=5.69min\n",
      "07-12 10:25 root         INFO     In-batch loss      : 0.2643\n",
      "07-12 10:25 root         INFO     Training accuracy  : 0.8085, f1: 0.8140\n",
      "07-12 10:25 root         INFO     Validation accuracy: 0.8149, f1: 0.8198\n",
      "07-12 10:27 root         INFO     Epoch 8. Global step 5985. T=7.30min\n",
      "07-12 10:27 root         INFO     In-batch loss      : 1.3777\n",
      "07-12 10:27 root         INFO     Training accuracy  : 0.8206, f1: 0.8184\n",
      "07-12 10:27 root         INFO     Validation accuracy: 0.8211, f1: 0.8181\n",
      "07-12 10:29 root         INFO     Epoch 10. Global step 7315. T=8.89min\n",
      "07-12 10:29 root         INFO     In-batch loss      : 0.1198\n",
      "07-12 10:29 root         INFO     Training accuracy  : 0.8335, f1: 0.8337\n",
      "07-12 10:29 root         INFO     Validation accuracy: 0.8376, f1: 0.8369\n",
      "07-12 10:30 root         INFO     Epoch 12. Global step 8645. T=10.49min\n",
      "07-12 10:30 root         INFO     In-batch loss      : 0.2321\n",
      "07-12 10:30 root         INFO     Training accuracy  : 0.8445, f1: 0.8431\n",
      "07-12 10:30 root         INFO     Validation accuracy: 0.8432, f1: 0.8410\n",
      "07-12 10:32 root         INFO     Epoch 14. Global step 9975. T=12.11min\n",
      "07-12 10:32 root         INFO     In-batch loss      : 0.9232\n",
      "07-12 10:32 root         INFO     Training accuracy  : 0.8505, f1: 0.8504\n",
      "07-12 10:32 root         INFO     Validation accuracy: 0.8528, f1: 0.8525\n",
      "07-12 10:33 root         INFO     Epoch 16. Global step 11305. T=13.69min\n",
      "07-12 10:33 root         INFO     In-batch loss      : 0.0272\n",
      "07-12 10:33 root         INFO     Training accuracy  : 0.8595, f1: 0.8590\n",
      "07-12 10:33 root         INFO     Validation accuracy: 0.8541, f1: 0.8533\n",
      "07-12 10:35 root         INFO     Epoch 18. Global step 12635. T=15.35min\n",
      "07-12 10:35 root         INFO     In-batch loss      : 0.0349\n",
      "07-12 10:35 root         INFO     Training accuracy  : 0.8654, f1: 0.8633\n",
      "07-12 10:35 root         INFO     Validation accuracy: 0.8568, f1: 0.8535\n",
      "07-12 10:36 root         INFO     Epoch 19. Global step 13300. T=16.14min\n",
      "07-12 10:36 root         INFO     In-batch loss      : 0.0161\n",
      "07-12 10:36 root         INFO     Training accuracy  : 0.8688, f1: 0.8685\n",
      "07-12 10:36 root         INFO     Validation accuracy: 0.8557, f1: 0.8544\n",
      "07-12 10:36 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 10:36 root         INFO     Parameters: {'hidden_dim': 256, 'dropout': 0.9549786461942674, 'input_dim': 300, 'lr': 0.00017187194554574214}\n",
      "07-12 10:36 root         INFO     Writer: runs/Jul12_10-36-20_lyalin_RNNBinaryClassifier_lr3_dropout0.9549786461942674_noise_level0.0000hyperparameters_search_random\n",
      "07-12 10:37 root         INFO     Epoch 0. Global step 665. T=0.79min\n",
      "07-12 10:37 root         INFO     In-batch loss      : 0.7786\n",
      "07-12 10:37 root         INFO     Training accuracy  : 0.5151, f1: 0.3763\n",
      "07-12 10:37 root         INFO     Validation accuracy: 0.5179, f1: 0.3842\n",
      "07-12 10:38 root         INFO     Epoch 2. Global step 1995. T=2.35min\n",
      "07-12 10:38 root         INFO     In-batch loss      : 0.6755\n",
      "07-12 10:38 root         INFO     Training accuracy  : 0.5255, f1: 0.3500\n",
      "07-12 10:38 root         INFO     Validation accuracy: 0.5325, f1: 0.3637\n",
      "07-12 10:40 root         INFO     Epoch 4. Global step 3325. T=3.91min\n",
      "07-12 10:40 root         INFO     In-batch loss      : 0.3665\n",
      "07-12 10:40 root         INFO     Training accuracy  : 0.6844, f1: 0.6932\n",
      "07-12 10:40 root         INFO     Validation accuracy: 0.6813, f1: 0.6916\n",
      "07-12 10:41 root         INFO     Epoch 6. Global step 4655. T=5.47min\n",
      "07-12 10:41 root         INFO     In-batch loss      : 0.2642\n",
      "07-12 10:41 root         INFO     Training accuracy  : 0.7846, f1: 0.7834\n",
      "07-12 10:41 root         INFO     Validation accuracy: 0.7816, f1: 0.7795\n",
      "07-12 10:43 root         INFO     Epoch 8. Global step 5985. T=7.01min\n",
      "07-12 10:43 root         INFO     In-batch loss      : 0.1498\n",
      "07-12 10:43 root         INFO     Training accuracy  : 0.8014, f1: 0.7998\n",
      "07-12 10:43 root         INFO     Validation accuracy: 0.8096, f1: 0.8074\n",
      "07-12 10:44 root         INFO     Epoch 10. Global step 7315. T=8.57min\n",
      "07-12 10:44 root         INFO     In-batch loss      : 0.8881\n",
      "07-12 10:44 root         INFO     Training accuracy  : 0.8131, f1: 0.8117\n",
      "07-12 10:44 root         INFO     Validation accuracy: 0.8213, f1: 0.8197\n",
      "07-12 10:46 root         INFO     Epoch 12. Global step 8645. T=10.11min\n",
      "07-12 10:46 root         INFO     In-batch loss      : 0.3524\n",
      "07-12 10:46 root         INFO     Training accuracy  : 0.8227, f1: 0.8212\n",
      "07-12 10:46 root         INFO     Validation accuracy: 0.8323, f1: 0.8303\n",
      "07-12 10:47 root         INFO     Epoch 14. Global step 9975. T=11.65min\n",
      "07-12 10:47 root         INFO     In-batch loss      : 0.0649\n",
      "07-12 10:47 root         INFO     Training accuracy  : 0.8279, f1: 0.8184\n",
      "07-12 10:47 root         INFO     Validation accuracy: 0.8384, f1: 0.8297\n",
      "07-12 10:49 root         INFO     Epoch 16. Global step 11305. T=13.21min\n",
      "07-12 10:49 root         INFO     In-batch loss      : 0.0614\n",
      "07-12 10:49 root         INFO     Training accuracy  : 0.8434, f1: 0.8410\n",
      "07-12 10:49 root         INFO     Validation accuracy: 0.8491, f1: 0.8459\n",
      "07-12 10:51 root         INFO     Epoch 18. Global step 12635. T=14.76min\n",
      "07-12 10:51 root         INFO     In-batch loss      : 0.0464\n",
      "07-12 10:51 root         INFO     Training accuracy  : 0.8509, f1: 0.8510\n",
      "07-12 10:51 root         INFO     Validation accuracy: 0.8557, f1: 0.8555\n",
      "07-12 10:51 root         INFO     Epoch 19. Global step 13300. T=15.53min\n",
      "07-12 10:51 root         INFO     In-batch loss      : 0.1457\n",
      "07-12 10:51 root         INFO     Training accuracy  : 0.8520, f1: 0.8477\n",
      "07-12 10:51 root         INFO     Validation accuracy: 0.8560, f1: 0.8516\n",
      "07-12 10:51 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 10:51 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.23983332034314891, 'input_dim': 300, 'lr': 0.0007241405733596442}\n",
      "07-12 10:51 root         INFO     Writer: runs/Jul12_10-51-56_lyalin_RNNBinaryClassifier_lr3_dropout0.23983332034314891_noise_level0.0000hyperparameters_search_random\n",
      "07-12 10:52 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 10:52 root         INFO     In-batch loss      : 0.6242\n",
      "07-12 10:52 root         INFO     Training accuracy  : 0.5315, f1: 0.3591\n",
      "07-12 10:52 root         INFO     Validation accuracy: 0.5360, f1: 0.3705\n",
      "07-12 10:54 root         INFO     Epoch 2. Global step 1995. T=2.31min\n",
      "07-12 10:54 root         INFO     In-batch loss      : 1.0553\n",
      "07-12 10:54 root         INFO     Training accuracy  : 0.7378, f1: 0.7215\n",
      "07-12 10:54 root         INFO     Validation accuracy: 0.7384, f1: 0.7241\n",
      "07-12 10:55 root         INFO     Epoch 4. Global step 3325. T=3.85min\n",
      "07-12 10:55 root         INFO     In-batch loss      : 0.1882\n",
      "07-12 10:55 root         INFO     Training accuracy  : 0.8034, f1: 0.7998\n",
      "07-12 10:55 root         INFO     Validation accuracy: 0.8152, f1: 0.8111\n",
      "07-12 10:57 root         INFO     Epoch 6. Global step 4655. T=5.39min\n",
      "07-12 10:57 root         INFO     In-batch loss      : 1.2048\n",
      "07-12 10:57 root         INFO     Training accuracy  : 0.8393, f1: 0.8363\n",
      "07-12 10:57 root         INFO     Validation accuracy: 0.8467, f1: 0.8439\n",
      "07-12 10:58 root         INFO     Epoch 8. Global step 5985. T=6.93min\n",
      "07-12 10:58 root         INFO     In-batch loss      : 0.4365\n",
      "07-12 10:58 root         INFO     Training accuracy  : 0.8621, f1: 0.8635\n",
      "07-12 10:58 root         INFO     Validation accuracy: 0.8605, f1: 0.8620\n",
      "07-12 11:00 root         INFO     Epoch 10. Global step 7315. T=8.48min\n",
      "07-12 11:00 root         INFO     In-batch loss      : 0.1377\n",
      "07-12 11:00 root         INFO     Training accuracy  : 0.8770, f1: 0.8793\n",
      "07-12 11:00 root         INFO     Validation accuracy: 0.8643, f1: 0.8673\n",
      "07-12 11:01 root         INFO     Epoch 12. Global step 8645. T=10.03min\n",
      "07-12 11:01 root         INFO     In-batch loss      : 0.6335\n",
      "07-12 11:01 root         INFO     Training accuracy  : 0.8884, f1: 0.8868\n",
      "07-12 11:01 root         INFO     Validation accuracy: 0.8693, f1: 0.8672\n",
      "07-12 11:03 root         INFO     Epoch 14. Global step 9975. T=11.57min\n",
      "07-12 11:03 root         INFO     In-batch loss      : 0.0452\n",
      "07-12 11:03 root         INFO     Training accuracy  : 0.8980, f1: 0.8970\n",
      "07-12 11:03 root         INFO     Validation accuracy: 0.8717, f1: 0.8693\n",
      "07-12 11:05 root         INFO     Epoch 16. Global step 11305. T=13.11min\n",
      "07-12 11:05 root         INFO     In-batch loss      : 0.0032\n",
      "07-12 11:05 root         INFO     Training accuracy  : 0.9064, f1: 0.9048\n",
      "07-12 11:05 root         INFO     Validation accuracy: 0.8741, f1: 0.8712\n",
      "07-12 11:06 root         INFO     Epoch 18. Global step 12635. T=14.66min\n",
      "07-12 11:06 root         INFO     In-batch loss      : 0.0208\n",
      "07-12 11:06 root         INFO     Training accuracy  : 0.9198, f1: 0.9195\n",
      "07-12 11:06 root         INFO     Validation accuracy: 0.8747, f1: 0.8735\n",
      "07-12 11:07 root         INFO     Epoch 19. Global step 13300. T=15.43min\n",
      "07-12 11:07 root         INFO     In-batch loss      : 0.0936\n",
      "07-12 11:07 root         INFO     Training accuracy  : 0.9226, f1: 0.9224\n",
      "07-12 11:07 root         INFO     Validation accuracy: 0.8763, f1: 0.8753\n",
      "07-12 11:07 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 11:07 root         INFO     Parameters: {'hidden_dim': 512, 'dropout': 0.7955932483375526, 'input_dim': 300, 'lr': 0.0002596469164785635}\n",
      "07-12 11:07 root         INFO     Writer: runs/Jul12_11-07-26_lyalin_RNNBinaryClassifier_lr3_dropout0.7955932483375526_noise_level0.0000hyperparameters_search_random\n",
      "07-12 11:08 root         INFO     Epoch 0. Global step 665. T=0.81min\n",
      "07-12 11:08 root         INFO     In-batch loss      : 0.7267\n",
      "07-12 11:08 root         INFO     Training accuracy  : 0.5346, f1: 0.3533\n",
      "07-12 11:08 root         INFO     Validation accuracy: 0.5416, f1: 0.3631\n",
      "07-12 11:09 root         INFO     Epoch 2. Global step 1995. T=2.43min\n",
      "07-12 11:09 root         INFO     In-batch loss      : 0.6997\n",
      "07-12 11:09 root         INFO     Training accuracy  : 0.7142, f1: 0.7047\n",
      "07-12 11:09 root         INFO     Validation accuracy: 0.7187, f1: 0.7106\n",
      "07-12 11:11 root         INFO     Epoch 4. Global step 3325. T=4.03min\n",
      "07-12 11:11 root         INFO     In-batch loss      : 0.3058\n",
      "07-12 11:11 root         INFO     Training accuracy  : 0.7692, f1: 0.7625\n",
      "07-12 11:11 root         INFO     Validation accuracy: 0.7733, f1: 0.7671\n",
      "07-12 11:13 root         INFO     Epoch 6. Global step 4655. T=5.63min\n",
      "07-12 11:13 root         INFO     In-batch loss      : 0.9200\n",
      "07-12 11:13 root         INFO     Training accuracy  : 0.8043, f1: 0.8069\n",
      "07-12 11:13 root         INFO     Validation accuracy: 0.8064, f1: 0.8087\n",
      "07-12 11:14 root         INFO     Epoch 8. Global step 5985. T=7.24min\n",
      "07-12 11:14 root         INFO     In-batch loss      : 0.2493\n",
      "07-12 11:14 root         INFO     Training accuracy  : 0.8401, f1: 0.8393\n",
      "07-12 11:14 root         INFO     Validation accuracy: 0.8424, f1: 0.8412\n",
      "07-12 11:16 root         INFO     Epoch 10. Global step 7315. T=8.85min\n",
      "07-12 11:16 root         INFO     In-batch loss      : 0.1372\n",
      "07-12 11:16 root         INFO     Training accuracy  : 0.8605, f1: 0.8595\n",
      "07-12 11:16 root         INFO     Validation accuracy: 0.8584, f1: 0.8561\n",
      "07-12 11:17 root         INFO     Epoch 12. Global step 8645. T=10.46min\n",
      "07-12 11:17 root         INFO     In-batch loss      : 0.3168\n",
      "07-12 11:17 root         INFO     Training accuracy  : 0.8730, f1: 0.8716\n",
      "07-12 11:17 root         INFO     Validation accuracy: 0.8624, f1: 0.8602\n",
      "07-12 11:19 root         INFO     Epoch 14. Global step 9975. T=12.07min\n",
      "07-12 11:19 root         INFO     In-batch loss      : 0.1547\n",
      "07-12 11:19 root         INFO     Training accuracy  : 0.8840, f1: 0.8835\n",
      "07-12 11:19 root         INFO     Validation accuracy: 0.8643, f1: 0.8625\n",
      "07-12 11:21 root         INFO     Epoch 16. Global step 11305. T=13.70min\n",
      "07-12 11:21 root         INFO     In-batch loss      : 0.0696\n",
      "07-12 11:21 root         INFO     Training accuracy  : 0.8934, f1: 0.8945\n",
      "07-12 11:21 root         INFO     Validation accuracy: 0.8683, f1: 0.8687\n",
      "07-12 11:22 root         INFO     Epoch 18. Global step 12635. T=15.30min\n",
      "07-12 11:22 root         INFO     In-batch loss      : 1.0616\n",
      "07-12 11:22 root         INFO     Training accuracy  : 0.9037, f1: 0.9030\n",
      "07-12 11:22 root         INFO     Validation accuracy: 0.8675, f1: 0.8655\n",
      "07-12 11:23 root         INFO     Epoch 19. Global step 13300. T=16.10min\n",
      "07-12 11:23 root         INFO     In-batch loss      : 0.3572\n",
      "07-12 11:23 root         INFO     Training accuracy  : 0.9077, f1: 0.9075\n",
      "07-12 11:23 root         INFO     Validation accuracy: 0.8707, f1: 0.8697\n",
      "07-12 11:23 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 11:23 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.7043801761491659, 'input_dim': 300, 'lr': 0.00016560724623957483}\n",
      "07-12 11:23 root         INFO     Writer: runs/Jul12_11-23-36_lyalin_RNNBinaryClassifier_lr3_dropout0.7043801761491659_noise_level0.0000hyperparameters_search_random\n",
      "07-12 11:24 root         INFO     Epoch 0. Global step 665. T=0.77min\n",
      "07-12 11:24 root         INFO     In-batch loss      : 0.6734\n",
      "07-12 11:24 root         INFO     Training accuracy  : 0.5148, f1: 0.6478\n",
      "07-12 11:24 root         INFO     Validation accuracy: 0.5133, f1: 0.6460\n",
      "07-12 11:25 root         INFO     Epoch 2. Global step 1995. T=2.32min\n",
      "07-12 11:25 root         INFO     In-batch loss      : 0.7056\n",
      "07-12 11:25 root         INFO     Training accuracy  : 0.5371, f1: 0.3627\n",
      "07-12 11:25 root         INFO     Validation accuracy: 0.5389, f1: 0.3747\n",
      "07-12 11:27 root         INFO     Epoch 4. Global step 3325. T=3.86min\n",
      "07-12 11:27 root         INFO     In-batch loss      : 0.5752\n",
      "07-12 11:27 root         INFO     Training accuracy  : 0.7605, f1: 0.7641\n",
      "07-12 11:27 root         INFO     Validation accuracy: 0.7552, f1: 0.7578\n",
      "07-12 11:29 root         INFO     Epoch 6. Global step 4655. T=5.41min\n",
      "07-12 11:29 root         INFO     In-batch loss      : 0.1907\n",
      "07-12 11:29 root         INFO     Training accuracy  : 0.7952, f1: 0.7919\n",
      "07-12 11:29 root         INFO     Validation accuracy: 0.7952, f1: 0.7908\n",
      "07-12 11:30 root         INFO     Epoch 8. Global step 5985. T=6.95min\n",
      "07-12 11:30 root         INFO     In-batch loss      : 0.1076\n",
      "07-12 11:30 root         INFO     Training accuracy  : 0.8084, f1: 0.8040\n",
      "07-12 11:30 root         INFO     Validation accuracy: 0.8184, f1: 0.8121\n",
      "07-12 11:32 root         INFO     Epoch 10. Global step 7315. T=8.49min\n",
      "07-12 11:32 root         INFO     In-batch loss      : 0.4518\n",
      "07-12 11:32 root         INFO     Training accuracy  : 0.8207, f1: 0.8195\n",
      "07-12 11:32 root         INFO     Validation accuracy: 0.8277, f1: 0.8254\n",
      "07-12 11:33 root         INFO     Epoch 12. Global step 8645. T=10.04min\n",
      "07-12 11:33 root         INFO     In-batch loss      : 0.5076\n",
      "07-12 11:33 root         INFO     Training accuracy  : 0.8270, f1: 0.8305\n",
      "07-12 11:33 root         INFO     Validation accuracy: 0.8371, f1: 0.8397\n",
      "07-12 11:35 root         INFO     Epoch 14. Global step 9975. T=11.59min\n",
      "07-12 11:35 root         INFO     In-batch loss      : 0.5929\n",
      "07-12 11:35 root         INFO     Training accuracy  : 0.8354, f1: 0.8382\n",
      "07-12 11:35 root         INFO     Validation accuracy: 0.8408, f1: 0.8428\n",
      "07-12 11:36 root         INFO     Epoch 16. Global step 11305. T=13.12min\n",
      "07-12 11:36 root         INFO     In-batch loss      : 0.0398\n",
      "07-12 11:36 root         INFO     Training accuracy  : 0.8433, f1: 0.8425\n",
      "07-12 11:36 root         INFO     Validation accuracy: 0.8459, f1: 0.8446\n",
      "07-12 11:38 root         INFO     Epoch 18. Global step 12635. T=14.68min\n",
      "07-12 11:38 root         INFO     In-batch loss      : 0.2604\n",
      "07-12 11:38 root         INFO     Training accuracy  : 0.8470, f1: 0.8466\n",
      "07-12 11:38 root         INFO     Validation accuracy: 0.8477, f1: 0.8471\n",
      "07-12 11:39 root         INFO     Epoch 19. Global step 13300. T=15.45min\n",
      "07-12 11:39 root         INFO     In-batch loss      : 0.0980\n",
      "07-12 11:39 root         INFO     Training accuracy  : 0.8496, f1: 0.8520\n",
      "07-12 11:39 root         INFO     Validation accuracy: 0.8525, f1: 0.8545\n",
      "07-12 11:39 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 11:39 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.3199289421634453, 'input_dim': 300, 'lr': 0.00014094257741631265}\n",
      "07-12 11:39 root         INFO     Writer: runs/Jul12_11-39-07_lyalin_RNNBinaryClassifier_lr3_dropout0.3199289421634453_noise_level0.0000hyperparameters_search_random\n",
      "07-12 11:39 root         INFO     Epoch 0. Global step 665. T=0.78min\n",
      "07-12 11:39 root         INFO     In-batch loss      : 0.7019\n",
      "07-12 11:39 root         INFO     Training accuracy  : 0.5226, f1: 0.3284\n",
      "07-12 11:39 root         INFO     Validation accuracy: 0.5293, f1: 0.3446\n",
      "07-12 11:41 root         INFO     Epoch 2. Global step 1995. T=2.34min\n",
      "07-12 11:41 root         INFO     In-batch loss      : 0.9361\n",
      "07-12 11:41 root         INFO     Training accuracy  : 0.5866, f1: 0.4445\n",
      "07-12 11:41 root         INFO     Validation accuracy: 0.5936, f1: 0.4588\n",
      "07-12 11:43 root         INFO     Epoch 4. Global step 3325. T=3.89min\n",
      "07-12 11:43 root         INFO     In-batch loss      : 1.3429\n",
      "07-12 11:43 root         INFO     Training accuracy  : 0.7746, f1: 0.7669\n",
      "07-12 11:43 root         INFO     Validation accuracy: 0.7741, f1: 0.7648\n",
      "07-12 11:44 root         INFO     Epoch 6. Global step 4655. T=5.44min\n",
      "07-12 11:44 root         INFO     In-batch loss      : 0.1649\n",
      "07-12 11:44 root         INFO     Training accuracy  : 0.7996, f1: 0.8000\n",
      "07-12 11:44 root         INFO     Validation accuracy: 0.8016, f1: 0.8022\n",
      "07-12 11:46 root         INFO     Epoch 8. Global step 5985. T=6.99min\n",
      "07-12 11:46 root         INFO     In-batch loss      : 0.1910\n",
      "07-12 11:46 root         INFO     Training accuracy  : 0.8120, f1: 0.8096\n",
      "07-12 11:46 root         INFO     Validation accuracy: 0.8144, f1: 0.8120\n",
      "07-12 11:47 root         INFO     Epoch 10. Global step 7315. T=8.54min\n",
      "07-12 11:47 root         INFO     In-batch loss      : 0.1082\n",
      "07-12 11:47 root         INFO     Training accuracy  : 0.8196, f1: 0.8179\n",
      "07-12 11:47 root         INFO     Validation accuracy: 0.8251, f1: 0.8237\n",
      "07-12 11:49 root         INFO     Epoch 12. Global step 8645. T=10.26min\n",
      "07-12 11:49 root         INFO     In-batch loss      : 0.2931\n",
      "07-12 11:49 root         INFO     Training accuracy  : 0.8267, f1: 0.8258\n",
      "07-12 11:49 root         INFO     Validation accuracy: 0.8309, f1: 0.8298\n",
      "07-12 11:51 root         INFO     Epoch 14. Global step 9975. T=11.98min\n",
      "07-12 11:51 root         INFO     In-batch loss      : 0.7475\n",
      "07-12 11:51 root         INFO     Training accuracy  : 0.8326, f1: 0.8316\n",
      "07-12 11:51 root         INFO     Validation accuracy: 0.8320, f1: 0.8309\n",
      "07-12 11:52 root         INFO     Epoch 16. Global step 11305. T=13.74min\n",
      "07-12 11:52 root         INFO     In-batch loss      : 0.6221\n",
      "07-12 11:52 root         INFO     Training accuracy  : 0.8376, f1: 0.8376\n",
      "07-12 11:52 root         INFO     Validation accuracy: 0.8389, f1: 0.8393\n",
      "07-12 11:54 root         INFO     Epoch 18. Global step 12635. T=15.34min\n",
      "07-12 11:54 root         INFO     In-batch loss      : 0.7045\n",
      "07-12 11:54 root         INFO     Training accuracy  : 0.8435, f1: 0.8455\n",
      "07-12 11:54 root         INFO     Validation accuracy: 0.8432, f1: 0.8454\n",
      "07-12 11:55 root         INFO     Epoch 19. Global step 13300. T=16.18min\n",
      "07-12 11:55 root         INFO     In-batch loss      : 0.0535\n",
      "07-12 11:55 root         INFO     Training accuracy  : 0.8462, f1: 0.8480\n",
      "07-12 11:55 root         INFO     Validation accuracy: 0.8477, f1: 0.8494\n",
      "07-12 11:55 root         WARNING  Model is evaluating in training mode!\n",
      "07-12 11:55 root         INFO     Parameters: {'hidden_dim': 64, 'dropout': 0.9573273831856772, 'input_dim': 300, 'lr': 0.0005492471192325942}\n",
      "07-12 11:55 root         INFO     Writer: runs/Jul12_11-55-23_lyalin_RNNBinaryClassifier_lr3_dropout0.9573273831856772_noise_level0.0000hyperparameters_search_random\n",
      "07-12 11:56 root         INFO     Epoch 0. Global step 665. T=0.82min\n",
      "07-12 11:56 root         INFO     In-batch loss      : 0.6494\n",
      "07-12 11:56 root         INFO     Training accuracy  : 0.5088, f1: 0.5998\n",
      "07-12 11:56 root         INFO     Validation accuracy: 0.5013, f1: 0.5885\n",
      "07-12 11:57 root         INFO     Epoch 2. Global step 1995. T=2.48min\n",
      "07-12 11:57 root         INFO     In-batch loss      : 0.6854\n",
      "07-12 11:57 root         INFO     Training accuracy  : 0.5267, f1: 0.3668\n",
      "07-12 11:57 root         INFO     Validation accuracy: 0.5280, f1: 0.3776\n",
      "07-12 11:59 root         INFO     Epoch 4. Global step 3325. T=4.11min\n",
      "07-12 11:59 root         INFO     In-batch loss      : 0.6696\n",
      "07-12 11:59 root         INFO     Training accuracy  : 0.5352, f1: 0.3398\n",
      "07-12 11:59 root         INFO     Validation accuracy: 0.5389, f1: 0.3483\n",
      "Process Process-14713:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/not_a_robot/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-19f77a01bc90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m               \u001b[0mlog_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hyperparameters_search_random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m               save_model_path=None)\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/text_classification/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, noise_level, lr, epochs, comment, log_every, save_model_path, use_annealing)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muse_annealing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# ensure that the worker exits on process exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0m_update_worker_pids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 0 > best_f1:\n",
    "    best_f1 = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    lr = 10**np.random.uniform(-4, -3)\n",
    "    hidden_dim = int(np.random.choice([32, 64, 128, 256, 512, 1024]))\n",
    "    dropout = np.random.rand() * 0.9 + 0.1\n",
    "\n",
    "    params = {\n",
    "        'hidden_dim': hidden_dim,\n",
    "        'dropout': dropout,\n",
    "        'input_dim': embeddings.vector_size\n",
    "    }\n",
    "\n",
    "    model = RNNBinaryClassifier(**params)\n",
    "    params['lr'] = lr\n",
    "    logger.info('Parameters: %s' % params)\n",
    "\n",
    "    trained_model = \\\n",
    "        train(model,\n",
    "              train_dataloader,\n",
    "              val_dataloader,\n",
    "              epochs=20,\n",
    "              noise_level=0,\n",
    "              lr=lr,\n",
    "              log_every=2,\n",
    "              comment='hyperparameters_search_random',\n",
    "              save_model_path=None)\n",
    "    metrics = get_metrics(trained_model, val_dataloader)\n",
    "\n",
    "    if metrics['f1'] > best_f1:\n",
    "        logger.info('YES!, f1: %s, parameters: %s' % (metrics['f1'], str(params)))\n",
    "        best_f1 = metrics['f1']\n",
    "        best_model = model\n",
    "        best_params = params\n",
    "        logger.info(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8744982606368745,\n",
       " {'hidden_dim': 256,\n",
       "  'dropout': 0.19682083244247645,\n",
       "  'input_dim': 300,\n",
       "  'lr': 0.0006258490940383969})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07-13 16:40 root         INFO     Parameters: {'hidden_dim': 128, 'dropout': 0.7517732019887394, 'input_dim': 300, 'lr': 0.0002307763213920885}\n",
      "07-13 16:40 root         INFO     Writer: runs/Jul13_16-40-11_lyalin_RNNBinaryClassifier_lr3_dropout0.7517732019887394_noise_level0.0000_hyperparameters_search_manual\n",
      "07-13 16:41 root         INFO     Epoch 0. Global step 665. T=1.16min\n",
      "07-13 16:41 root         INFO     In-batch loss      : 0.6244\n",
      "07-13 16:41 root         INFO     Training accuracy  : 0.5200, f1: 0.3444\n",
      "07-13 16:41 root         INFO     Validation accuracy: 0.5080, f1: 0.3547\n",
      "07-13 16:44 root         INFO     Epoch 2. Global step 1995. T=3.95min\n",
      "07-13 16:44 root         INFO     In-batch loss      : 0.6833\n",
      "07-13 16:44 root         INFO     Training accuracy  : 0.5220, f1: 0.3564\n",
      "07-13 16:44 root         INFO     Validation accuracy: 0.5157, f1: 0.3157\n",
      "07-13 16:46 root         INFO     Epoch 4. Global step 3325. T=6.71min\n",
      "07-13 16:46 root         INFO     In-batch loss      : 0.7043\n",
      "07-13 16:46 root         INFO     Training accuracy  : 0.5251, f1: 0.3555\n",
      "07-13 16:46 root         INFO     Validation accuracy: 0.5147, f1: 0.3573\n",
      "07-13 16:49 root         INFO     Epoch 6. Global step 4655. T=9.41min\n",
      "07-13 16:49 root         INFO     In-batch loss      : 0.7083\n",
      "07-13 16:49 root         INFO     Training accuracy  : 0.5235, f1: 0.6550\n",
      "07-13 16:49 root         INFO     Validation accuracy: 0.5027, f1: 0.6358\n",
      "07-13 16:52 root         INFO     Epoch 8. Global step 5985. T=12.12min\n",
      "07-13 16:52 root         INFO     In-batch loss      : 0.9411\n",
      "07-13 16:52 root         INFO     Training accuracy  : 0.5500, f1: 0.2435\n",
      "07-13 16:52 root         INFO     Validation accuracy: 0.5123, f1: 0.0509\n"
     ]
    }
   ],
   "source": [
    "params ={'hidden_dim': 128,\n",
    "         'dropout': 0.7517732019887394,\n",
    "         'input_dim': 300}\n",
    "\n",
    "model = RNNBinaryClassifier(**params)\n",
    "params['lr'] = lr = 0.0002307763213920885\n",
    "logger.info('Parameters: %s' % params)\n",
    "\n",
    "trained_model = \\\n",
    "    train(model,\n",
    "          train_dataloader,\n",
    "          val_dataloader,\n",
    "          epochs=20,\n",
    "          noise_level=0,\n",
    "          lr=lr,\n",
    "          log_every=2,\n",
    "          comment='_hyperparameters_search_manual',\n",
    "          save_model_path=None,\n",
    "          use_annealing=False)\n",
    "\n",
    "trained_model.eval()\n",
    "metrics = get_metrics(trained_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
