{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from random import random, choice\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 256\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "NOISE_LEVEL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "ALPHABET = [' ', 'e', 't', 'a', 'i', 'o', 's', 'n', 'r', 'h', 'l', 'd', 'c', 'm', 'u', 'f', 'g', 'y', 'b', 'w', 'p',\\\n",
    "            '.', 'v', ',', 'k', \"'\", '/', '>', '<', '-', '\"', 'j', 'x', ')', '(', '!', 'z', 'q', '0', '1', '?', ':',\\\n",
    "            '9', '2', '*', ';', '3', '5', '8', '4', '7', '&', '6', 'é', '\\x96', '`', '$', '\\x85', '_', '%', '=', '#',\\\n",
    "            'UNK', 'PAD']\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['UNK'])] = 1.\n",
    "    if i < MAXLEN:\n",
    "        for j in range(i+1, MAXLEN):\n",
    "            one_hotted_text[j, char2int['PAD']] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = ALPHABET[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)  # это плохо\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n",
    "\n",
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def get_accuracy(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "\n",
    "    for text, label in test_dataset:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    model.train()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharIMDB.noise_level = NOISE_LEVEL\n",
    "train, test = CharIMDB.splits(text_field, label_field)\n",
    "\n",
    "dataloader, val_dataloader = get_train_valid_loader(train, valid_size=VALID_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, init_function, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.init_function = init_function\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, 256, kernel_size=16, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=64, stride=8)\n",
    "        )\n",
    "        self.conv[0].weight = init_function(self.conv[0].weight)\n",
    "\n",
    "        self.fc = nn.Linear(5888, 2)  # 30464 for MAXLEN=1024\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, init_function, lr=1e-4, dropout=0.5, epochs=30):\n",
    "    CharIMDB.noise_level = noise_level\n",
    "\n",
    "    model = CharCNN(init_function=init_function)\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    writer = SummaryWriter(comment='_charCNN_smaller2_lr%s_noise%s_NOdropout' % (\n",
    "        int(-np.log10(lr)), noise_level\n",
    "    ))\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    #     if epoch == 10:\n",
    "    #         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        print('Loss after epoch %s:' % epoch)\n",
    "        print('Global step: %s' % global_step)\n",
    "        print(loss.data[0])\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        print('In-batch accuracy:', acc)\n",
    "\n",
    "        acc = get_accuracy(model, val_dataloader)\n",
    "        print('Validation accuracy:', acc)\n",
    "        writer.add_scalar('accuracy_val', acc, global_step=global_step)\n",
    "        print()\n",
    "\n",
    "    # Test\n",
    "\n",
    "    acc = get_accuracy(model, test_dataloader)\n",
    "    print('Final test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test_final', acc, global_step=global_step)\n",
    "    print()\n",
    "    model.eval()\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6670222878456116\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5112\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6755492091178894\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5172\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.699364960193634\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5364\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.6891615390777588\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6676\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.5262390375137329\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7088\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.41326266527175903\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7372\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.5759977102279663\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7484\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.4313564896583557\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.746\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.5776655673980713\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7544\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.3323601484298706\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7712\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.3805471658706665\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.3446338176727295\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7784\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.15464019775390625\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7656\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1888725757598877\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7876\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.1652103066444397\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7864\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.2724268436431885\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7964\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.6561002731323242\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7836\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.19407756626605988\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7792\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.8851348161697388\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.6685544848442078\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7936\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.06143583357334137\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.78\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.3794499337673187\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7744\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.3443407416343689\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7984\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.2735293507575989\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7892\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.1365838497877121\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7888\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.6129616498947144\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7968\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.10170719027519226\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8036\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.22721727192401886\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7992\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.38628992438316345\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.555729329586029\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8004\n",
      "\n",
      "Final test accuracy: 0.79904\n",
      "\n",
      "CPU times: user 7min 50s, sys: 3min 13s, total: 11min 4s\n",
      "Wall time: 11min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=61184, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.1, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.7154096364974976\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6276\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3147427439689636\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.43052104115486145\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7732\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.14214535057544708\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8052\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.16783644258975983\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8112\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.5878106951713562\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.82\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.1835513859987259\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.036214977502822876\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8056\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.036427706480026245\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.09720713645219803\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8232\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.027575135231018066\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.06920866668224335\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.015279620885848999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.032747477293014526\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8172\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.02133116126060486\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.0014932751655578613\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.0026256442070007324\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8236\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.00022476911544799805\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "1.52587890625e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8168\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "3.4570693969726562e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.828\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "4.4465065002441406e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8132\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00014007091522216797\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.812\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "4.76837158203125e-07\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8216\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "2.7179718017578125e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8252\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.005523800849914551\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.792\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "1.800060272216797e-05\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8224\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "3.933906555175781e-06\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.818\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00014293193817138672\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8244\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.11518393456935883\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7812\n",
      "\n",
      "Final test accuracy: 0.77836\n",
      "\n",
      "CPU times: user 5min 50s, sys: 2min 26s, total: 8min 17s\n",
      "Wall time: 8min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=30464, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.785068154335022\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.6084\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.3312198519706726\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7292\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.2843222916126251\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7424\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.1944502741098404\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7604\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.24288120865821838\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8008\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.36140114068984985\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8036\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.2669448256492615\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8048\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.18363156914710999\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8092\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.48155519366264343\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.47901251912117004\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.802\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.03075912594795227\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.822\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.2517656683921814\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.08778958022594452\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8184\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1717863380908966\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8276\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.14468592405319214\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8148\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.013375252485275269\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8308\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.07788994908332825\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8228\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.005857408046722412\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8136\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.10116563737392426\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8044\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.01556655764579773\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.01607152819633484\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8204\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.00832277536392212\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.826\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.036525875329971313\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8268\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.00587010383605957\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.0029016733169555664\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8284\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.012174874544143677\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8124\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.02179431915283203\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8156\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.00522458553314209\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8208\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.0005469918251037598\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8316\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.0004094839096069336\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.8324\n",
      "\n",
      "Final test accuracy: 0.82348\n",
      "\n",
      "CPU times: user 3min 42s, sys: 1min 33s, total: 5min 15s\n",
      "Wall time: 5min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=30464, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6622531414031982\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5076\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6478318572044373\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.654\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.5919772386550903\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.684\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.8037890195846558\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.6764\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.48778462409973145\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7124\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.41007521748542786\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6928\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.5600640177726746\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.5205470323562622\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7052\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.534763753414154\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7228\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.2934337258338928\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.10048031806945801\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.16950218379497528\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7216\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.05815801024436951\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7024\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.09488996863365173\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7252\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.3324296772480011\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7132\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.10388220846652985\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7208\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.42392557859420776\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7236\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.05512695014476776\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7204\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.08270235359668732\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7188\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.11897016316652298\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7148\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.6041805744171143\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7136\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.022924453020095825\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.72\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.012082993984222412\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7156\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.03923580050468445\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7232\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.10438671708106995\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7316\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.024999678134918213\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.722\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.03975370526313782\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.712\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.02144831418991089\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7288\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.011870712041854858\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7208\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.04195290803909302\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.726\n",
      "\n",
      "Final test accuracy: 0.70556\n",
      "\n",
      "CPU times: user 1min 22s, sys: 30.6 s, total: 1min 52s\n",
      "Wall time: 2min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(16,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=64, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=5888, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_model_with(noise_level=0.01, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
