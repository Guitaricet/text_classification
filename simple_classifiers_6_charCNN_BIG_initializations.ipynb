{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from random import random, choice\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torchtext\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 1024\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "NOISE_LEVEL = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = torchtext.data.Field(\n",
    "    lower=True, include_lengths=False, fix_length=2048, tensor_type=torch.FloatTensor, batch_first=True,\n",
    "    tokenize=lambda x: x, use_vocab=False, sequential=False\n",
    ")\n",
    "label_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "ALPHABET = [' ', 'e', 't', 'a', 'i', 'o', 's', 'n', 'r', 'h', 'l', 'd', 'c', 'm', 'u', 'f', 'g', 'y', 'b', 'w', 'p',\\\n",
    "            '.', 'v', ',', 'k', \"'\", '/', '>', '<', '-', '\"', 'j', 'x', ')', '(', '!', 'z', 'q', '0', '1', '?', ':',\\\n",
    "            '9', '2', '*', ';', '3', '5', '8', '4', '7', '&', '6', 'Ã©', '\\x96', '`', '$', '\\x85', '_', '%', '=', '#',\\\n",
    "            'UNK', 'PAD']\n",
    "\n",
    "ALPHABET_LEN = len(ALPHABET)\n",
    "\n",
    "char2int = {s: i for s, i in zip(ALPHABET, range(ALPHABET_LEN))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(char):\n",
    "    zeros = np.zeros(ALPHABET_LEN)\n",
    "    if char in char2int:\n",
    "        zeros[char2int[char]] = 1.\n",
    "    else:\n",
    "        zeros[char2int['UNK']] = 1.\n",
    "\n",
    "def preprocess_text_nobatch(text, maxlen=MAXLEN):\n",
    "    one_hotted_text = np.zeros((maxlen, ALPHABET_LEN))\n",
    "    for i, char in enumerate(text):\n",
    "        if i >= MAXLEN:\n",
    "            break\n",
    "        one_hotted_text[i, char2int.get(char, char2int['UNK'])] = 1.\n",
    "    if i < MAXLEN:\n",
    "        for j in range(i+1, MAXLEN):\n",
    "            one_hotted_text[j, char2int['PAD']] = 1.\n",
    "\n",
    "    return torch.FloatTensor(one_hotted_text)\n",
    "\n",
    "def onehot2text(one_hotted_text, batch_size=None):\n",
    "    if batch_size is None:\n",
    "        text = ''\n",
    "        _, idx = torch.max(one_hotted_text, 1)\n",
    "        for i in idx:\n",
    "            symb = ALPHABET[i]\n",
    "            if symb == 'PAD':\n",
    "                break\n",
    "            else:\n",
    "                text += symb\n",
    "        return text\n",
    "    else:\n",
    "        texts = []\n",
    "        for text in one_hotted_text:\n",
    "            texts.append(onehot2text(one_hotted_text, batch_size=None))\n",
    "        return texts\n",
    "\n",
    "def noise_generator(string, noise_level, chars=ALPHABET+['']):\n",
    "    noised = \"\"\n",
    "    for c in string:\n",
    "        if random() > noise_level:\n",
    "            noised += c\n",
    "        if random() < noise_level:\n",
    "            noised += choice(chars)\n",
    "    return noised\n",
    "\n",
    "class CharIMDB(torchtext.datasets.imdb.IMDB):\n",
    "    noise_level = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = super(CharIMDB, self).__getitem__(idx)\n",
    "        text = item.text\n",
    "        text = noise_generator(text, self.noise_level)\n",
    "        label = int(item.label == 'pos')\n",
    "        return preprocess_text_nobatch(text), label\n",
    "\n",
    "def get_train_valid_loader(dataset, valid_size, batch_size, random_seed=42, shuffle=True, num_workers=4):\n",
    "\n",
    "    len_dataset = len(dataset)\n",
    "    indices = list(range(len_dataset))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    val_actual_size = int(len_dataset * valid_size)\n",
    "\n",
    "    train_idx, valid_idx = indices[:-val_actual_size], indices[-val_actual_size:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler, num_workers=4\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=4\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def get_accuracy(model, test_dataset):\n",
    "    \"\"\"\n",
    "    Moder will be in TRAIN mode after that\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    lables = []\n",
    "\n",
    "    for text, label in test_dataset:\n",
    "        if CUDA:\n",
    "            text = Variable(text.cuda())\n",
    "        else:\n",
    "            text = Variable(text)\n",
    "\n",
    "        text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "        prediction = model(text)\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        predictions += idx.data.tolist()\n",
    "        lables += label.tolist()\n",
    "\n",
    "    acc = accuracy_score(lables, predictions)\n",
    "    model.train()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CharIMDB.noise_level = NOISE_LEVEL\n",
    "train, test = CharIMDB.splits(text_field, label_field)\n",
    "\n",
    "dataloader, val_dataloader = get_train_valid_loader(train, valid_size=VALID_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, init_function, dropout=0.5):  #, hidden_dim=256, kernel_size=16):\n",
    "        super(CharCNN, self).__init__()\n",
    "        self.init_function = init_function\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(ALPHABET_LEN, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.conv1[0].weight = init_function(self.conv1[0].weight)\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )\n",
    "        self.conv2[0].weight = init_function(self.conv2[0].weight)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3[0].weight = init_function(self.conv3[0].weight)\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "        self.conv4[0].weight = init_function(self.conv4[0].weight)\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv5[0].weight = init_function(self.conv5[0].weight)\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        )   \n",
    "        self.conv6[0].weight = init_function(self.conv6[0].weight)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8704, 1024),  # MAXLEN = 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Linear(1024, 2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "\n",
    "        # collapse\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # linear layer\n",
    "        x = self.fc1(x)\n",
    "        # linear layer\n",
    "        x = self.fc2(x)\n",
    "        # linear layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with(noise_level, init_function, lr=1e-4, dropout=0.5, epochs=30):\n",
    "    CharIMDB.noise_level = noise_level\n",
    "\n",
    "    model = CharCNN(init_function=init_function)\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    writer = SummaryWriter(comment='_charCNN_BIG_lr%s_noise%s_dropout%s_init_' % (\n",
    "        int(-np.log10(lr)), noise_level, dropout, str(init_function).split()[1]\n",
    "    ))\n",
    "    \n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    global_step = 0\n",
    "\n",
    "    loss_f = F.cross_entropy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    #     if epoch == 10:\n",
    "    #         optimizer = optim.Adam(params=model.parameters(), lr=10**-5)\n",
    "\n",
    "        for batch_idx, (text, label) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if CUDA:\n",
    "                text = Variable(text.cuda())\n",
    "                label = Variable(torch.LongTensor(label).cuda())\n",
    "            else:\n",
    "                text = Variable(text)\n",
    "                label = Variable(torch.LongTensor(label))\n",
    "\n",
    "            text = text.permute(0, 2, 1)  # (1, 0, 2) for RNN\n",
    "            prediction = model(text)\n",
    "\n",
    "            loss = loss_f(prediction, label)\n",
    "\n",
    "            writer.add_scalar('loss', loss.data[0], global_step=global_step)\n",
    "\n",
    "            loss.backward()        \n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1e-1)\n",
    "            optimizer.step()\n",
    "\n",
    "            if CUDA:\n",
    "                torch.cuda.synchronize()\n",
    "            global_step += 1\n",
    "\n",
    "        # evaluation\n",
    "        print('Loss after epoch %s:' % epoch)\n",
    "        print('Global step: %s' % global_step)\n",
    "        print(loss.data[0])\n",
    "\n",
    "        _, idx = torch.max(prediction, 1)\n",
    "        acc = accuracy_score(label.data.tolist(), idx.data.tolist())\n",
    "        writer.add_scalar('accuracy_train', acc, global_step=global_step)\n",
    "        print('In-batch accuracy:', acc)\n",
    "\n",
    "        acc = get_accuracy(model, val_dataloader)\n",
    "        print('Validation accuracy:', acc)\n",
    "        writer.add_scalar('accuracy_val', acc, global_step=global_step)\n",
    "        print()\n",
    "\n",
    "    # Test\n",
    "\n",
    "    acc = get_accuracy(model, test_dataloader)\n",
    "    print('Final test accuracy:', acc)\n",
    "    writer.add_scalar('accuracy_test_final', acc, global_step=global_step)\n",
    "    print()\n",
    "    model.eval()\n",
    "    # model is in EVAL mode!\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6915237903594971\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.7383397817611694\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5424\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.6445028781890869\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.576\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "1.007167100906372\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.6452\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.2538266181945801\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6412\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.44906681776046753\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7124\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.46940934658050537\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.728\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.6819859743118286\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7132\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "1.3677139282226562\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7284\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.5739767551422119\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7476\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.397115558385849\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.768\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.6553877592086792\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.4544152617454529\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7752\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.3340124189853668\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6952\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.33775216341018677\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7048\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.6415084004402161\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7444\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.4912450313568115\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7704\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.07842446863651276\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7816\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.48896145820617676\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7992\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.8107033967971802\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7848\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.1179756373167038\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7536\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.11633720248937607\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6836\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.0539068877696991\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7908\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.41351550817489624\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.752\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.12804491817951202\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7572\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.3357700705528259\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.804\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.6948433518409729\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7584\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.12242886424064636\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.806\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "1.1594997644424438\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.784\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.3284730911254883\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.8096\n",
      "\n",
      "Final test accuracy: 0.80012\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_with(noise_level=0.1, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6712560653686523\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5184\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6933161020278931\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5148\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.6862149238586426\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.514\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.7016793489456177\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5704\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.9100275039672852\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.6268\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.7255017161369324\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.608\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.43671470880508423\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6308\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.7293297648429871\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6644\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.48420223593711853\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.636\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.6475629210472107\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6644\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.2721070349216461\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6916\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.5710490942001343\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7248\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.40101873874664307\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7096\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.3863362669944763\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6772\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.6978304982185364\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7104\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.39088666439056396\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7384\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.3384395241737366\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7324\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.2244337648153305\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.736\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.6939419507980347\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7036\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.29639291763305664\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.752\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.21022260189056396\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.764\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.507341206073761\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.762\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.33287107944488525\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7568\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.7660133838653564\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.766\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.3985484838485718\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7732\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.2857173979282379\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7612\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.4717232286930084\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7712\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.5288262963294983\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7684\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.42267850041389465\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7832\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.25864607095718384\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7592\n",
      "\n",
      "Final test accuracy: 0.77108\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_with(noise_level=0.15, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6963770985603333\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.4988\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6533082723617554\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.4952\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.6950268149375916\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5156\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.684116780757904\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5128\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.6747205257415771\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5168\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.7066308259963989\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.4924\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.7365478873252869\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.5036\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.6840904355049133\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5028\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.6969524025917053\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5076\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.7382858991622925\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6008\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.46222954988479614\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.5848\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.9123713374137878\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.6276\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.936979353427887\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.592\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "1.5209507942199707\n",
      "In-batch accuracy: 0.0\n",
      "Validation accuracy: 0.6344\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.5047850608825684\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6832\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.7840680480003357\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6788\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.3147125840187073\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7048\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.7174410223960876\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7068\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.24927285313606262\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.712\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.6458947062492371\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6832\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.7054051160812378\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.2769394516944885\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.694\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.28699588775634766\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7208\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.37547603249549866\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7276\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "1.024379849433899\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7332\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.5952358841896057\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7288\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.29733869433403015\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7172\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.33172935247421265\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7116\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.14479663968086243\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7464\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.7804518938064575\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6744\n",
      "\n",
      "Final test accuracy: 0.67156\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_with(noise_level=0.2, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6842697262763977\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5052\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6580076217651367\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5148\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.7000224590301514\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.5056\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.685793936252594\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.5172\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.703365683555603\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.504\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.7062662839889526\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.504\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.7318582534790039\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.54\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.6022824048995972\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6156\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.6868293881416321\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.596\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.7190409898757935\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.648\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.5177989602088928\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6584\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.8277955651283264\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6948\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.23688626289367676\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.66\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.5994875431060791\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7104\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.9494305849075317\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.7148\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.5118730068206787\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7092\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.3388878405094147\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6684\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.4896692633628845\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7184\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.24510231614112854\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.73\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.2735171616077423\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7108\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.3494790196418762\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7508\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "1.0175701379776\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7588\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.22332000732421875\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7456\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.2745436429977417\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7544\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.5525521039962769\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7636\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.8320050835609436\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7628\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.6609363555908203\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7592\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.5380147099494934\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7752\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.4814421832561493\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7736\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.23529863357543945\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7048\n",
      "\n",
      "Final test accuracy: 0.70948\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_with(noise_level=0.175, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0:\n",
      "Global step: 704\n",
      "0.6821818351745605\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5096\n",
      "\n",
      "Loss after epoch 1:\n",
      "Global step: 1408\n",
      "0.6878247261047363\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5044\n",
      "\n",
      "Loss after epoch 2:\n",
      "Global step: 2112\n",
      "0.6898511052131653\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5056\n",
      "\n",
      "Loss after epoch 3:\n",
      "Global step: 2816\n",
      "0.6872284412384033\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.5164\n",
      "\n",
      "Loss after epoch 4:\n",
      "Global step: 3520\n",
      "0.6889880299568176\n",
      "In-batch accuracy: 0.25\n",
      "Validation accuracy: 0.514\n",
      "\n",
      "Loss after epoch 5:\n",
      "Global step: 4224\n",
      "0.6952470541000366\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.516\n",
      "\n",
      "Loss after epoch 6:\n",
      "Global step: 4928\n",
      "0.695263147354126\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.6144\n",
      "\n",
      "Loss after epoch 7:\n",
      "Global step: 5632\n",
      "0.3912643790245056\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.5828\n",
      "\n",
      "Loss after epoch 8:\n",
      "Global step: 6336\n",
      "0.832965075969696\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.63\n",
      "\n",
      "Loss after epoch 9:\n",
      "Global step: 7040\n",
      "0.606596827507019\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6652\n",
      "\n",
      "Loss after epoch 10:\n",
      "Global step: 7744\n",
      "0.478373646736145\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6632\n",
      "\n",
      "Loss after epoch 11:\n",
      "Global step: 8448\n",
      "0.5620737075805664\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.69\n",
      "\n",
      "Loss after epoch 12:\n",
      "Global step: 9152\n",
      "0.846269965171814\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6644\n",
      "\n",
      "Loss after epoch 13:\n",
      "Global step: 9856\n",
      "0.1924087256193161\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7244\n",
      "\n",
      "Loss after epoch 14:\n",
      "Global step: 10560\n",
      "0.8424379825592041\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6828\n",
      "\n",
      "Loss after epoch 15:\n",
      "Global step: 11264\n",
      "0.3764747977256775\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7392\n",
      "\n",
      "Loss after epoch 16:\n",
      "Global step: 11968\n",
      "0.4319818615913391\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7216\n",
      "\n",
      "Loss after epoch 17:\n",
      "Global step: 12672\n",
      "0.5370374917984009\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.66\n",
      "\n",
      "Loss after epoch 18:\n",
      "Global step: 13376\n",
      "0.6465838551521301\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7412\n",
      "\n",
      "Loss after epoch 19:\n",
      "Global step: 14080\n",
      "0.3952066898345947\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.732\n",
      "\n",
      "Loss after epoch 20:\n",
      "Global step: 14784\n",
      "0.2917499840259552\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.6488\n",
      "\n",
      "Loss after epoch 21:\n",
      "Global step: 15488\n",
      "0.2824338674545288\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7668\n",
      "\n",
      "Loss after epoch 22:\n",
      "Global step: 16192\n",
      "0.3050396740436554\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7252\n",
      "\n",
      "Loss after epoch 23:\n",
      "Global step: 16896\n",
      "0.5271618366241455\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7664\n",
      "\n",
      "Loss after epoch 24:\n",
      "Global step: 17600\n",
      "0.825470507144928\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.7476\n",
      "\n",
      "Loss after epoch 25:\n",
      "Global step: 18304\n",
      "0.4684687554836273\n",
      "In-batch accuracy: 0.75\n",
      "Validation accuracy: 0.7624\n",
      "\n",
      "Loss after epoch 26:\n",
      "Global step: 19008\n",
      "0.5633856058120728\n",
      "In-batch accuracy: 0.5\n",
      "Validation accuracy: 0.6304\n",
      "\n",
      "Loss after epoch 27:\n",
      "Global step: 19712\n",
      "0.1630975306034088\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.766\n",
      "\n",
      "Loss after epoch 28:\n",
      "Global step: 20416\n",
      "0.214586079120636\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7604\n",
      "\n",
      "Loss after epoch 29:\n",
      "Global step: 21120\n",
      "0.13723284006118774\n",
      "In-batch accuracy: 1.0\n",
      "Validation accuracy: 0.7736\n",
      "\n",
      "Final test accuracy: 0.77156\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CharCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(64, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=8704, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc3): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model_with(noise_level=0.16, init_function=init.xavier_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
